{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8c4f587",
   "metadata": {},
   "source": [
    "# Demonstração: Detecção de Fraude Neuromórfica\n",
    "\n",
    "**Descrição:** Tutorial Interativo sobre o mecanismo biológico de aprendizado STDP (Plasticidade Dependente do Tempo de Spike) usado em redes neurais neuromórficas. Demonstra como os neurônios aprendem correlações temporais automaticamente.\n",
    "\n",
    "**Autor:** Mauro Risonho de Paula Assumpção.\n",
    "**Data de Criação:** 5 Dezembro 2025.\n",
    "**Licença:** MIT License.\n",
    "**Desenvolvimento:** Desenvolvimento Humano + Assistido por IA (Claude Sonnet 4.5, Gemini 3 Pro Preview).\n",
    "\n",
    "---\n",
    "\n",
    "Este notebook Demonstra o pipeline completo de detecção de fraude usando Spiking Neural Networks (SNNs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a287c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Adicionar src ao path\n",
    "# Notebook é em: /portfolio/01_fraud_neuromorphic/notebooks/\n",
    "# src é em: /portfolio/01_fraud_neuromorphic/src/\n",
    "notebook_dir = Path.cwd()\n",
    "\n",
    "# Verificar se estamos no diretório raiz do projeto ou no diretório notebooks\n",
    "if (notebook_dir / 'portfolio' / '01_fraud_neuromorphic' / 'src').exists():\n",
    "    # Estamos na raiz do projeto (Projeto-Neuromorfico-X)\n",
    "    src_path = notebook_dir / 'portfolio' / '01_fraud_neuromorphic' / 'src'\n",
    "elif (notebook_dir.parent / 'src').exists():\n",
    "    # Estamos em notebooks/\n",
    "    src_path = notebook_dir.parent / 'src'\n",
    "elif (notebook_dir / 'src').exists():\n",
    "    # Estamos em 01_fraud_neuromorphic/\n",
    "    src_path = notebook_dir / 'src'\n",
    "else:\n",
    "    src_path = None\n",
    "\n",
    "if src_path and src_path.exists():\n",
    "    if str(src_path) not in sys.path:\n",
    "        sys.path.insert(0, str(src_path))\n",
    "        print(f\" Diretório src adicionado: {src_path}\")\n",
    "else:\n",
    "    print(f\"⚠️ Diretório src não encontrado!\")\n",
    "    print(f\"  Notebook dir: {notebook_dir}\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import time\n",
    "from tqdm.auto import tqdm\n",
    "import brian2\n",
    "\n",
    "# Configurar Brian2 para usar numpy (evita errors de compilação C++ e problemas com SymPy/Cython)\n",
    "brian2.prefs.codegen.target = \"numpy\"\n",
    "\n",
    "# Nossos módulos\n",
    "try:\n",
    "    from principal import FraudDetectionPipeline, generate_synthetic_transactions\n",
    "    from encoders import RateEncoder, TemporalEncoder, PopulationEncoder, TransactionEncoder\n",
    "    from models_snn import FraudSNN, demonstrate_lif_neuron  # type: ignore[attr-defined]\n",
    "    print(\" Imports dos project modules completed!\")\n",
    "except ImportError as e:\n",
    "    print(f\" error ao importar módulos: {e}\")\n",
    "    print(f\"  sys.path: {sys.path[:3]}\")\n",
    "\n",
    "# Configuração de visualization\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b3c422e",
   "metadata": {},
   "source": [
    "## 2. Geração de dados Sintéticos\n",
    "\n",
    "Vamos criar a conjunto de dados sintético de transações bancárias com padrões realistas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9542a0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gerar 1000 transactions (5% fraudes)\n",
    "print(\"Gerando transações sintéticas...\")\n",
    "df = generate_synthetic_transactions(n=1000, fraud_ratio=0.05)\n",
    "\n",
    "print(f\"\\n Dataset generated:\")\n",
    "print(f\"total de transações: {len(df)}\")\n",
    "print(f\"Transações legítimas: {np.sum(df['is_fraud'] == 0)}\")\n",
    "print(f\"Transações fraudulentas: {np.sum(df['is_fraud'] == 1)}\")\n",
    "print(f\"taxa de fraude: {df['is_fraud'].mean():.2%}\")\n",
    "\n",
    "# Mostrar primeiras linhas\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55178d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar distribuição de valores\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# distribuição de valores por classe\n",
    "df[df['is_fraud'] == 0]['amount'].hist(bins=50, alpha=0.7, label='Legítimas', ax=axes[0], color='green')\n",
    "df[df['is_fraud'] == 1]['amount'].hist(bins=30, alpha=0.7, label='Fraudulentas', ax=axes[0], color='red')\n",
    "axes[0].set_xlabel('valor da Transação ($)')\n",
    "axes[0].set_ylabel('frequency')\n",
    "axes[0].set_title('distribuição de valores por classe')\n",
    "axes[0].legend()\n",
    "\n",
    "# frequência diária por classe\n",
    "df.boxplot(column='daily_frequency', by='is_fraud', ax=axes[1])\n",
    "axes[1].set_xlabel('class (0=Legítima, 1=Fraude)')\n",
    "axes[1].set_ylabel('Daily Frequency')\n",
    "axes[1].set_title('frequência de Transações por classe')\n",
    "plt.suptitle('')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n padrões observados:\")\n",
    "print(\" - Fraudes tendem a ter valores mais altos\")\n",
    "print(\" - Fraudes têm maior frequência de transações\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac22d44",
   "metadata": {},
   "source": [
    "## 3. Encoding de Disparos\n",
    "\n",
    "Demonstrar como features de transactions são convertidas em disparos temporal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b29cf11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemplo de Rate Encoding\n",
    "print(\"=== CODIFICAÇÃO POR TAXA ===\")\n",
    "print(\"Codifica values contínuos how frequency de disparos\\n\")\n",
    "\n",
    "rate_encoder = RateEncoder(min_rate=1, max_rate=100, duração=0.1)\n",
    "\n",
    "# Testarar com diferentes valores\n",
    "test_amounts = [100, 500, 1000, 5000, 10000]\n",
    "\n",
    "fig, axes = plt.subplots(len(test_amounts), 1, figsize=(12, 10))\n",
    "\n",
    "for idx, amount em enumerate(test_amounts):\n",
    "    disparo_times = rate_encoder.encode(amount, min_val=0, max_val=10000)\n",
    "    \n",
    "    # Visualizar\n",
    "    if disparo_times:\n",
    "        axes[idx].eventplot([spike_times], linewidths=2, colors='blue')\n",
    "        axes[idx].set_xlim(0, 0.1)\n",
    "        axes[idx].set_ylim(0.5, 1.5)\n",
    "        axes[idx].set_ylabel(f'${amount}')\n",
    "        axes[idx].set_title(f'value: ${amount} → {len(spike_times)} disparos')\n",
    "        axes[idx].grid(True, alpha=0.3)\n",
    "    \n",
    "axes[-1].set_xlabel('time (segundos)')\n",
    "plt.suptitle('Rate Encoding: value → frequency de Disparos', fontsize=14, y=1.0)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n Note: values larger generate more disparos (larger frequency)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3bd4fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemplo de Population Encoding (Geolocation)\n",
    "print(\"=== CODIFICAÇÃO POR POPULAÇÃO ===\")\n",
    "print(\"Codifica values usando multiple neurônios com receptive fields\\n\")\n",
    "\n",
    "pop_encoder = PopulationEncoder(n_neurônios=20, min_val=-1, max_val=1, sigma=0.15)\n",
    "\n",
    "# Testarar com diferentes localizações\n",
    "test_locations = [-0.8, -0.3, 0.0, 0.4, 0.9]\n",
    "\n",
    "fig, axes = plt.subplots(2, 1, figsize=(14, 8))\n",
    "\n",
    "# Plot 1: Activation dos neurônios\n",
    "for loc em test_locations:\n",
    "    activations = np.exp(-((pop_encoder.centers - loc) ** 2) / (2 * pop_encoder.sigma ** 2))\n",
    "    axes[0].plot(pop_encoder.centers, activations, marker='o', label=f'Location = {loc:.1f}', alpha=0.7)\n",
    "\n",
    "axes[0].set_xlabel('Centro do neurônio')\n",
    "axes[0].set_ylabel('Activation')\n",
    "axes[0].set_title('Activation da Population de neurônios por Location')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Raster plot de disparos\n",
    "spike_data = []\n",
    "for idx, loc em enumerate(test_locations):\n",
    "    encoding = pop_encoder.encode(loc, duração=0.1)\n",
    "    if len(encoding.spike_times) > 0:\n",
    "        para t, n em zip(encoding.spike_times, encoding.neuron_indices):\n",
    "            disparo_data.append([t, n + idx * 25]) # Offset para visualization\n",
    "\n",
    "if disparo_data:\n",
    "    disparo_array = np.array(spike_data)\n",
    "    axes[1].scatter(spike_array[:, 0], disparo_array[:, 1], marker='|', s=100, alpha=0.6)\n",
    "\n",
    "axes[1].set_xlabel('time (segundos)')\n",
    "axes[1].set_ylabel('neurônio + Deslocamento')\n",
    "axes[1].set_title('Disparos Gerados por Population de neurônios')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n Note: Each location activates um group different de neurônios\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cccf508d",
   "metadata": {},
   "source": [
    "## 4. Arquitetura da SNN\n",
    "\n",
    "Visualizar e entender a arquitetura da Spiking Neural Network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68cc26d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstration de neurônio LIF individual\n",
    "print(\"=== NEURÔNIO LEAKY INTEGRATE-AND-FIRE ===\")\n",
    "print(\"Demonstration do behavior de um neurônio LIF\\n\")\n",
    "\n",
    "lif_data = demonstrate_lif_neuron()  # type: ignore[name-defined]\n",
    "\n",
    "fig, axes = plt.subplots(2, 1, figsize=(14, 8), sharex=True)\n",
    "\n",
    "# Plot 1: Corrente de entrada\n",
    "axes[0].plot(lif_data['time'], lif_data['input'], color='blue', linewidth=2)\n",
    "axes[0].set_ylabel('Corrente de entrada (I)')\n",
    "axes[0].set_title('Estímulo de entrada (Corrente de Passo)')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Potencial de membrana e disparos\n",
    "axes[1].plot(lif_data['time'], lif_data['voltage'], color='green', linewidth=2, label='Potencial de Membrana')\n",
    "axes[1].axhline(-50, color='red', linestyle='--', label='Threshold (-50mV)', alpha=0.7)\n",
    "axes[1].axhline(-70, color='gray', linestyle='--', label='Resting (-70mV)', alpha=0.5)\n",
    "\n",
    "# Marcar disparos\n",
    "for disparo_time em lif_data['disparos']:\n",
    "    axes[1].axvline(spike_time, color='red', alpha=0.3, linewidth=1)\n",
    "\n",
    "axes[1].set_xlabel('time (ms)')\n",
    "axes[1].set_ylabel('Voltagem (mV)')\n",
    "axes[1].set_title(f'Potencial de Membrana (total de {len(lif_data[\"disparos\"])} disparos)')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n Análise:\")\n",
    "print(f\"  - Disparos detectados: {len(lif_data['disparos'])}\")\n",
    "print(f\"  - frequência média: {len(lif_data['disparos']) / (lif_data['time'][-1] / 1000):.1f} Hz\")\n",
    "print(f\"  - ISI médio: {np.mean(np.diff(lif_data['disparos'])):.2f} ms\" if len(lif_data['disparos']) > 1 else \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830456a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estatísticas da arquitetura SNN\n",
    "print(\"=== ARQUITETURA DA SNN ===\")\n",
    "\n",
    "snn = FraudSNN(input_size=256, hidden_sizes=[128, 64], output_size=2)\n",
    "stats = snn.get_network_stats()  # type: ignore[attr-defined]\n",
    "\n",
    "print(f\"\\n Estrutura da network:\")\n",
    "print(f\"  Input Layer: {stats['layers']['input']} neurônios\")\n",
    "print(f\"  Hidden Layer 1: {stats['layers']['hidden'][0]} neurônios (LIF)\")\n",
    "print(f\"  Hidden Layer 2: {stats['layers']['hidden'][1]} neurônios (LIF)\")\n",
    "print(f\"  Output Layer: {stats['layers']['output']} neurônios\")\n",
    "print(f\"\\n  total de neurônios: {stats['total_neurônios']}\")\n",
    "print(f\"  total de sinapses: {stats['total_synapses']}\")\n",
    "\n",
    "print(f\"\\n pesos Sinápticos:\")\n",
    "print(f\"  average: {stats['pesos']['mean']:.4f}\")\n",
    "print(f\"  deviation pattern: {stats['pesos']['std']:.4f}\")\n",
    "print(f\"  Min: {stats['pesos']['min']:.4f}\")\n",
    "print(f\"  Max: {stats['pesos']['max']:.4f}\")\n",
    "\n",
    "# Visualizar arquitetura\n",
    "layer_sizes = [256, 128, 64, 2]\n",
    "layer_names = ['Input\\n(256)', 'Hidden 1\\n(128)', 'Hidden 2\\n(64)', 'Output\\n(2)']\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 6))\n",
    "\n",
    "# Desenhar layers\n",
    "x_positions = np.linspace(0, 10, len(layer_sizes))\n",
    "max_size = max(layer_sizes)\n",
    "\n",
    "for i, (size, name, x) em enumerate(zip(layer_sizes, layer_names, x_positions)):\n",
    "    y_positions = np.linspace(0, max_size, size)\n",
    "    \n",
    "    # Limitar visualização para layers large\n",
    "    display_neurônios = min(size, 20)\n",
    "    y_display = np.linspace(0, max_size, display_neurônios)\n",
    "    \n",
    "    ax.scatter([x] * display_neurônios, y_display, s=100, alpha=0.7, \n",
    "               color=f'C{i}', label=name, zorder=3)\n",
    "    \n",
    "    # Conectar com próximo layer\n",
    "    if i < len(layer_sizes) - 1:\n",
    "        next_x = x_positions[i + 1]\n",
    "        next_size = min(layer_sizes[i + 1], 20)\n",
    "        next_y = np.linspace(0, max_size, next_size)\n",
    "        \n",
    "        # Desenhar algumas connections (amostra)\n",
    "        para y1 em y_display[::3]:\n",
    "            para y2 em next_y[::3]:\n",
    "                ax.plot([x, next_x], [y1, y2], 'k-', alpha=0.05, linewidth=0.5, zorder=1)\n",
    "\n",
    "ax.set_xlim(-1, 11)\n",
    "ax.set_ylim(-20, max_size + 20)\n",
    "ax.set_xticks(x_positions)\n",
    "ax.set_xticklabels(layer_names)\n",
    "ax.set_yticks([])\n",
    "ax.set_title('Arquitetura da Spiking Neural Network para Detection de Fraude', fontsize=14)\n",
    "ax.spines['left'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0cd59bc",
   "metadata": {},
   "source": [
    "## 5. Pipeline Completo\n",
    "\n",
    "Executar o pipeline de ponta a ponta: treinar e avaliar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d67fe06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializar pipeline\n",
    "print(\"Inicializando pipeline de detection de fraude...\")\n",
    "pipeline = FraudDetectionPipeline()\n",
    "\n",
    "# Split train/test - usar dados smaller para demo fast\n",
    "train_size = int(0.8 * len(df))\n",
    "train_data = df[:train_size].copy()\n",
    "test_data = df[train_size:].copy()\n",
    "\n",
    "# Para demo, use apenas a pequeno subset do treino\n",
    "# Reduzido para 20 amostras para execution rápido em modo numpy (without compilação C++)\n",
    "train_subset_size = min(20, len(train_data))\n",
    "train_subset = train_data.sample(n=train_subset_size, random_state=42)\n",
    "\n",
    "print(f\"\\n Divisão dos data:\")\n",
    "print(f\" Treino (subset para demo): {len(train_subset)} transactions\")\n",
    "print(f\" Test: {len(test_data)} transactions\")\n",
    "print(f\"\\n Note: Using reduced subset para Demonstration fast\")\n",
    "\n",
    "print(\"\\n⏳ Starting Training com STDP...\")\n",
    "print(\"(Usando poucos epochs e data reduzidos para demo fast)\\n\")\n",
    "\n",
    "# Reduzir drasticamente para demo\n",
    "epochs = 2\n",
    "print(f\" Training: {epochs} epochs com {len(train_subset)} transactions\")\n",
    "\n",
    "# Treinaring fast\n",
    "start_time = time.time()\n",
    "print(\"Treinando...\")\n",
    "pipeline.train(train_subset, epochs=epochs)\n",
    "training_time = time.time() - start_time\n",
    "\n",
    "print(f\"\\n Training concluído em {training_time:.1f}s\")\n",
    "print(f\" tempo médio por epoch: {training_time/epochs:.2f}s\")\n",
    "print(f\" rate: {len(train_subset) * epochs / training_time:.1f} transactions/de acordo com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b7304d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avaliar no set de Testar\n",
    "print(\" Avaliando model no set de Test...\")\n",
    "print(f\"total de {len(test_data)} transactions\\n\")\n",
    "\n",
    "# Avaliação com tempo estimado\n",
    "start_eval = time.time()\n",
    "metrics = pipeline.evaluate(test_data)\n",
    "eval_time = time.time() - start_eval\n",
    "\n",
    "print(f\"\\n Evaluation concluída em {eval_time:.2f}s\")\n",
    "print(f\" speed: {len(test_data)/eval_time:.1f} transactions/de acordo com\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d27213",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar matriz de confusão\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "# Converter explicitamente para numpy arrays\n",
    "y_true = test_data['is_fraud'].to_numpy()\n",
    "y_pred = []\n",
    "\n",
    "print(\" Gerando predictions para matriz de confusão...\")\n",
    "for _, row em tqdm(test_data.iterrows(), total=len(test_data), desc=\"Predictions\", unit=\"txn\"):\n",
    "    result = pipeline.predict(row.to_dict())\n",
    "    y_pred.append(int(result['is_fraud']))\n",
    "\n",
    "# Converter y_pred para numpy array\n",
    "y_pred = np.array(y_pred, dtype=int)\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['Legítima', 'Fraude'],\n",
    "            yticklabels=['Legítima', 'Fraude'],\n",
    "            cbar_kws={'label': 'Contagem'})\n",
    "ax.set_xlabel('Prediction')\n",
    "ax.set_ylabel('Real')\n",
    "ax.set_title('Matriz de Confusão - Detecção de Fraude Neuromórfica')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n accuracy: {metrics['accuracy']:.2%}\")\n",
    "print(f\"  precision: {metrics['precision']:.2%}\")\n",
    "print(f\"  Recall: {metrics['recall']:.2%}\")\n",
    "print(f\"  F1-Score: {metrics['f1_score']:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42280973",
   "metadata": {},
   "source": [
    "## 6. Exemplos de Prediction Individual\n",
    "\n",
    "Testarar com transactions específicas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f933f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemplo 1: Transaction legítima típica\n",
    "print(\"=\" * 60)\n",
    "print(\"Exemplo 1: Transaction Legítima\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "legitimate_txn = {\n",
    " 'id': 'demo_001',\n",
    " 'amount': 85.50,\n",
    " 'timestamp': time.time(),\n",
    " 'merchant_category': 'groceries',\n",
    " 'location': (-23.5505, -46.6333), # São Paulo\n",
    " 'device_id': 'device_regular_001',\n",
    " 'daily_frequency': 3\n",
    "}\n",
    "\n",
    "result = pipeline.predict(legitimate_txn)\n",
    "\n",
    "print(f\"\\nTransaction:\")\n",
    "print(f\" value: ${legitimate_txn['amount']:.2f}\")\n",
    "print(f\" Categoria: {legitimate_txn['merchant_category']}\")\n",
    "print(f\" Location: São Paulo\")\n",
    "\n",
    "print(f\"\\n result da Análise:\")\n",
    "print(f\" Fraude detectada: {' YES' if result['is_fraud'] else ' NO'}\")\n",
    "print(f\" Confiança: {result['confidence']:.2%}\")\n",
    "print(f\" Score Legítima: {result['legitimate_score']:.2f} Hz\")\n",
    "print(f\" Score Fraude: {result['fraud_score']:.2f} Hz\")\n",
    "print(f\" latência: {result['latência_ms']:.2f}ms\")\n",
    "print(f\" Disparos generated: {result['n_disparos_generated']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e53466",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemplo 2: Transaction suspeita (high probability de fraude)\n",
    "print(\"=\" * 60)\n",
    "print(\"Exemplo 2: Transaction Suspeita\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "suspicious_txn = {\n",
    " 'id': 'demo_002',\n",
    " 'amount': 8500.00, # value high\n",
    " 'timestamp': time.time(),\n",
    " 'merchant_category': 'electronics',\n",
    " 'location': (51.5074, -0.1278), # Londres (location incomum)\n",
    " 'device_id': 'device_new_unknown', # Dispositivo new\n",
    " 'daily_frequency': 25 # frequency anormal\n",
    "}\n",
    "\n",
    "result = pipeline.predict(suspicious_txn)\n",
    "\n",
    "print(f\"\\nTransaction:\")\n",
    "print(f\" value: ${suspicious_txn['amount']:.2f}\")\n",
    "print(f\" Categoria: {suspicious_txn['merchant_category']}\")\n",
    "print(f\" Location: Londres (incomum)\")\n",
    "print(f\" Dispositivo: new/Desconhecido\")\n",
    "\n",
    "print(f\"\\n result da Análise:\")\n",
    "print(f\" Fraude detectada: {' YES' if result['is_fraud'] else ' NO'}\")\n",
    "print(f\" Confiança: {result['confidence']:.2%}\")\n",
    "print(f\" Score Legítima: {result['legitimate_score']:.2f} Hz\")\n",
    "print(f\" Score Fraude: {result['fraud_score']:.2f} Hz\")\n",
    "print(f\" latência: {result['latência_ms']:.2f}ms\")\n",
    "print(f\" Disparos generated: {result['n_disparos_generated']}\")\n",
    "\n",
    "if result['is_fraud']:\n",
    " print(f\"\\n ALERTA: Transaction bloqueada para Analysis manual!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "692bb248",
   "metadata": {},
   "source": [
    "## 7. Análise de Desempenho\n",
    "\n",
    "Avaliar latência e throughput do sistema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b29e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benchmark de latência\n",
    "print(\"=== Benchmark DE latência ===\")\n",
    "n_samples = min(100, len(test_data))\n",
    "print(f\"Testando {n_samples} transactions...\\n\")\n",
    "\n",
    "latencies = []\n",
    "sample_txns = test_data.sample(n=n_samples)\n",
    "\n",
    "for _, row em tqdm(sample_txns.iterrows(), total=n_samples, desc=\"Benchmark\", unit=\"txn\"):\n",
    " start = time.time()\n",
    " result = pipeline.predict(row.to_dict())\n",
    " latência = (time.time() - start) * 1000 # ms\n",
    " latencies.append(latência)\n",
    "\n",
    "latencies = np.array(latencies)\n",
    "\n",
    "print(f\"\\n Estatísticas de latência:\")\n",
    "print(f\" average: {latencies.mean():.2f}ms\")\n",
    "print(f\" median: {np.median(latencies):.2f}ms\")\n",
    "print(f\" Min: {latencies.min():.2f}ms\")\n",
    "print(f\" Max: {latencies.max():.2f}ms\")\n",
    "print(f\" P95: {np.percentile(latencies, 95):.2f}ms\")\n",
    "print(f\" P99: {np.percentile(latencies, 99):.2f}ms\")\n",
    "\n",
    "throughput = 1000 / latencies.mean() # transações por segundo\n",
    "print(f\"\\n Vazão estimada: {throughput:.0f} transactions/de acordo com\")\n",
    "\n",
    "# Visualizar distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "axes[0].hist(latencies, bins=30, color='skyblue', edgecolor='black', alpha=0.7)\n",
    "axes[0].axvline(latencies.mean(), color='red', linestyle='--', label=f'average: {latencies.mean():.2f}ms')\n",
    "axes[0].axvline(np.percentile(latencies, 95), color='orange', linestyle='--', label=f'P95: {np.percentile(latencies, 95):.2f}ms')\n",
    "axes[0].set_xlabel('latência (ms)')\n",
    "axes[0].set_ylabel('frequency')\n",
    "axes[0].set_title('distribution de latência')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1].boxplot(latencies, vert=True)\n",
    "axes[1].set_ylabel('latência (ms)')\n",
    "axes[1].set_title('Boxplot de latência')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e126f205",
   "metadata": {},
   "source": [
    "## 8. Conclusões\n",
    "\n",
    "### Vantagens da Abordagem Neuromórfica\n",
    "\n",
    "1. **Latência ultra-baixa**: Detection em ~10ms\n",
    "2. **Processamento temporal nativo**: Captura patterns de sequence naturalmente\n",
    "3. **eficiência energética**: Ideal para deployment em edge devices\n",
    "4. **Learning biological**: STDP allows adaptation contínua\n",
    "\n",
    "### Applications em Bancos e Fintechs\n",
    "\n",
    "- Detection de fraude em tempo real no POS\n",
    "- Protection de transactions Pix/TED/DOC\n",
    "- Monitoramento de carteiras digitais\n",
    "- Análise comportamental em mobile banking\n",
    "\n",
    "### Next steps\n",
    "\n",
    "- Deploy em hardware neuromórfico (Intel Loihi, IBM TrueNorth)\n",
    "- Integration com sistemas legados via API\n",
    "- Explicabilidade (SHAP para SNNs)\n",
    "- Federated aprendizado entre institutions\n",
    "\n",
    "---\n",
    "\n",
    "**Autor:** Mauro Risonho de Paula Assumpção \n",
    "**Projeto:** Computation Neuromórfica para Cybersecurity Banking"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fraud-detection-neuromorphic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
