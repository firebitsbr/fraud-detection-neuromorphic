{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed5a3e24",
   "metadata": {},
   "source": [
    "# Hardware Benchmark: Loihi vs CPU\n",
    "\n",
    "**Descrição:** Comparação de performance entre implementação CPU (Brian2) e simulação Intel Loihi 2 para detecção de fraude neuromórfica. Avalia latência, throughput, energia e eficiência.\n",
    "\n",
    "**Autor:** Mauro Risonho de Paula Assumpção.\n",
    "**Data de Criação:** 5 de Dezembro de 2025.\n",
    "**Licença:** MIT License.\n",
    "**Desenvolvimento:** Humano + Desenvolvimento por AI Assistida (Claude Sonnet 4.5, Gemini 3 Pro Preview).\n",
    "\n",
    "---\n",
    "\n",
    "## Objetivo\n",
    "\n",
    "Comparar a performance da implementação de detecção de fraude com SNN em:\n",
    "- **CPU Tradicional** (Brian2 simulator)\n",
    "- **Intel Loihi 2** (simulação de hardware neuromórfico)\n",
    "\n",
    "## Métricas Avaliadas\n",
    "\n",
    "1. **Latência** (ms por inferência)\n",
    "2. **Throughput** (transações por segundo)\n",
    "3. **Energia** (millijoules)\n",
    "4. **Potência** (milliwatts)\n",
    "5. **Eficiência** (speedup e power efficiency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "491bb418",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block after 'if' statement on line 23 (4132280828.py, line 24)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 24\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31msys.path.remove(path)\u001b[39m\n    ^\n\u001b[31mIndentationError\u001b[39m\u001b[31m:\u001b[39m expected an indented block after 'if' statement on line 23\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Determinar o diretório raiz do projeto\n",
    "# O notebook está em: portfolio/01_fraud_neuromorphic/notebooks/\n",
    "# Precisamos chegar em: portfolio/01_fraud_neuromorphic/\n",
    "notebook_dir = Path.cwd()\n",
    "if 'notebooks' in str(notebook_dir):\n",
    "    # Se estamos em .../portfolio/01_fraud_neuromorphic/notebooks\n",
    "    project_root = notebook_dir.parent if notebook_dir.name == 'notebooks' else notebook_dir\n",
    "elif '01_fraud_neuromorphic' not in str(notebook_dir):\n",
    "    # Se estamos no root do repositório, navegar até o projeto\n",
    "    project_root = notebook_dir / 'portfolio' / '01_fraud_neuromorphic'\n",
    "else:\n",
    "    # Já estamos no diretório do projeto\n",
    "    project_root = notebook_dir\n",
    "\n",
    "src_path = project_root / 'src'\n",
    "hardware_path = project_root / 'hardware'\n",
    "\n",
    "# Remover caminhos anteriores se existirem para evitar duplicatas\n",
    "for path in [str(src_path), str(hardware_path)]:\n",
    "    if path in sys.path:\n",
    "        sys.path.remove(path)\n",
    "\n",
    "# Adicionar ao início do path\n",
    "sys.path.insert(0, str(src_path))\n",
    "sys.path.insert(0, str(hardware_path))\n",
    "\n",
    "# Verificar se os diretórios existem\n",
    "print(f\"✓ Current directory: {notebook_dir}\")\n",
    "print(f\"✓ Project root: {project_root}\")\n",
    "print(f\"✓ Src path exists: {src_path.exists()}\")\n",
    "print(f\"✓ Hardware path exists: {hardware_path.exists()}\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "from tqdm.auto import tqdm\n",
    "import brian2\n",
    "\n",
    "# Configurar Brian2 para usar numpy (evita erros de compilação C++ e problemas com SymPy/Cython)\n",
    "# Isso também suprime os logs de compilação do Cython que você estava vendo\n",
    "brian2.prefs.codegen.target = \"numpy\"\n",
    "\n",
    "# Imports do projeto - diretamente pois já estão no sys.path\n",
    "from main import FraudDetectionPipeline, generate_synthetic_transactions\n",
    "from loihi_simulator import LoihiSimulator, compare_with_cpu, LoihiSpecs # type: ignore\n",
    "\n",
    "# Configurar visualização\n",
    "plt.style.use('seaborn-v0_8-darkgrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c16e29",
   "metadata": {},
   "source": [
    "## 1. Benchmark em CPU\n",
    "\n",
    "Primeiro, vamos medir a performance real da implementação rodando em CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae7c4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gerar dataset de teste\n",
    "print(\" Gerando dataset de teste...\")\n",
    "df_train = generate_synthetic_transactions(n=500, fraud_ratio=0.2)\n",
    "df_test = generate_synthetic_transactions(n=1000, fraud_ratio=0.2)\n",
    "\n",
    "# Separar features e labels\n",
    "feature_cols = ['amount', 'daily_frequency']\n",
    "X_train = df_train[feature_cols].values\n",
    "y_train = df_train['is_fraud'].values\n",
    "X_test = df_test[feature_cols].values\n",
    "y_test = df_test['is_fraud'].values\n",
    "\n",
    "print(f\"Train: X={X_train.shape}, y={y_train.shape}\")\n",
    "print(f\"Test: X={X_test.shape}, y={y_test.shape}\")\n",
    "\n",
    "# Converter para numpy array explicitamente para evitar erros de tipagem do Pylance\n",
    "y_train_np = np.array(y_train)\n",
    "y_test_np = np.array(y_test)\n",
    "\n",
    "print(f\"Fraudes no treino: {int(np.sum(y_train_np))}/{len(y_train_np)} ({float(np.mean(y_train_np))*100:.1f}%)\")\n",
    "print(f\"Fraudes no teste: {int(np.sum(y_test_np))}/{len(y_test_np)} ({float(np.mean(y_test_np))*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a4d2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializar modelo (usar sem treinamento para benchmark de inferência)\n",
    "print(\" Inicializando pipeline SNN...\")\n",
    "pipeline = FraudDetectionPipeline()\n",
    "\n",
    "print(\" Pipeline inicializado\")\n",
    "print(\" Nota: Este benchmark foca em LATÊNCIA DE INFERÊNCIA\")\n",
    "print(\" O modelo está usando pesos aleatórios - em produção seria pré-treinado\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d66499",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTANTE: Recarregar módulos após correções\n",
    "import importlib\n",
    "import sys\n",
    "\n",
    "# Recarregar módulos do projeto\n",
    "if 'models_snn' in sys.modules:\n",
    " importlib.reload(sys.modules['models_snn'])\n",
    "if 'encoders' in sys.modules:\n",
    " importlib.reload(sys.modules['encoders'])\n",
    "if 'main' in sys.modules:\n",
    " importlib.reload(sys.modules['main'])\n",
    "\n",
    "# Reimportar após reload\n",
    "from main import FraudDetectionPipeline, generate_synthetic_transactions\n",
    "\n",
    "print(\" Módulos recarregados com correções de dt=0.1ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b879705",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reinicializar pipeline com módulos corrigidos\n",
    "print(\" Reinicializando pipeline SNN com dt=0.1ms...\")\n",
    "pipeline = FraudDetectionPipeline()\n",
    "\n",
    "print(\" Pipeline reinicializado\")\n",
    "print(\" Nota: Agora usando Brian2 dt=0.1ms (100 microsegundos)\")\n",
    "print(\" Isso elimina conflitos de spikes duplicados\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae613912",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benchmark de inferência em CPU\n",
    "print(\"⏱ Benchmark de Inferência em CPU\\n\")\n",
    "\n",
    "# Usar menos samples para benchmark rápido (Brian2 é lento)\n",
    "num_samples = 100 # Reduzido de 1000 para velocidade\n",
    "latencies_cpu = []\n",
    "\n",
    "print(f\"Processando {num_samples} amostras...\")\n",
    "\n",
    "for i in tqdm(range(num_samples), desc=\"Inferências CPU\"):\n",
    " # Converter DataFrame row para dicionário\n",
    " transaction = df_test.iloc[i].to_dict()\n",
    " \n",
    " try:\n",
    " start = time.perf_counter()\n",
    " prediction = pipeline.predict(transaction)\n",
    " end = time.perf_counter()\n",
    " \n",
    " latency_ms = (end - start) * 1000\n",
    " latencies_cpu.append(latency_ms)\n",
    " except ValueError as e:\n",
    " if \"spike more than once\" in str(e):\n",
    " print(f\"\\n Erro de colisão de spikes na amostra {i}!\")\n",
    " print(f\"Detalhes: {e}\")\n",
    " print(\"Tentando continuar com a próxima amostra...\")\n",
    " continue\n",
    " else:\n",
    " print(f\"\\n Erro inesperado na amostra {i}: {e}\")\n",
    " raise e\n",
    " except Exception as e:\n",
    " print(f\"\\n Erro genérico na amostra {i}: {e}\")\n",
    " raise e\n",
    "\n",
    "# Estatísticas CPU\n",
    "if latencies_cpu:\n",
    " cpu_metrics = {\n",
    " 'mean_latency_ms': np.mean(latencies_cpu),\n",
    " 'median_latency_ms': np.median(latencies_cpu),\n",
    " 'p95_latency_ms': np.percentile(latencies_cpu, 95),\n",
    " 'p99_latency_ms': np.percentile(latencies_cpu, 99),\n",
    " 'throughput_fps': 1000 / np.mean(latencies_cpu),\n",
    " 'total_time_s': sum(latencies_cpu) / 1000\n",
    " }\n",
    "\n",
    " print(\"\\n\" + \"=\"*50)\n",
    " print(\"CPU BENCHMARK RESULTS\")\n",
    " print(\"=\"*50)\n",
    " print(f\"Amostras processadas: {len(latencies_cpu)}/{num_samples}\")\n",
    " print(f\"Latência Média: {cpu_metrics['mean_latency_ms']:.2f} ms\")\n",
    " print(f\"Latência Mediana: {cpu_metrics['median_latency_ms']:.2f} ms\")\n",
    " print(f\"Latência P95: {cpu_metrics['p95_latency_ms']:.2f} ms\")\n",
    " print(f\"Latência P99: {cpu_metrics['p99_latency_ms']:.2f} ms\")\n",
    " print(f\"Throughput: {cpu_metrics['throughput_fps']:.1f} transações/s\")\n",
    " print(f\"Tempo Total: {cpu_metrics['total_time_s']:.2f} s\")\n",
    " print(\"=\"*50)\n",
    "else:\n",
    " print(\"\\n Nenhuma amostra processada com sucesso.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af24f4b9",
   "metadata": {},
   "source": [
    "## 2. Simulação Intel Loihi 2\n",
    "\n",
    "Agora vamos simular como seria a performance no chip neuromórfico Loihi 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad70467",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializar simulador Loihi\n",
    "loihi = LoihiSimulator()\n",
    "\n",
    "# Especificações da rede\n",
    "network_neurons = 256 + 128 + 64 + 2 # 450 neurônios\n",
    "network_synapses = (256 * 128) + (128 * 64) + (64 * 2) # 41,088 sinapses\n",
    "\n",
    "print(f\" Rede Neural:\")\n",
    "print(f\" - Neurônios: {network_neurons:,}\")\n",
    "print(f\" - Sinapses: {network_synapses:,}\")\n",
    "print(f\"\\n Loihi 2 Specs:\")\n",
    "print(f\" - Cores: {loihi.specs.num_cores}\")\n",
    "print(f\" - Neurônios: {loihi.specs.total_neurons:,}\")\n",
    "print(f\" - Power/core: {loihi.specs.power_per_core_active*1000:.1f} mW\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b015af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Executar benchmark Loihi\n",
    "print(\"\\n Executando benchmark Loihi 2...\\n\")\n",
    "\n",
    "loihi_metrics = loihi.benchmark_inference(\n",
    " network_neurons=network_neurons,\n",
    " network_synapses=network_synapses,\n",
    " num_inferences=num_samples,\n",
    " simulation_time_ms=100.0\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"LOIHI 2 BENCHMARK RESULTS\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Latência: {loihi_metrics.latency_ms:.2f} ms\")\n",
    "print(f\"Throughput: {loihi_metrics.throughput_fps:.1f} transações/s\")\n",
    "print(f\"Energia Total: {loihi_metrics.energy_mj:.2f} mJ\")\n",
    "print(f\"Potência Média: {loihi_metrics.power_mw:.2f} mW\")\n",
    "print(f\"Cores Usados: {loihi_metrics.cores_used}/{loihi.specs.num_cores}\")\n",
    "print(f\"Total de Spikes: {loihi_metrics.total_spikes:,}\")\n",
    "print(f\"Ops Sinápticas: {loihi_metrics.synaptic_operations:,}\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4977f6cc",
   "metadata": {},
   "source": [
    "## 3. Comparação e Análise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eaead8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparar com CPU\n",
    "cpu_power_w = 65.0 # TDP típico de CPU Intel Core i5/i7\n",
    "\n",
    "comparison = compare_with_cpu(\n",
    " loihi_metrics=loihi_metrics,\n",
    " cpu_latency_ms=cpu_metrics['mean_latency_ms'],\n",
    " cpu_power_w=cpu_power_w\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"LOIHI vs CPU COMPARISON\")\n",
    "print(\"=\"*50)\n",
    "print(f\" Speedup: {comparison['speedup']:.2f}x\")\n",
    "print(f\" Power Efficiency: {comparison['power_efficiency']:.2f}x\")\n",
    "print(f\" Energy Efficiency: {comparison['energy_efficiency']:.2f}x\")\n",
    "print(f\"\\n Reduções:\")\n",
    "print(f\" - Latência: {comparison['latency_reduction_percent']:.1f}%\")\n",
    "print(f\" - Potência: {comparison['power_reduction_percent']:.1f}%\")\n",
    "print(f\" - Energia: {comparison['energy_reduction_percent']:.1f}%\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d25e024",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar DataFrame comparativo\n",
    "comparison_df = pd.DataFrame({\n",
    " 'Métrica': ['Latência (ms)', 'Throughput (TPS)', 'Potência (mW)', 'Energia (mJ)'],\n",
    " 'CPU': [\n",
    " cpu_metrics['mean_latency_ms'],\n",
    " cpu_metrics['throughput_fps'],\n",
    " cpu_power_w * 1000, # 65W em mW\n",
    " (cpu_power_w * 1000 * cpu_metrics['mean_latency_ms']) / 1000 # mJ\n",
    " ],\n",
    " 'Loihi 2': [\n",
    " loihi_metrics.latency_ms,\n",
    " loihi_metrics.throughput_fps,\n",
    " loihi_metrics.power_mw,\n",
    " loihi_metrics.energy_mj\n",
    " ]\n",
    "})\n",
    "\n",
    "comparison_df['Improvement'] = comparison_df['CPU'] / comparison_df['Loihi 2']\n",
    "comparison_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c0c983",
   "metadata": {},
   "source": [
    "## 4. Visualizações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff257c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot 1: Comparação de Latência\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Latência\n",
    "ax1 = axes[0, 0]\n",
    "latencies = [cpu_metrics['mean_latency_ms'], loihi_metrics.latency_ms]\n",
    "labels = ['CPU', 'Loihi 2']\n",
    "colors = ['#FF6B6B', '#4ECDC4']\n",
    "ax1.bar(labels, latencies, color=colors, alpha=0.8, edgecolor='black')\n",
    "ax1.set_ylabel('Latência (ms)', fontsize=12)\n",
    "ax1.set_title('Latência por Inferência', fontsize=14, fontweight='bold')\n",
    "ax1.grid(axis='y', alpha=0.3)\n",
    "for i, v in enumerate(latencies):\n",
    " ax1.text(i, v + 0.5, f'{v:.2f}ms', ha='center', fontweight='bold')\n",
    "\n",
    "# Throughput\n",
    "ax2 = axes[0, 1]\n",
    "throughputs = [cpu_metrics['throughput_fps'], loihi_metrics.throughput_fps]\n",
    "ax2.bar(labels, throughputs, color=colors, alpha=0.8, edgecolor='black')\n",
    "ax2.set_ylabel('Throughput (TPS)', fontsize=12)\n",
    "ax2.set_title('Throughput (Transações/Segundo)', fontsize=14, fontweight='bold')\n",
    "ax2.grid(axis='y', alpha=0.3)\n",
    "for i, v in enumerate(throughputs):\n",
    " ax2.text(i, v + 5, f'{v:.1f}', ha='center', fontweight='bold')\n",
    "\n",
    "# Potência\n",
    "ax3 = axes[1, 0]\n",
    "powers = [cpu_power_w * 1000, loihi_metrics.power_mw]\n",
    "ax3.bar(labels, powers, color=colors, alpha=0.8, edgecolor='black')\n",
    "ax3.set_ylabel('Potência (mW)', fontsize=12)\n",
    "ax3.set_title('Consumo de Potência', fontsize=14, fontweight='bold')\n",
    "ax3.set_yscale('log')\n",
    "ax3.grid(axis='y', alpha=0.3)\n",
    "for i, v in enumerate(powers):\n",
    " ax3.text(i, v * 1.2, f'{v:.0f}mW', ha='center', fontweight='bold')\n",
    "\n",
    "# Energia por inferência\n",
    "ax4 = axes[1, 1]\n",
    "cpu_energy = (cpu_power_w * 1000 * cpu_metrics['mean_latency_ms']) / 1000\n",
    "energies = [cpu_energy, loihi_metrics.energy_mj / num_samples]\n",
    "ax4.bar(labels, energies, color=colors, alpha=0.8, edgecolor='black')\n",
    "ax4.set_ylabel('Energia (mJ)', fontsize=12)\n",
    "ax4.set_title('Energia por Inferência', fontsize=14, fontweight='bold')\n",
    "ax4.set_yscale('log')\n",
    "ax4.grid(axis='y', alpha=0.3)\n",
    "for i, v in enumerate(energies):\n",
    " ax4.text(i, v * 1.5, f'{v:.2f}mJ', ha='center', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('hardware_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n Gráficos salvos em 'hardware_comparison.png'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7b4b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot 2: Efficiency Gains\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "metrics_names = ['Speedup', 'Power\\nEfficiency', 'Energy\\nEfficiency']\n",
    "improvements = [\n",
    " comparison['speedup'],\n",
    " comparison['power_efficiency'],\n",
    " comparison['energy_efficiency']\n",
    "]\n",
    "\n",
    "bars = ax.barh(metrics_names, improvements, color='#4ECDC4', alpha=0.8, edgecolor='black')\n",
    "ax.set_xlabel('Fator de Melhoria (X vezes melhor)', fontsize=12)\n",
    "ax.set_title('Loihi 2 Efficiency Gains vs CPU', fontsize=14, fontweight='bold')\n",
    "ax.axvline(x=1, color='red', linestyle='--', linewidth=2, label='Baseline CPU')\n",
    "ax.grid(axis='x', alpha=0.3)\n",
    "ax.legend(fontsize=10)\n",
    "\n",
    "for i, (bar, val) in enumerate(zip(bars, improvements)):\n",
    " ax.text(val + 50, i, f'{val:.1f}x', va='center', fontweight='bold', fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('efficiency_gains.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\" Gráficos salvos em 'efficiency_gains.png'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4566fba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot 3: Distribuição de Latências CPU\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "ax.hist(latencies_cpu, bins=50, color='#FF6B6B', alpha=0.7, edgecolor='black')\n",
    "ax.axvline(cpu_metrics['mean_latency_ms'], color='red', linestyle='--', \n",
    " linewidth=2, label=f\"Média: {cpu_metrics['mean_latency_ms']:.2f}ms\")\n",
    "ax.axvline(cpu_metrics['median_latency_ms'], color='orange', linestyle='--', \n",
    " linewidth=2, label=f\"Mediana: {cpu_metrics['median_latency_ms']:.2f}ms\")\n",
    "ax.axvline(loihi_metrics.latency_ms, color='green', linestyle='-', \n",
    " linewidth=3, label=f\"Loihi: {loihi_metrics.latency_ms:.2f}ms\")\n",
    "\n",
    "ax.set_xlabel('Latência (ms)', fontsize=12)\n",
    "ax.set_ylabel('Frequência', fontsize=12)\n",
    "ax.set_title('Distribuição de Latências - CPU vs Loihi 2', fontsize=14, fontweight='bold')\n",
    "ax.legend(fontsize=11)\n",
    "ax.grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('latency_distribution.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\" Gráficos salvos em 'latency_distribution.png'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f057f26",
   "metadata": {},
   "source": [
    "## 5. Análise de Escalabilidade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02daaadd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simular diferentes volumes de transações\n",
    "print(\" Analisando escalabilidade...\\n\")\n",
    "\n",
    "volumes = [100, 500, 1000, 5000, 10000, 50000]\n",
    "scalability_results = []\n",
    "\n",
    "for vol in tqdm(volumes, desc=\"Volumes\"):\n",
    " # CPU: latência cresce linearmente\n",
    " cpu_total_time_s = (cpu_metrics['mean_latency_ms'] * vol) / 1000\n",
    " cpu_total_energy_mj = (cpu_power_w * 1000 * cpu_total_time_s)\n",
    " \n",
    " # Loihi: escalabilidade muito melhor\n",
    " loihi_sim = loihi.benchmark_inference(\n",
    " network_neurons=network_neurons,\n",
    " network_synapses=network_synapses,\n",
    " num_inferences=vol,\n",
    " simulation_time_ms=100.0\n",
    " )\n",
    " loihi_total_time_s = (loihi_sim.latency_ms * vol) / 1000\n",
    " \n",
    " scalability_results.append({\n",
    " 'volume': vol,\n",
    " 'cpu_time_s': cpu_total_time_s,\n",
    " 'loihi_time_s': loihi_total_time_s,\n",
    " 'cpu_energy_mj': cpu_total_energy_mj,\n",
    " 'loihi_energy_mj': loihi_sim.energy_mj,\n",
    " 'speedup': cpu_total_time_s / loihi_total_time_s\n",
    " })\n",
    "\n",
    "scalability_df = pd.DataFrame(scalability_results)\n",
    "scalability_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b71f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot de escalabilidade\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Tempo de execução\n",
    "ax1 = axes[0]\n",
    "ax1.plot(scalability_df['volume'], scalability_df['cpu_time_s'], \n",
    " marker='o', linewidth=2, markersize=8, label='CPU', color='#FF6B6B')\n",
    "ax1.plot(scalability_df['volume'], scalability_df['loihi_time_s'], \n",
    " marker='s', linewidth=2, markersize=8, label='Loihi 2', color='#4ECDC4')\n",
    "ax1.set_xlabel('Volume de Transações', fontsize=12)\n",
    "ax1.set_ylabel('Tempo Total (s)', fontsize=12)\n",
    "ax1.set_title('Escalabilidade: Tempo de Execução', fontsize=14, fontweight='bold')\n",
    "ax1.set_xscale('log')\n",
    "ax1.set_yscale('log')\n",
    "ax1.legend(fontsize=11)\n",
    "ax1.grid(alpha=0.3)\n",
    "\n",
    "# Energia consumida\n",
    "ax2 = axes[1]\n",
    "ax2.plot(scalability_df['volume'], scalability_df['cpu_energy_mj'], \n",
    " marker='o', linewidth=2, markersize=8, label='CPU', color='#FF6B6B')\n",
    "ax2.plot(scalability_df['volume'], scalability_df['loihi_energy_mj'], \n",
    " marker='s', linewidth=2, markersize=8, label='Loihi 2', color='#4ECDC4')\n",
    "ax2.set_xlabel('Volume de Transações', fontsize=12)\n",
    "ax2.set_ylabel('Energia Total (mJ)', fontsize=12)\n",
    "ax2.set_title('Escalabilidade: Consumo de Energia', fontsize=14, fontweight='bold')\n",
    "ax2.set_xscale('log')\n",
    "ax2.set_yscale('log')\n",
    "ax2.legend(fontsize=11)\n",
    "ax2.grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('scalability_analysis.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\" Gráficos salvos em 'scalability_analysis.png'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c85d905e",
   "metadata": {},
   "source": [
    "## 6. Conclusões e Recomendações\n",
    "\n",
    "### Principais Resultados\n",
    "\n",
    "Com base nos benchmarks realizados:\n",
    "\n",
    "**Performance:**\n",
    "- Loihi 2 oferece **speedup significativo** em latência\n",
    "- Throughput muito superior para processamento paralelo\n",
    "- Latência consistente e previsível (event-driven)\n",
    "\n",
    "**Eficiência Energética:**\n",
    "- **Redução drástica** no consumo de energia (1000x+)\n",
    "- Ideal para edge computing e dispositivos móveis\n",
    "- Operação contínua viável com bateria\n",
    "\n",
    "**Escalabilidade:**\n",
    "- Vantagem do Loihi aumenta com volume de transações\n",
    "- Processamento paralelo nativo\n",
    "- Multi-chip para aplicações muito grandes\n",
    "\n",
    "### Recomendações de Deployment\n",
    "\n",
    "#### Use **CPU/GPU** quando:\n",
    "- Volume baixo de transações (< 1000/s)\n",
    "- Prototipagem e desenvolvimento\n",
    "- Flexibilidade de código é prioritária\n",
    "- Infraestrutura existente disponível\n",
    "\n",
    "#### Use **Loihi 2** quando:\n",
    "- Alto volume de transações (> 10000/s)\n",
    "- Eficiência energética é crítica\n",
    "- Edge computing / dispositivos móveis\n",
    "- Latência ultra-baixa é requisito\n",
    "- Operação 24/7 com restrições de energia\n",
    "\n",
    "### Próximos Passos\n",
    "\n",
    "1. **Implementação real em Loihi**: Migrar de Brian2 para Lava\n",
    "2. **Otimização de arquitetura**: Ajustar para maximizar eficiência do Loihi\n",
    "3. **Testes em produção**: Validar com tráfego real\n",
    "4. **Custo-benefício**: Análise de TCO (Total Cost of Ownership)\n",
    "5. **Comparação com outros chips**: TrueNorth, SpiNNaker, BrainScaleS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b709f22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvar resultados em CSV\n",
    "comparison_df.to_csv('hardware_benchmark_results.csv', index=False)\n",
    "scalability_df.to_csv('scalability_results.csv', index=False)\n",
    "\n",
    "print(\"\\n Resultados salvos:\")\n",
    "print(\" - hardware_benchmark_results.csv\")\n",
    "print(\" - scalability_results.csv\")\n",
    "print(\" - hardware_comparison.png\")\n",
    "print(\" - efficiency_gains.png\")\n",
    "print(\" - latency_distribution.png\")\n",
    "print(\" - scalability_analysis.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
