{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38942fd1",
   "metadata": {},
   "source": [
    "## ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã¨ã‚¤ãƒ³ãƒãƒ¼ãƒˆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba5467f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# srcã‚’ãƒ‘ã‚¹ã«è¿½åŠ \n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚¤ãƒ³ãƒãƒ¼ãƒˆç”¨ã«srcãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’Pythonãƒ‘ã‚¹ã«è¿½åŠ \n",
    "src_path = Path.cwd().parent / 'src'\n",
    "if str(src_path) not in sys.path:\n",
    " sys.path.insert(0, str(src_path))\n",
    "\n",
    "# ã‚³ã‚¢ã‚¤ãƒ³ãƒãƒ¼ãƒˆ\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import display, Markdown\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# ã‚¹ã‚¿ã‚¤ãƒ«ã‚’è¨­å®š\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "# ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ç”¨ã®tqdmã‚’è¨­å®š\n",
    "tqdm.pandas()\n",
    "\n",
    "print(\"âœ“ ã‚¤ãƒ³ãƒãƒ¼ãƒˆå®Œäº†\")\n",
    "print(f\"PyTorchãƒãƒ¼ã‚¸ãƒ§ãƒ³: {torch.__version__}\")\n",
    "print(f\"CUDAåˆ©ç”¨å¯èƒ½: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4edf31ba",
   "metadata": {},
   "source": [
    "### CUDAè¨ºæ–­"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f45550",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CUDAäº’æ›æ€§ãƒã‚§ãƒƒã‚¯\n",
    "import warnings\n",
    "\n",
    "if torch.cuda.is_available():\n",
    " print(\"âœ… GPUæ¤œå‡º\\n\")\n",
    " print(f\"GPUå: {torch.cuda.get_device_name(0)}\")\n",
    " print(f\"CUDAãƒãƒ¼ã‚¸ãƒ§ãƒ³ï¼ˆPyTorchï¼‰: {torch.version.cuda}\") # type: ignore\n",
    " print(f\"cuDNNãƒãƒ¼ã‚¸ãƒ§ãƒ³: {torch.backends.cudnn.version()}\")\n",
    " print(f\"GPUæ•°: {torch.cuda.device_count()}\")\n",
    " \n",
    " # GPUã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ãƒˆèƒ½åŠ›ã‚’å–å¾—\n",
    " gpu_capability = torch.cuda.get_device_capability(0)\n",
    " gpu_capability_str = f\"sm_{gpu_capability[0]}{gpu_capability[1]}\"\n",
    " print(f\"GPUã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ãƒˆèƒ½åŠ›: {gpu_capability_str} ({gpu_capability[0]}.{gpu_capability[1]})\")\n",
    " \n",
    " # PyTorchã‚µãƒãƒ¼ãƒˆã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’ç¢ºèª\n",
    " # PyTorch 2.3.1+cu118ã¯sm_60ä»¥ä¸Šã‚’ã‚µãƒãƒ¼ãƒˆï¼ˆGTX 1060 sm_61ã‚’å«ã‚€ï¼‰\n",
    " min_supported_capability = 6.0\n",
    " current_capability = float(f\"{gpu_capability[0]}.{gpu_capability[1]}\")\n",
    " \n",
    " print(f\"\\næœ€å°PyTorchèƒ½åŠ›: sm_60 (6.0)\")\n",
    " print(f\"ã‚ãªãŸã®GPUèƒ½åŠ›: {gpu_capability_str} ({current_capability})\")\n",
    " \n",
    " if current_capability >= min_supported_capability:\n",
    "     print(\"\\nâœ… GPUäº’æ›æ€§ã‚ã‚Š!\")\n",
    "     print(\"=\"*60)\n",
    "     print(f\"ã‚ãªãŸã®GPUï¼ˆ{torch.cuda.get_device_name(0)}ï¼‰ã¯\")\n",
    "     print(f\"PyTorch {torch.__version__}ã¨äº’æ›æ€§ãŒã‚ã‚Šã¾ã™\")\n",
    "     print(f\"CUDAã‚¢ã‚¯ã‚»ãƒ©ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³: æœ‰åŠ¹ âš¡\")\n",
    " else:\n",
    "     print(\"\\nâš ï¸ äº’æ›æ€§è­¦å‘Š âš ï¸\")\n",
    "     print(\"=\"*60)\n",
    "     print(f\"ã‚ãªãŸã®GPUï¼ˆ{torch.cuda.get_device_name(0)}ï¼‰ã®\")\n",
    "     print(f\"ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ãƒˆèƒ½åŠ›ã¯{current_capability}ã§ã™ãŒã€PyTorch {torch.__version__}ã¯\")\n",
    "     print(f\"èƒ½åŠ›{min_supported_capability}ä»¥ä¸Šã‚’å¿…è¦ã¨ã—ã¾ã™ã€‚\")\n",
    "     print(\"\\nğŸ“‹ æ¨å¥¨äº‹é …:\")\n",
    "     print(\"  1. CPUã‚’ä½¿ç”¨ï¼ˆã‚ˆã‚Šå®‰å®šã€è­¦å‘Šãªã—ï¼‰\")\n",
    "     print(\"  2. NVIDIAãƒ‰ãƒ©ã‚¤ãƒãƒ¼ã‚’æ›´æ–°\")\n",
    "else:\n",
    " print(\"ğŸ’» CPUãƒ¢ãƒ¼ãƒ‰\")\n",
    " print(\"CUDAãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚è¨ˆç®—ã«CPUã‚’ä½¿ç”¨ã—ã¾ã™ã€‚\")\n",
    " print(\"ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã¯ä½ä¸‹ã—ã¾ã™ãŒã€å®Œå…¨ã«æ©Ÿèƒ½ã—ã¾ã™ã€‚\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac3a8c4e",
   "metadata": {},
   "source": [
    "### ãƒ‡ãƒã‚¤ã‚¹è¨­å®š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9468ce78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# äº’æ›æ€§ã®ãªã„GPUã§ãƒ©ãƒ³ã‚¿ã‚¤ãƒ ã‚¨ãƒ©ãƒ¼ã‚’å›é¿ã™ã‚‹ãŸã‚CPUãƒ¢ãƒ¼ãƒ‰ã‚’å¼·åˆ¶\n",
    "import os\n",
    "\n",
    "if torch.cuda.is_available():\n",
    " gpu_capability = torch.cuda.get_device_capability(0)\n",
    " current_capability = float(f\"{gpu_capability[0]}.{gpu_capability[1]}\")\n",
    " \n",
    " if current_capability < 6.0:\n",
    "     # äº’æ›æ€§ã®ãªã„GPUã§ã®ãƒ¡ãƒ¢ãƒªå‰²ã‚Šå½“ã¦ã‚’é˜²ããŸã‚CUDAã‚’å®Œå…¨ã«ç„¡åŠ¹åŒ–\n",
    "     print(\"âš ï¸ äº’æ›æ€§ã®ãªã„GPUç”¨ã«CUDAã‚’ç„¡åŠ¹åŒ–ä¸­...\")\n",
    "     os.environ['CUDA_VISIBLE_DEVICES'] = ''\n",
    "     \n",
    "     # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã•ã‚ŒãŸCUDAçŠ¶æ…‹ã‚’ã‚¯ãƒªã‚¢\n",
    "     if torch.cuda.is_available(): # ç’°å¢ƒå¤‰æ›´å¾Œã«å†ç¢ºèª\n",
    "         torch.cuda.empty_cache()\n",
    "     \n",
    "     print(\"âœ… CUDAã‚’ç„¡åŠ¹åŒ–ã€‚ã™ã¹ã¦ã®ãƒ†ãƒ³ã‚½ãƒ«ã¯CPUã‚’ä½¿ç”¨ã—ã¾ã™ã€‚\")\n",
    "     print(f\"ğŸ“Š GPUãƒ¡ãƒ¢ãƒªè§£æ”¾å®Œäº†ã€‚\")\n",
    " else:\n",
    "     print(\"âœ… GPUä½¿ç”¨å¯èƒ½!\")\n",
    "     print(f\"ğŸš€ ãƒ‡ãƒã‚¤ã‚¹: {torch.cuda.get_device_name(0)}\")\n",
    "     print(f\"ğŸ’¾ GPUåˆ©ç”¨å¯èƒ½ãƒ¡ãƒ¢ãƒª: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f}GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c40cf26",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. Brian2 â†’ PyTorch SNNã¸ã®ç§»è¡Œ\n",
    "\n",
    "### å•é¡Œ\n",
    "- Brian2: 100msãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ã€10 TPSã€CPUã®ã¿\n",
    "- æœ¬ç•ªç’°å¢ƒã®é‡å¤§ãªãƒœãƒˆãƒ«ãƒãƒƒã‚¯\n",
    "\n",
    "### ã‚½ãƒªãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³\n",
    "- PyTorch + snnTorchï¼ˆCPU/GPUï¼‰\n",
    "- ãƒã‚¤ãƒ†ã‚£ãƒ–ãƒãƒƒãƒæ¨è«–\n",
    "- **6.7å€**é«˜é€Ÿã€**80å€**ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆï¼ˆäº’æ›æ€§ã®ã‚ã‚‹GPUã§ï¼‰\n",
    "\n",
    "**æ³¨æ„**: GPUã‚¢ã‚¯ã‚»ãƒ©ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã«ã¯CUDAã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ãƒˆèƒ½åŠ› â‰¥ 6.0ãŒå¿…è¦ï¼ˆGTX 1060+ã€Tesla P100+ï¼‰ã€‚\n",
    "GTX 10xxã‚·ãƒªãƒ¼ã‚ºä»¥ä¸Šã¨äº’æ›æ€§ãŒã‚ã‚Šã¾ã™! âš¡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeed3edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models_snn_pytorch import FraudSNNPyTorch, BatchInferenceEngine # type: ignore\n",
    "\n",
    "# ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ãƒˆèƒ½åŠ›ãƒã‚§ãƒƒã‚¯ä»˜ããƒ‡ãƒã‚¤ã‚¹é¸æŠ\n",
    "if torch.cuda.is_available():\n",
    " gpu_capability = torch.cuda.get_device_capability(0)\n",
    " current_capability = float(f\"{gpu_capability[0]}.{gpu_capability[1]}\")\n",
    " \n",
    " # PyTorch 2.3.1+cu118ã¯sm_60ï¼ˆ6.0ï¼‰ä»¥ä¸Šã‚’ã‚µãƒãƒ¼ãƒˆ\n",
    " if current_capability >= 6.0:\n",
    "     device = 'cuda'\n",
    "     print(f\"\\nğŸš€ ãƒ‡ãƒã‚¤ã‚¹ã‚’ä½¿ç”¨: {device}\")\n",
    "     print(f\"âš¡ GPU: {torch.cuda.get_device_name(0)}\")\n",
    "     print(f\"ğŸ’¾ VRAM: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f}GB\")\n",
    " else:\n",
    "     print(f\"âš ï¸ GPUã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ãƒˆèƒ½åŠ›{current_capability} < 6.0ï¼ˆéäº’æ›ï¼‰\")\n",
    "     print(f\"ğŸ’» CPUãƒ¢ãƒ¼ãƒ‰ã‚’å¼·åˆ¶\")\n",
    "     device = 'cpu'\n",
    "else:\n",
    " device = 'cpu'\n",
    " print(f\"\\nğŸ’» ãƒ‡ãƒã‚¤ã‚¹ã‚’ä½¿ç”¨: {device}\")\n",
    "\n",
    "model = FraudSNNPyTorch(\n",
    " input_size=256,\n",
    " hidden_sizes=[128, 64],\n",
    " output_size=2,\n",
    " device=device\n",
    ")\n",
    "\n",
    "print(\"\\nğŸ“Š ãƒ¢ãƒ‡ãƒ«çµ±è¨ˆ:\")\n",
    "stats = model.get_stats()\n",
    "for key, value in stats.items():\n",
    " print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69da950a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ¨è«–ã‚’ãƒ†ã‚¹ãƒˆ\n",
    "print(\"ğŸ§ª æ¨è«–ãƒ†ã‚¹ãƒˆä¸­...\\n\")\n",
    "\n",
    "# å˜ä¸€ãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³\n",
    "test_input = torch.randn(1, 256).to(device)\n",
    "\n",
    "import time\n",
    "start = time.time()\n",
    "prediction = model.predict(test_input)\n",
    "latency = (time.time() - start) * 1000\n",
    "\n",
    "proba = model.predict_proba(test_input)\n",
    "\n",
    "print(f\"äºˆæ¸¬: {'ä¸æ­£' if prediction.item() == 1 else 'æ­£å¸¸'}\")\n",
    "print(f\"ç¢ºç‡: æ­£å¸¸={proba[0,0]:.4f}, ä¸æ­£={proba[0,1]:.4f}\")\n",
    "print(f\"ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·: {latency:.2f}ms\")\n",
    "\n",
    "# ãƒãƒƒãƒæ¨è«–\n",
    "print(\"\\nğŸ”„ ãƒãƒƒãƒæ¨è«–ï¼ˆ32ãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³ï¼‰:\")\n",
    "batch_input = torch.randn(32, 256).to(device)\n",
    "\n",
    "start = time.time()\n",
    "batch_predictions = model.predict(batch_input)\n",
    "batch_latency = (time.time() - start) * 1000\n",
    "\n",
    "print(f\"ãƒãƒƒãƒãƒ¬ã‚¤ãƒ†ãƒ³ã‚·: {batch_latency:.2f}ms\")\n",
    "print(f\"ãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³ã‚ãŸã‚Šãƒ¬ã‚¤ãƒ†ãƒ³ã‚·: {batch_latency/32:.2f}ms\")\n",
    "print(f\"ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆ: {32/(batch_latency/1000):.0f} TPS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72942452",
   "metadata": {},
   "source": [
    "### ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯: PyTorch vs Brian2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31bdec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ›´æ–°ã•ã‚ŒãŸé–¢æ•°ã‚·ã‚°ãƒãƒãƒ£ã‚’å–å¾—ã™ã‚‹ãŸã‚ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ãƒªãƒ­ãƒ¼ãƒ‰\n",
    "import importlib\n",
    "import models_snn_pytorch\n",
    "importlib.reload(models_snn_pytorch)\n",
    "from models_snn_pytorch import benchmark_pytorch_vs_brian2 # type: ignore\n",
    "\n",
    "# åŒ…æ‹¬çš„ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚’å®Ÿè¡Œï¼ˆãƒ¢ãƒ‡ãƒ«ã¨åŒã˜ãƒ‡ãƒã‚¤ã‚¹ã‚’ä½¿ç”¨ï¼‰\n",
    "benchmark_pytorch_vs_brian2(device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f9d7824",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. å®Ÿéš›ã®Kaggleãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ\n",
    "\n",
    "### å•é¡Œ\n",
    "- 1,000åˆæˆã‚µãƒ³ãƒ—ãƒ« vs 41,088ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆ41:1æ¯”ç‡ï¼‰\n",
    "- æ·±åˆ»ãªéå­¦ç¿’\n",
    "\n",
    "### ã‚½ãƒªãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³\n",
    "- IEEE-CISä¸æ­£æ¤œå‡ºãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆï¼ˆKaggleï¼‰\n",
    "- **590,540ã®å®Ÿéš›ã®ãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³**\n",
    "- å®Œå…¨ãªç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288bc0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# æœ€æ–°ã®æœ€é©åŒ–ã‚’å–å¾—ã™ã‚‹ãŸã‚ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ãƒªãƒ­ãƒ¼ãƒ‰\n",
    "import importlib\n",
    "import dataset_kaggle\n",
    "importlib.reload(dataset_kaggle)\n",
    "from dataset_kaggle import prepare_fraud_dataset, KaggleDatasetDownloader # type: ignore\n",
    "\n",
    "# ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãŒå­˜åœ¨ã™ã‚‹ã‹ç¢ºèª\n",
    "data_dir = Path.cwd().parent / 'data' / 'kaggle'\n",
    "downloader = KaggleDatasetDownloader(data_dir)\n",
    "\n",
    "if not downloader.check_files():\n",
    " print(\"âš ï¸ Kaggleãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“!\")\n",
    " print(\"\\nğŸ“¥ ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰æ‰‹é †:\")\n",
    " print(\"1. pip install kaggle\")\n",
    " print(\"2. kaggle.com â†’ ã‚¢ã‚«ã‚¦ãƒ³ãƒˆ â†’ æ–°ã—ã„APIãƒˆãƒ¼ã‚¯ãƒ³ã‚’ä½œæˆ\")\n",
    " print(\"3. kaggle.jsonã‚’~/.kaggle/ã«ç§»å‹•\")\n",
    " print(\"4. chmod 600 ~/.kaggle/kaggle.json\")\n",
    " print(\"5. å®Ÿè¡Œ: downloader.download()\")\n",
    " print(\"\\nã¾ãŸã¯æ‰‹å‹•ã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰:\")\n",
    " print(\"https://www.kaggle.com/c/ieee-fraud-detection/data\")\n",
    "else:\n",
    " print(\"âœ… Kaggleãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæ¤œå‡º!\")\n",
    " print(\"\\nğŸ“Š ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’æº–å‚™ä¸­...\")\n",
    " \n",
    " # GPUã‚µãƒãƒ¼ãƒˆã¨ä¸¦åˆ—ãƒ¯ãƒ¼ã‚«ãƒ¼ã«ã‚ˆã‚‹æœ€é©åŒ–ã•ã‚ŒãŸãƒ­ãƒ¼ãƒ‰\n",
    " # - ã‚­ãƒ£ãƒƒã‚·ãƒ¥: 2å›ç›®ã®å®Ÿè¡Œã¯10-20å€é«˜é€Ÿ\n",
    " # - GPU pin_memory: CPUâ†’GPUè»¢é€ã‚’åŠ é€Ÿ\n",
    " # - ä¸¦åˆ—ãƒ¯ãƒ¼ã‚«ãƒ¼: è¤‡æ•°ã®CPUã‚³ã‚¢ã‚’ä½¿ç”¨\n",
    " # - ã‚ˆã‚Šå¤§ããªval/testãƒãƒƒãƒ: ãƒãƒƒã‚¯ãƒ—ãƒ­ãƒ‘ã‚²ãƒ¼ã‚·ãƒ§ãƒ³ãªã— = ã‚ˆã‚Šé«˜ã„ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆ\n",
    " dataset_dict = prepare_fraud_dataset(\n",
    "     data_dir=data_dir,\n",
    "     target_features=64,\n",
    "     batch_size=32,\n",
    "     use_gpu=True,  # GPUåˆ©ç”¨å¯èƒ½ãªå ´åˆpin_memoryã‚’æœ‰åŠ¹åŒ–\n",
    "     num_workers=None  # CPUã‚’è‡ªå‹•æ¤œå‡ºï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: min(8, cpu_count)ï¼‰\n",
    " )\n",
    " \n",
    " print(\"\\nâœ… ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæº–å‚™å®Œäº†!\")\n",
    " print(f\"ğŸ“Š è¨“ç·´ãƒãƒƒãƒ: {len(dataset_dict['train'])}\")\n",
    " print(f\"ğŸ“Š æ¤œè¨¼ãƒãƒƒãƒ: {len(dataset_dict['val'])}\")\n",
    " print(f\"ğŸ“Š ãƒ†ã‚¹ãƒˆãƒãƒƒãƒ: {len(dataset_dict['test'])}\")\n",
    " print(f\"\\nğŸ’¡ ãƒ’ãƒ³ãƒˆ: 2å›ç›®ã®å®Ÿè¡Œã§ã¯ã€ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãŒä½¿ç”¨ã•ã‚Œã¾ã™ï¼ˆ10-20å€é«˜é€Ÿï¼‰!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a8c459",
   "metadata": {},
   "source": [
    "### âš¡ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–\n",
    "\n",
    "ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ãƒ­ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã¯ä»¥ä¸‹ã®æŠ€è¡“ã§æœ€é©åŒ–ã•ã‚Œã¦ã„ã¾ã™:\n",
    "\n",
    "**1. è‡ªå‹•ã‚­ãƒ£ãƒƒã‚·ãƒ¥ï¼ˆjoblibï¼‰**\n",
    "- 1å›ç›®ã®å®Ÿè¡Œ: CSVã‚’ãƒ­ãƒ¼ãƒ‰ã—ã¦å‡¦ç†ï¼ˆç´„5-10åˆ†ï¼‰\n",
    "- 2å›ç›®ä»¥é™ã®å®Ÿè¡Œ: ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰ãƒ­ãƒ¼ãƒ‰ï¼ˆç´„30-60ç§’ï¼‰\n",
    "- **ã‚¹ãƒ”ãƒ¼ãƒ‰ã‚¢ãƒƒãƒ—: 10-20å€é«˜é€Ÿ**\n",
    "\n",
    "**2. æœ€é©åŒ–ã•ã‚ŒãŸCSVã‚¨ãƒ³ã‚¸ãƒ³**\n",
    "- `engine='c'`ã‚’ä½¿ç”¨ï¼ˆpandas Cãƒ‘ãƒ¼ã‚µãƒ¼ï¼‰\n",
    "- Pythonãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ‘ãƒ¼ã‚µãƒ¼ã‚ˆã‚Šé«˜é€Ÿ\n",
    "\n",
    "**3. GPUã‚¢ã‚¯ã‚»ãƒ©ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³**\n",
    "- `pin_memory=True`: ãƒ”ãƒ³ç•™ã‚ãƒ¡ãƒ¢ãƒªã«ãƒ†ãƒ³ã‚½ãƒ«ã‚’å‰²ã‚Šå½“ã¦\n",
    "- CPUâ†’GPUè»¢é€ãŒ**æœ€å¤§2å€é«˜é€Ÿ**\n",
    "- `torch.cuda.is_available()`ã®å ´åˆã«è‡ªå‹•\n",
    "\n",
    "**4. ä¸¦åˆ—DataLoaderãƒ¯ãƒ¼ã‚«ãƒ¼**\n",
    "- CPUã‚³ã‚¢ã‚’è‡ªå‹•æ¤œå‡ºï¼ˆã‚ãªãŸã®ã‚·ã‚¹ãƒ†ãƒ : **8ã‚³ã‚¢**ï¼‰\n",
    "- `num_workers=8`: ãƒãƒƒãƒã‚’ä¸¦åˆ—ã§ãƒ­ãƒ¼ãƒ‰\n",
    "- `persistent_workers=True`: ãƒ¯ãƒ¼ã‚«ãƒ¼ã‚’å†åˆ©ç”¨ï¼ˆã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰å‰Šæ¸›ï¼‰\n",
    "- `prefetch_factor=2`: GPUè¨ˆç®—ä¸­ã«æ¬¡ã®ãƒãƒƒãƒã‚’ãƒ­ãƒ¼ãƒ‰\n",
    "\n",
    "**5. æœ€é©åŒ–ã•ã‚ŒãŸãƒãƒƒãƒã‚µã‚¤ã‚º**\n",
    "- è¨“ç·´: `batch_size=32`ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼‰\n",
    "- Val/Test: `batch_size=64`ï¼ˆ**2å€å¤§ãã„**ï¼‰\n",
    "- ç†ç”±: æ¤œè¨¼/ãƒ†ã‚¹ãƒˆã¯ãƒãƒƒã‚¯ãƒ—ãƒ­ãƒ‘ã‚²ãƒ¼ã‚·ãƒ§ãƒ³ä¸è¦\n",
    "\n",
    "**æœŸå¾…ã•ã‚Œã‚‹çµæœ:**\n",
    "- 1å›ç›®ã®å®Ÿè¡Œ: ç´„5-10åˆ†\n",
    "- 2å›ç›®ä»¥é™ã®å®Ÿè¡Œ: ç´„30-60ç§’ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ï¼‰\n",
    "- è¨“ç·´ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆ: **ç´„800ã‚µãƒ³ãƒ—ãƒ«/ç§’**ï¼ˆGPUã§ï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b295546b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ãƒ‡ãƒ¢: ç‰¹å¾´é‡é‡è¦åº¦ã‚’è¦–è¦šåŒ–ï¼ˆãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãŒãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¦ã„ã‚‹å ´åˆï¼‰\n",
    "try:\n",
    " preprocessor = dataset_dict['preprocessor']\n",
    " feature_importance = preprocessor.feature_importance # type: ignore\n",
    " \n",
    " # ãƒˆãƒƒãƒ—20ç‰¹å¾´é‡ã‚’ãƒ—ãƒ­ãƒƒãƒˆ\n",
    " plt.figure(figsize=(12, 8))\n",
    " top_features = feature_importance.head(20)\n",
    " plt.barh(range(len(top_features)), top_features['importance'])\n",
    " plt.yticks(range(len(top_features)), top_features['feature'])\n",
    " plt.xlabel('ç›¸äº’æƒ…å ±ã‚¹ã‚³ã‚¢')\n",
    " plt.title('ãƒˆãƒƒãƒ—20ã®æœ€é‡è¦ç‰¹å¾´é‡ï¼ˆKaggleãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆï¼‰')\n",
    " plt.gca().invert_yaxis()\n",
    " plt.tight_layout()\n",
    " plt.show()\n",
    " \n",
    " print(\"\\nğŸ“ˆ ãƒˆãƒƒãƒ—10ç‰¹å¾´é‡:\")\n",
    " display(top_features.head(10))\n",
    " \n",
    "except NameError:\n",
    " print(\"â­ ã‚¹ã‚­ãƒƒãƒ—ï¼ˆãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæœªãƒ­ãƒ¼ãƒ‰ï¼‰\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de28074",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. èª¬æ˜å¯èƒ½æ€§ï¼ˆLGPD/GDPRæº–æ‹ ï¼‰\n",
    "\n",
    "### å•é¡Œ\n",
    "- ãƒ–ãƒ©ãƒƒã‚¯ãƒœãƒƒã‚¯ã‚¹ãƒ¢ãƒ‡ãƒ«\n",
    "- LGPDç¬¬20æ¡éæº–æ‹ \n",
    "\n",
    "### ã‚½ãƒªãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³\n",
    "- SHAPï¼ˆSHapley Additive exPlanationsï¼‰\n",
    "- ã‚¢ãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³åˆ†æ\n",
    "- ã‚¹ãƒ‘ã‚¤ã‚¯ãƒ‘ã‚¿ãƒ¼ãƒ³è¦–è¦šåŒ–\n",
    "- åäº‹å®Ÿçš„èª¬æ˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e27cb74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from explainability import ExplainabilityEngine, SHAPExplainer, AblationExplainer # type: ignore\n",
    "\n",
    "# ãƒ‡ãƒ¢ç”¨ã®å°ã•ã„ãƒ¢ãƒ‡ãƒ«ã‚’ä½œæˆï¼ˆé«˜é€Ÿï¼‰\n",
    "demo_model = FraudSNNPyTorch(\n",
    " input_size=64,\n",
    " hidden_sizes=[32, 16],\n",
    " output_size=2,\n",
    " device=device\n",
    ")\n",
    "\n",
    "# SHAPç”¨ã®ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ\n",
    "background_data = torch.randn(100, 64).to(device)\n",
    "feature_names = [f\"ç‰¹å¾´é‡_{i}\" for i in range(64)]\n",
    "\n",
    "# èª¬æ˜å¯èƒ½æ€§ã‚¨ãƒ³ã‚¸ãƒ³ã‚’ä½œæˆ\n",
    "print(\"ğŸ” èª¬æ˜å¯èƒ½æ€§ã‚¨ãƒ³ã‚¸ãƒ³ã‚’ä½œæˆä¸­...\")\n",
    "explainer = ExplainabilityEngine(\n",
    " model=demo_model,\n",
    " background_data=background_data,\n",
    " feature_names=feature_names\n",
    ")\n",
    "\n",
    "print(\"âœ… èª¬æ˜å¯èƒ½æ€§ã‚¨ãƒ³ã‚¸ãƒ³æº–å‚™å®Œäº†!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75c42f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³ã®èª¬æ˜ã‚’ç”Ÿæˆ\n",
    "print(\"ğŸ“ èª¬æ˜ã‚’ç”Ÿæˆä¸­...\\n\")\n",
    "\n",
    "transaction = torch.randn(1, 64).to(device)\n",
    "explanation = explainer.explain_prediction(transaction, \"TXN_DEMO_12345\")\n",
    "\n",
    "# äººé–“ãŒèª­ã‚ã‚‹ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ\n",
    "report = explainer.generate_report(explanation)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5606f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç‰¹å¾´é‡é‡è¦åº¦ã‚’è¦–è¦šåŒ–\n",
    "print(\"ğŸ“Š ç‰¹å¾´é‡é‡è¦åº¦åˆ†æ\\n\")\n",
    "\n",
    "# ãƒˆãƒƒãƒ—ç‰¹å¾´é‡ã‚’å–å¾—\n",
    "top_features = dict(list(explanation.feature_importance.items())[:10])\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.barh(range(len(top_features)), list(top_features.values()))\n",
    "plt.yticks(range(len(top_features)), list(top_features.keys()))\n",
    "plt.xlabel('é‡è¦åº¦ã‚¹ã‚³ã‚¢ï¼ˆã‚¢ãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ï¼‰')\n",
    "plt.title('ãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³ã®ãƒˆãƒƒãƒ—10ç‰¹å¾´é‡é‡è¦åº¦')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32af5704",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ã‚¹ãƒ‘ã‚¤ã‚¯ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ\n",
    "from explainability import SpikePatternAnalyzer # type: ignore\n",
    "\n",
    "print(\"ğŸ”¥ ã‚¹ãƒ‘ã‚¤ã‚¯ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ\\n\")\n",
    "\n",
    "spike_analyzer = SpikePatternAnalyzer(demo_model)\n",
    "spike_pattern = spike_analyzer.analyze(transaction)\n",
    "\n",
    "print(f\"ç·ã‚¹ãƒ‘ã‚¤ã‚¯æ•°: {spike_pattern['total_spikes']}\")\n",
    "print(f\"ã‚¹ãƒ‘ã‚¤ã‚¯ç‡: {spike_pattern['spike_rate']:.4f}\")\n",
    "print(f\"å±¤ã”ã¨ã®ã‚¹ãƒ‘ã‚¤ã‚¯: {spike_pattern['spikes_per_layer']}\")\n",
    "print(f\"ãƒ›ãƒƒãƒˆã‚¹ãƒãƒƒãƒˆãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³: {spike_pattern['hotspot_neurons']}\")\n",
    "\n",
    "# è¦–è¦šåŒ–\n",
    "spike_analyzer.plot_pattern(transaction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8030152e",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–\n",
    "\n",
    "### å•é¡Œ\n",
    "- é«˜ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ï¼ˆ100msï¼‰\n",
    "- ä½ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆï¼ˆ10 TPSï¼‰\n",
    "- å¤§ãã„ãƒ¢ãƒ‡ãƒ«ï¼ˆFP32ï¼‰\n",
    "\n",
    "### ã‚½ãƒªãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³\n",
    "- INT8é‡å­åŒ–ï¼ˆ4å€å°ã•ã„ï¼‰\n",
    "- ãƒãƒƒãƒå‡¦ç†ï¼ˆ16å€ã‚¹ãƒ”ãƒ¼ãƒ‰ã‚¢ãƒƒãƒ—ï¼‰\n",
    "- çµæœã‚­ãƒ£ãƒƒã‚·ãƒ¥\n",
    "- ONNX Runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504fc415",
   "metadata": {},
   "outputs": [],
   "source": [
    "from performance_optimization import ( # type: ignore\n",
    " QuantizedModelWrapper,\n",
    " ResultCache,\n",
    " export_to_onnx\n",
    ")\n",
    "\n",
    "# ãƒ¢ãƒ‡ãƒ«é‡å­åŒ–\n",
    "print(\"âš™ï¸ ãƒ¢ãƒ‡ãƒ«é‡å­åŒ–ãƒ‡ãƒ¢\\n\")\n",
    "\n",
    "quantizer = QuantizedModelWrapper(demo_model)\n",
    "test_input = torch.randn(8, 64)\n",
    "\n",
    "results = quantizer.benchmark(test_input, iterations=100)\n",
    "\n",
    "print(f\"\\nğŸ“Š é‡å­åŒ–çµæœ:\")\n",
    "print(f\"  FP32ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·: {results['fp32_latency_ms']:.2f}ms\")\n",
    "print(f\"  INT8ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·: {results['int8_latency_ms']:.2f}ms\")\n",
    "print(f\"  ã‚¹ãƒ”ãƒ¼ãƒ‰ã‚¢ãƒƒãƒ—: {results['speedup']:.2f}å€\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63d6723",
   "metadata": {},
   "outputs": [],
   "source": [
    "# çµæœã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ‡ãƒ¢\n",
    "print(\"ğŸ’¾ çµæœã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ‡ãƒ¢\\n\")\n",
    "\n",
    "cache = ResultCache(max_size=1000, ttl_seconds=60)\n",
    "\n",
    "transaction = torch.randn(1, 64)\n",
    "\n",
    "# æœ€åˆã®ã‚¢ã‚¯ã‚»ã‚¹ï¼ˆãƒŸã‚¹ï¼‰\n",
    "result = cache.get(transaction)\n",
    "print(f\"æœ€åˆã®ã‚¢ã‚¯ã‚»ã‚¹: {'ãƒ’ãƒƒãƒˆ' if result is not None else 'ãƒŸã‚¹'}\")\n",
    "\n",
    "# çµæœã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥\n",
    "cache.put(transaction, 1)\n",
    "\n",
    "# 2å›ç›®ã®ã‚¢ã‚¯ã‚»ã‚¹ï¼ˆãƒ’ãƒƒãƒˆï¼‰\n",
    "result = cache.get(transaction)\n",
    "print(f\"2å›ç›®ã®ã‚¢ã‚¯ã‚»ã‚¹: {'ãƒ’ãƒƒãƒˆ' if result is not None else 'ãƒŸã‚¹'}\")\n",
    "\n",
    "# ç•°ãªã‚‹ãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³ï¼ˆãƒŸã‚¹ï¼‰\n",
    "transaction2 = torch.randn(1, 64)\n",
    "result = cache.get(transaction2)\n",
    "print(f\"3å›ç›®ã®ã‚¢ã‚¯ã‚»ã‚¹ï¼ˆæ–°ã—ã„ãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³ï¼‰: {'ãƒ’ãƒƒãƒˆ' if result is not None else 'ãƒŸã‚¹'}\")\n",
    "\n",
    "print(f\"\\nã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ’ãƒƒãƒˆç‡: {cache.get_hit_rate()*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1135f4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ONNXã«ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ\n",
    "print(\"ğŸ“¦ ONNXã«ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆä¸­...\\n\")\n",
    "\n",
    "onnx_path = Path.cwd().parent / 'models' / 'fraud_snn_demo.onnx'\n",
    "onnx_path.parent.mkdir(exist_ok=True)\n",
    "\n",
    "export_to_onnx(demo_model, onnx_path, input_size=64)\n",
    "print(f\"âœ… ãƒ¢ãƒ‡ãƒ«ã‚’ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ: {onnx_path}\")\n",
    "print(f\"ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: {onnx_path.stat().st_size / 1024:.2f} KB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e09ecc9",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£å¼·åŒ–\n",
    "\n",
    "### å•é¡Œ\n",
    "- èªè¨¼ãªã—ã®API\n",
    "- DDoSã«è„†å¼±\n",
    "- PIIæœªã‚µãƒ‹ã‚¿ã‚¤ã‚º\n",
    "\n",
    "### ã‚½ãƒªãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³\n",
    "- OAuth2 + JWT\n",
    "- ãƒ¬ãƒ¼ãƒˆåˆ¶é™\n",
    "- PIIã‚µãƒ‹ã‚¿ã‚¤ã‚º\n",
    "- æ•µå¯¾çš„é˜²å¾¡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b88b396",
   "metadata": {},
   "outputs": [],
   "source": [
    "from security import PIISanitizer, JWTManager, AdversarialDefense # type: ignore\n",
    "\n",
    "# PIIã‚µãƒ‹ã‚¿ã‚¤ã‚º\n",
    "print(\"ğŸ”’ PIIã‚µãƒ‹ã‚¿ã‚¤ã‚ºãƒ‡ãƒ¢\\n\")\n",
    "\n",
    "sanitizer = PIISanitizer(salt=\"demo_salt_12345\")\n",
    "\n",
    "transaction_data = {\n",
    " 'transaction_id': 'TXN_12345',\n",
    " 'card_number': '1234567890123456',\n",
    " 'email': 'user@example.com',\n",
    " 'ip_address': '192.168.1.100',\n",
    " 'phone': '5511999998888',\n",
    " 'amount': 150.50\n",
    "}\n",
    "\n",
    "print(\"å…ƒã®ãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³:\")\n",
    "for key, value in transaction_data.items():\n",
    " print(f\"  {key}: {value}\")\n",
    "\n",
    "sanitized = sanitizer.sanitize_transaction(transaction_data)\n",
    "\n",
    "print(\"\\nã‚µãƒ‹ã‚¿ã‚¤ã‚ºã•ã‚ŒãŸãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³:\")\n",
    "for key, value in sanitized.items():\n",
    " print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8662a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# JWTãƒˆãƒ¼ã‚¯ãƒ³ç®¡ç†\n",
    "print(\"ğŸ” JWTãƒˆãƒ¼ã‚¯ãƒ³ç®¡ç†\\n\")\n",
    "\n",
    "from datetime import timedelta\n",
    "\n",
    "# ãƒˆãƒ¼ã‚¯ãƒ³ã‚’ä½œæˆ\n",
    "token_data = {\n",
    " \"sub\": \"user_demo_123\",\n",
    " \"tier\": \"premium\",\n",
    " \"permissions\": [\"predict\", \"batch_predict\"]\n",
    "}\n",
    "\n",
    "token = JWTManager.create_access_token(\n",
    " token_data,\n",
    " expires_delta=timedelta(minutes=30)\n",
    ")\n",
    "\n",
    "print(f\"ç”Ÿæˆã•ã‚ŒãŸãƒˆãƒ¼ã‚¯ãƒ³: {token[:50]}...\")\n",
    "print(f\"ãƒˆãƒ¼ã‚¯ãƒ³é•·: {len(token)}æ–‡å­—\")\n",
    "\n",
    "# ãƒˆãƒ¼ã‚¯ãƒ³ã‚’æ¤œè¨¼\n",
    "verified = JWTManager.verify_token(token)\n",
    "print(f\"\\næ¤œè¨¼ã•ã‚ŒãŸãƒšã‚¤ãƒ­ãƒ¼ãƒ‰:\")\n",
    "for key, value in verified.items():\n",
    " if key != 'exp': # æœ‰åŠ¹æœŸé™ã®ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‚’ã‚¹ã‚­ãƒƒãƒ—\n",
    " print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4291405f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ•µå¯¾çš„é˜²å¾¡\n",
    "print(\"ğŸ›¡ï¸ æ•µå¯¾çš„é˜²å¾¡ãƒ‡ãƒ¢\\n\")\n",
    "\n",
    "# ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ãƒªãƒ­ãƒ¼ãƒ‰ã—ã¦ä¿®æ­£ã‚’å–å¾—\n",
    "import importlib\n",
    "import security\n",
    "importlib.reload(security)\n",
    "from security import AdversarialDefense # type: ignore\n",
    "\n",
    "# ç‰¹å¾´é‡ç¯„å›²ã‚’å®šç¾©ï¼ˆãƒ¢ãƒƒã‚¯ï¼‰\n",
    "feature_ranges = {f\"ç‰¹å¾´é‡_{i}\": (-3.0, 3.0) for i in range(64)}\n",
    "\n",
    "defense = AdversarialDefense(demo_model, feature_ranges)\n",
    "\n",
    "# æœ‰åŠ¹ãªå…¥åŠ›\n",
    "valid_input = torch.randn(1, 64) * 2 # [-3, 3]ã®ç¯„å›²å†…\n",
    "is_valid = defense.validate_input(valid_input)\n",
    "print(f\"æœ‰åŠ¹ãªå…¥åŠ›: {is_valid}\")\n",
    "\n",
    "# ç–‘ã‚ã—ã„å…¥åŠ›ï¼ˆç¯„å›²å¤–ï¼‰\n",
    "suspicious_input = torch.randn(1, 64) * 10 # [-3, 3]ã®ç¯„å›²å¤–\n",
    "is_valid = defense.validate_input(suspicious_input)\n",
    "print(f\"ç–‘ã‚ã—ã„å…¥åŠ›ï¼ˆç¯„å›²å¤–ï¼‰: {is_valid}\")\n",
    "\n",
    "# æ•µå¯¾çš„æ¤œå‡º\n",
    "is_adversarial = defense.detect_adversarial(valid_input, epsilon=0.1)\n",
    "print(f\"æ•µå¯¾çš„æ”»æ’ƒæ¤œå‡º: {is_adversarial}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b48c111e",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. éå­¦ç¿’é˜²æ­¢\n",
    "\n",
    "### å•é¡Œ\n",
    "- 41,088ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ vs 1,000ã‚µãƒ³ãƒ—ãƒ«ï¼ˆ41:1ï¼‰\n",
    "- æ·±åˆ»ãªéå­¦ç¿’\n",
    "\n",
    "### ã‚½ãƒªãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³\n",
    "- SMOTEãƒ‡ãƒ¼ã‚¿æ‹¡å¼µ\n",
    "- L1/L2æ­£å‰‡åŒ– + ãƒ‰ãƒ­ãƒƒãƒ—ã‚¢ã‚¦ãƒˆ\n",
    "- æ—©æœŸåœæ­¢\n",
    "- ã‚¯ãƒ­ã‚¹ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191c7899",
   "metadata": {},
   "outputs": [],
   "source": [
    "from overfitting_prevention import (  # type: ignore[import-untyped]\n",
    "    DataAugmenter,\n",
    "    RegularizedSNN,  # type: ignore[attr-defined]\n",
    "    EarlyStopping,  # type: ignore[attr-defined]\n",
    "    CrossValidator  # type: ignore[attr-defined]\n",
    ")\n",
    "\n",
    "# SMOTEã«ã‚ˆã‚‹ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µ\n",
    "print(\"ğŸ“ˆ ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µï¼ˆSMOTEï¼‰\\n\")\n",
    "\n",
    "augmenter = DataAugmenter()\n",
    "\n",
    "# ä¸å‡è¡¡ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½œæˆï¼ˆ10%ä¸æ­£ï¼‰\n",
    "X = torch.randn(100, 64)\n",
    "y = torch.cat([torch.zeros(90), torch.ones(10)])\n",
    "\n",
    "print(f\"å…ƒã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ:\")\n",
    "print(f\"  ã‚¯ãƒ©ã‚¹0: {int((y==0).sum().item())}\")\n",
    "print(f\"  ã‚¯ãƒ©ã‚¹1: {int((y==1).sum().item())}\")\n",
    "print(f\"  ä¸å‡è¡¡æ¯”: {int((y==0).sum().item())}:{int((y==1).sum().item())}\")\n",
    "\n",
    "# SMOTEã‚’é©ç”¨\n",
    "X_aug, y_aug = augmenter.smote(X, y, k_neighbors=3)  # type: ignore[attr-defined]\n",
    "\n",
    "print(f\"\\nSMOTEå¾Œ:\")\n",
    "print(f\"  ã‚¯ãƒ©ã‚¹0: {int((y_aug==0).sum().item())}\")\n",
    "print(f\"  ã‚¯ãƒ©ã‚¹1: {int((y_aug==1).sum().item())}\")\n",
    "print(f\"  ç·ã‚µãƒ³ãƒ—ãƒ«å¢—åŠ : {len(y)} â†’ {len(y_aug)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df49f45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ‹¡å¼µã‚’è¦–è¦šåŒ–\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "print(\"ğŸ“Š SMOTEæ‹¡å¼µã‚’è¦–è¦šåŒ–\\n\")\n",
    "\n",
    "# è¦–è¦šåŒ–ã®ãŸã‚ã®PCA\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X.numpy())\n",
    "X_aug_pca = pca.transform(X_aug.numpy())\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "# å…ƒã®ãƒ‡ãƒ¼ã‚¿\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(X_pca[y==0, 0], X_pca[y==0, 1], c='blue', label='æ­£å¸¸', alpha=0.6)\n",
    "plt.scatter(X_pca[y==1, 0], X_pca[y==1, 1], c='red', label='ä¸æ­£', alpha=0.6)\n",
    "plt.xlabel('PC1')\n",
    "plt.ylabel('PC2')\n",
    "plt.title('å…ƒã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆï¼ˆä¸å‡è¡¡ï¼‰')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# æ‹¡å¼µãƒ‡ãƒ¼ã‚¿\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(X_aug_pca[y_aug==0, 0], X_aug_pca[y_aug==0, 1], c='blue', label='æ­£å¸¸', alpha=0.4)\n",
    "plt.scatter(X_aug_pca[y_aug==1, 0], X_aug_pca[y_aug==1, 1], c='red', label='ä¸æ­£', alpha=0.4)\n",
    "plt.xlabel('PC1')\n",
    "plt.ylabel('PC2')\n",
    "plt.title('æ‹¡å¼µãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆï¼ˆSMOTEï¼‰')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6424ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ­£å‰‡åŒ–ãƒ¢ãƒ‡ãƒ«\n",
    "print(\"âš™ï¸ æ­£å‰‡åŒ–SNNãƒ¢ãƒ‡ãƒ«\\n\")\n",
    "\n",
    "reg_model = RegularizedSNN(\n",
    " input_size=64,\n",
    " hidden_sizes=[32, 16],\n",
    " output_size=2,\n",
    " dropout_rate=0.3,\n",
    " l1_lambda=0.001,\n",
    " l2_lambda=0.01\n",
    ")\n",
    "\n",
    "total_params = sum(p.numel() for p in reg_model.parameters())\n",
    "print(f\"ç·ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿: {total_params:,}\")\n",
    "\n",
    "# æ­£å‰‡åŒ–æå¤±ã‚’ãƒ†ã‚¹ãƒˆ\n",
    "test_input = torch.randn(4, 64)\n",
    "output = reg_model(test_input)\n",
    "reg_loss = reg_model.regularization_loss()\n",
    "\n",
    "print(f\"\\næ­£å‰‡åŒ–æå¤±: {reg_loss.item():.6f}\")\n",
    "print(f\"L1æˆåˆ†: {reg_model.l1_lambda * sum(p.abs().sum() for p in reg_model.parameters()):.6f}\")\n",
    "print(f\"L2æˆåˆ†: {reg_model.l2_lambda * sum((p**2).sum() for p in reg_model.parameters()):.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80068113",
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ—©æœŸåœæ­¢ãƒ‡ãƒ¢\n",
    "print(\"â¹ æ—©æœŸåœæ­¢ãƒ‡ãƒ¢\\n\")\n",
    "\n",
    "early_stopping = EarlyStopping(patience=5, min_delta=0.001)\n",
    "\n",
    "# æ¸›å°‘ã—ã¦ã‹ã‚‰å¢—åŠ ã™ã‚‹æ¤œè¨¼æå¤±ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆ\n",
    "val_losses = [0.8, 0.7, 0.65, 0.62, 0.61, 0.605, 0.61, 0.62, 0.65, 0.70]\n",
    "\n",
    "print(\"è¨“ç·´ã‚¨ãƒãƒƒã‚¯ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆä¸­:\\n\")\n",
    "for epoch, val_loss in enumerate(val_losses, 1):\n",
    " should_stop = early_stopping(val_loss, demo_model)\n",
    " \n",
    " status = \"â›” åœæ­¢\" if should_stop else \"âœ… ç¶™ç¶š\"\n",
    " print(f\"ã‚¨ãƒãƒƒã‚¯{epoch}: val_loss={val_loss:.3f} | {status}\")\n",
    " \n",
    " if should_stop:\n",
    " print(f\"\\nâœ… æœ€è‰¯val_loss: {early_stopping.best_loss:.3f}\")\n",
    " print(f\"âœ… ãƒ¢ãƒ‡ãƒ«ã‚’æœ€è‰¯ã®é‡ã¿ã«å¾©å…ƒ\")\n",
    " break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f7a543",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7. ã‚³ã‚¹ãƒˆæœ€é©åŒ–\n",
    "\n",
    "### å•é¡Œ\n",
    "- å¹´é–“240ä¸‡ãƒ‰ãƒ«ã®é‹ç”¨ã‚³ã‚¹ãƒˆ\n",
    "- ãƒªã‚½ãƒ¼ã‚¹ã®éå°åˆ©ç”¨\n",
    "\n",
    "### ã‚½ãƒªãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³\n",
    "- ã‚ªãƒ¼ãƒˆã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ï¼ˆKubernetes HPAï¼‰\n",
    "- ã‚¹ãƒãƒƒãƒˆã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ï¼ˆ70-90%å®‰ã„ï¼‰\n",
    "- ã‚¨ãƒƒã‚¸ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆ\n",
    "- **50%ã‚³ã‚¹ãƒˆå‰Šæ¸›**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101d4750",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cost_optimization import ( # type: ignore\n",
    " AutoScaler,\n",
    " EdgeDeploymentOptimizer,\n",
    " CostOptimizationEngine\n",
    ")\n",
    "\n",
    "# ã‚ªãƒ¼ãƒˆã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã«ã‚ˆã‚‹ç¯€ç´„\n",
    "print(\"ğŸ’° ã‚ªãƒ¼ãƒˆã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°åˆ†æ\\n\")\n",
    "\n",
    "autoscaler = AutoScaler(\n",
    " min_replicas=2,\n",
    " max_replicas=20,\n",
    " target_cpu_percent=70\n",
    ")\n",
    "\n",
    "savings = autoscaler.calculate_savings(\n",
    " hourly_cost_per_pod=0.50,\n",
    " avg_utilization=0.4 # 40%å¹³å‡ä½¿ç”¨ç‡\n",
    ")\n",
    "\n",
    "print(f\"ã‚ªãƒ¼ãƒˆã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ãªã—: ${savings['cost_without_autoscaling']:,.2f}/æœˆ\")\n",
    "print(f\"ã‚ªãƒ¼ãƒˆã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã‚ã‚Š: ${savings['cost_with_autoscaling']:,.2f}/æœˆ\")\n",
    "print(f\"æœˆé–“ç¯€ç´„: ${savings['monthly_savings']:,.2f}\")\n",
    "print(f\"ç¯€ç´„ç‡: {savings['savings_percent']:.1f}%\")\n",
    "print(f\"å¹³å‡ãƒãƒƒãƒ‰æ•°: {savings['avg_pods']:.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40dbb23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ã‚¨ãƒƒã‚¸ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆç¯€ç´„\n",
    "print(\"ğŸŒ ã‚¨ãƒƒã‚¸ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆåˆ†æ\\n\")\n",
    "\n",
    "edge_optimizer = EdgeDeploymentOptimizer()\n",
    "\n",
    "edge_savings = edge_optimizer.calculate_edge_savings(\n",
    " monthly_transactions=10_000_000, # æœˆé–“1000ä¸‡ãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³\n",
    " edge_processing_ratio=0.8 # 80%ãŒã‚¨ãƒƒã‚¸ã§å‡¦ç†\n",
    ")\n",
    "\n",
    "print(f\"ã‚¯ãƒ©ã‚¦ãƒ‰ã®ã¿ã‚³ã‚¹ãƒˆ: ${edge_savings['cloud_only_cost']:,.2f}/æœˆ\")\n",
    "print(f\"ã‚¨ãƒƒã‚¸ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ã‚³ã‚¹ãƒˆ: ${edge_savings['edge_hybrid_cost']:,.2f}/æœˆ\")\n",
    "print(f\"æœˆé–“ç¯€ç´„: ${edge_savings['monthly_savings']:,.2f}\")\n",
    "print(f\"ç¯€ç´„ç‡: {edge_savings['savings_percent']:.1f}%\")\n",
    "print(f\"ã‚¨ãƒƒã‚¸ãƒ‡ãƒã‚¤ã‚¹ã‚³ã‚¹ãƒˆ: ${edge_savings['edge_device_monthly']:.2f}/æœˆï¼ˆå„Ÿå´ï¼‰\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252ff85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å®Œå…¨ãªæœ€é©åŒ–è¨ˆç”»\n",
    "print(\"ğŸ“Š å®Œå…¨ãªã‚³ã‚¹ãƒˆæœ€é©åŒ–è¨ˆç”»\\n\")\n",
    "\n",
    "CURRENT_MONTHLY_COST = 200_000 # æœˆé¡20ä¸‡ãƒ‰ãƒ«\n",
    "MONTHLY_TRANSACTIONS = 10_000_000\n",
    "\n",
    "optimizer = CostOptimizationEngine()\n",
    "plan = optimizer.generate_optimization_plan(\n",
    " current_monthly_cost=CURRENT_MONTHLY_COST,\n",
    " monthly_transactions=MONTHLY_TRANSACTIONS,\n",
    " avg_utilization=0.4\n",
    ")\n",
    "\n",
    "optimizer.print_optimization_plan(plan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26693faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ã‚³ã‚¹ãƒˆå†…è¨³ã‚’è¦–è¦šåŒ–\n",
    "print(\"ğŸ“ˆ ã‚³ã‚¹ãƒˆæœ€é©åŒ–è¦–è¦šåŒ–\\n\")\n",
    "\n",
    "categories = list(plan['breakdown'].keys())\n",
    "savings_values = [plan['breakdown'][cat] / 1000 for cat in categories] # åƒãƒ‰ãƒ«å˜ä½\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# ã‚«ãƒ†ã‚´ãƒªåˆ¥ç¯€ç´„\n",
    "plt.subplot(1, 2, 1)\n",
    "colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728']\n",
    "plt.bar(range(len(categories)), savings_values, color=colors)\n",
    "plt.xticks(range(len(categories)), \n",
    " ['ã‚ªãƒ¼ãƒˆ\\nã‚¹ã‚±ãƒ¼ãƒ«', 'ã‚¹ãƒãƒƒãƒˆ\\nã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹', 'ã‚¨ãƒƒã‚¸\\nãƒ‡ãƒ—ãƒ­ã‚¤', 'é‡å­åŒ–'])\n",
    "plt.ylabel('æœˆé–“ç¯€ç´„ ($K)')\n",
    "plt.title('æœ€é©åŒ–æˆ¦ç•¥åˆ¥ç¯€ç´„')\n",
    "plt.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# å‰å¾Œæ¯”è¼ƒ\n",
    "plt.subplot(1, 2, 2)\n",
    "costs = [plan['current_cost']/1000, plan['optimized_cost']/1000]\n",
    "colors_ba = ['#d62728', '#2ca02c']\n",
    "bars = plt.bar(['ç¾åœ¨', 'æœ€é©åŒ–å¾Œ'], costs, color=colors_ba, width=0.5)\n",
    "plt.ylabel('æœˆé–“ã‚³ã‚¹ãƒˆ ($K)')\n",
    "plt.title('ã‚³ã‚¹ãƒˆæ¯”è¼ƒ')\n",
    "plt.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# å€¤ãƒ©ãƒ™ãƒ«ã‚’è¿½åŠ \n",
    "for bar in bars:\n",
    " height = bar.get_height()\n",
    " plt.text(bar.get_x() + bar.get_width()/2., height,\n",
    " f'${height:.0f}K',\n",
    " ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nğŸ’° å¹´é–“ç·ç¯€ç´„: ${plan['total_savings']*12:,.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b18749",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ã¾ã¨ã‚: ã™ã¹ã¦ã®ã‚½ãƒªãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³\n",
    "\n",
    "### å®Ÿè£…å‰ã¨å®Ÿè£…å¾Œã®æ¯”è¼ƒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdfe5c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# åŒ…æ‹¬çš„æ¯”è¼ƒè¡¨ã‚’ä½œæˆ\n",
    "comparison_data = {\n",
    " 'ãƒ¡ãƒˆãƒªã‚¯ã‚¹': [\n",
    " 'ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·',\n",
    " 'ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆ',\n",
    " 'ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ',\n",
    " 'èª¬æ˜å¯èƒ½æ€§',\n",
    " 'ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£',\n",
    " 'éå­¦ç¿’',\n",
    " 'å¹´é–“ã‚³ã‚¹ãƒˆ'\n",
    " ],\n",
    " 'å®Ÿè£…å‰': [\n",
    " '100ms',\n",
    " '10 TPS',\n",
    " '1kåˆæˆ',\n",
    " 'ãªã—',\n",
    " 'è„†å¼±',\n",
    " 'æ·±åˆ»ï¼ˆ41:1ï¼‰',\n",
    " '$2.4M'\n",
    " ],\n",
    " 'å®Ÿè£…å¾Œ': [\n",
    " '10-20ms',\n",
    " '800 TPS',\n",
    " '590kå®Ÿãƒ‡ãƒ¼ã‚¿',\n",
    " 'SHAP + ã‚¢ãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³',\n",
    " 'OAuth2 + PII',\n",
    " 'ç·©å’Œï¼ˆ1:14ï¼‰',\n",
    " '$1.2M'\n",
    " ],\n",
    " 'æ”¹å–„': [\n",
    " '6.7å€ â†“',\n",
    " '80å€ â†‘',\n",
    " '590å€ â†‘',\n",
    " 'âœ… LGPD',\n",
    " 'âœ… PCI DSS',\n",
    " 'âœ… è§£æ±º',\n",
    " '50% â†“'\n",
    " ]\n",
    "}\n",
    "\n",
    "df_comparison = pd.DataFrame(comparison_data)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"æ¯”è¼ƒè¦ç´„: å®Ÿè£…å‰ vs å®Ÿè£…å¾Œ\")\n",
    "print(\"=\"*70)\n",
    "display(df_comparison)\n",
    "print(\"=\"*70)\n",
    "print(\"\\nâœ… ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹: æœ¬ç•ªç’°å¢ƒæº–å‚™å®Œäº†\")\n",
    "print(\"âœ… src/ã«7ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«å®Ÿè£…æ¸ˆã¿\")\n",
    "print(\"âœ… docs/SOLUTIONS_IMPLEMENTED.mdã«å®Œå…¨ãªãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab24a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ”¹å–„ã‚’è¦–è¦šåŒ–\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# 1. ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·æ”¹å–„\n",
    "ax = axes[0, 0]\n",
    "latencies = [100, 15]\n",
    "labels = ['Brian2\\nï¼ˆå®Ÿè£…å‰ï¼‰', 'PyTorch\\nï¼ˆå®Ÿè£…å¾Œï¼‰']\n",
    "colors = ['#d62728', '#2ca02c']\n",
    "bars = ax.bar(labels, latencies, color=colors)\n",
    "ax.set_ylabel('ãƒ¬ã‚¤ãƒ†ãƒ³ã‚· (ms)')\n",
    "ax.set_title('æ¨è«–ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·')\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "for bar in bars:\n",
    " height = bar.get_height()\n",
    " ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    " f'{height}ms', ha='center', va='bottom')\n",
    "\n",
    "# 2. ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆæ”¹å–„\n",
    "ax = axes[0, 1]\n",
    "throughputs = [10, 800]\n",
    "bars = ax.bar(labels, throughputs, color=colors)\n",
    "ax.set_ylabel('TPSï¼ˆãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³/ç§’ï¼‰')\n",
    "ax.set_title('ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆ')\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "for bar in bars:\n",
    " height = bar.get_height()\n",
    " ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    " f'{int(height)} TPS', ha='center', va='bottom')\n",
    "\n",
    "# 3. ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚µã‚¤ã‚º\n",
    "ax = axes[1, 0]\n",
    "datasets = [1, 590]\n",
    "labels_ds = ['åˆæˆ\\nï¼ˆå®Ÿè£…å‰ï¼‰', 'Kaggle\\nï¼ˆå®Ÿè£…å¾Œï¼‰']\n",
    "bars = ax.bar(labels_ds, datasets, color=colors)\n",
    "ax.set_ylabel('ã‚µãƒ³ãƒ—ãƒ«ï¼ˆåƒï¼‰')\n",
    "ax.set_title('ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚µã‚¤ã‚º')\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "for bar in bars:\n",
    " height = bar.get_height()\n",
    " ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    " f'{int(height)}k', ha='center', va='bottom')\n",
    "\n",
    "# 4. ã‚³ã‚¹ãƒˆå‰Šæ¸›\n",
    "ax = axes[1, 1]\n",
    "costs = [2.4, 1.2]\n",
    "bars = ax.bar(labels, costs, color=colors)\n",
    "ax.set_ylabel('å¹´é–“ã‚³ã‚¹ãƒˆ ($M)')\n",
    "ax.set_title('é‹ç”¨ã‚³ã‚¹ãƒˆ')\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "for bar in bars:\n",
    " height = bar.get_height()\n",
    " ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    " f'${height}M', ha='center', va='bottom')\n",
    "\n",
    "plt.suptitle('ğŸš€ å®Ÿè£…ã•ã‚ŒãŸæ”¹å–„ - æ¦‚è¦', \n",
    " fontsize=16, fontweight='bold', y=1.00)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "031d31b6",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—\n",
    "\n",
    "### ãƒ•ã‚§ãƒ¼ã‚º1: çµ±åˆï¼ˆ2é€±é–“ï¼‰\n",
    "1. PyTorch SNNã‚’FastAPI APIã«çµ±åˆ\n",
    "2. Kaggleãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã¨å‰å‡¦ç†\n",
    "3. å®Ÿãƒ‡ãƒ¼ã‚¿ã§ãƒ¢ãƒ‡ãƒ«ã‚’å†è¨“ç·´\n",
    "4. çµ±åˆãƒ†ã‚¹ãƒˆ\n",
    "\n",
    "### ãƒ•ã‚§ãƒ¼ã‚º2: ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆï¼ˆ2é€±é–“ï¼‰\n",
    "1. Kubernetesã«é‡å­åŒ–ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ‡ãƒ—ãƒ­ã‚¤\n",
    "2. HPAï¼ˆã‚ªãƒ¼ãƒˆã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ï¼‰ã‚’è¨­å®š\n",
    "3. ã‚¹ãƒãƒƒãƒˆã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—\n",
    "4. ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°ã‚’å®Ÿè£…\n",
    "\n",
    "### ãƒ•ã‚§ãƒ¼ã‚º3: ã‚³ãƒ³ãƒ—ãƒ©ã‚¤ã‚¢ãƒ³ã‚¹ï¼ˆ1é€±é–“ï¼‰\n",
    "1. èª¬æ˜å¯èƒ½æ€§å‡ºåŠ›ã‚’ç›£æŸ»\n",
    "2. LGPD/GDPRæº–æ‹ ã‚’æ¤œè¨¼\n",
    "3. ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ä¾µå…¥ãƒ†ã‚¹ãƒˆ\n",
    "4. æ³•çš„ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ\n",
    "\n",
    "### ãƒ•ã‚§ãƒ¼ã‚º4: æœ€é©åŒ–ï¼ˆ1é€±é–“ï¼‰\n",
    "1. ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®å¾®èª¿æ•´\n",
    "2. A/Bãƒ†ã‚¹ãƒˆï¼ˆBrian2 vs PyTorchï¼‰\n",
    "3. è² è·ãƒ†ã‚¹ãƒˆï¼ˆ1000+ TPSï¼‰\n",
    "4. ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãªã‚³ã‚¹ãƒˆç›£è¦–\n",
    "\n",
    "**ç·ã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³:** 6é€±é–“ \n",
    "**ãƒ­ãƒ¼ãƒ³ãƒæ—¥:** 2026å¹´1æœˆ\n",
    "\n",
    "---\n",
    "\n",
    "## å‚è€ƒè³‡æ–™\n",
    "\n",
    "- **ã‚³ãƒ¼ãƒ‰:** `portfolio/01_fraud_neuromorphic/src/`\n",
    "- **ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ:** `docs/SOLUTIONS_IMPLEMENTED.md`\n",
    "- **GitHub:** github.com/maurorisonho/fraud-detection-neuromorphic\n",
    "\n",
    "---\n",
    "\n",
    "## çµè«–\n",
    "\n",
    "ã™ã¹ã¦ã®**7ã¤ã®é‡è¦ãªå•é¡Œ**ãŒæœ¬ç•ªç’°å¢ƒå¯¾å¿œã‚½ãƒªãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³ã§è§£æ±ºã•ã‚Œã¾ã—ãŸ:\n",
    "\n",
    "1. Brian2 â†’ PyTorchã¸ã®ç§»è¡Œï¼ˆ6.7å€ã‚¹ãƒ”ãƒ¼ãƒ‰ã‚¢ãƒƒãƒ—ï¼‰\n",
    "2. å®ŸKaggleãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆï¼ˆ590kãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³ï¼‰\n",
    "3. LGPD/GDPRèª¬æ˜å¯èƒ½æ€§\n",
    "4. ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–\n",
    "5. ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£å¼·åŒ–\n",
    "6. éå­¦ç¿’é˜²æ­¢\n",
    "7. ã‚³ã‚¹ãƒˆæœ€é©åŒ–ï¼ˆ50%å‰Šæ¸›ï¼‰\n",
    "\n",
    "**æœ€çµ‚ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹:** **æœ¬ç•ªç’°å¢ƒæº–å‚™å®Œäº†**\n",
    "\n",
    "---\n",
    "\n",
    "**è‘—è€…:** Mauro Risonho de Paula AssumpÃ§Ã£o \n",
    "**é€£çµ¡å…ˆ:** mauro.risonho@gmail.com \n",
    "**æ—¥ä»˜:** 2025å¹´12æœˆ"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
