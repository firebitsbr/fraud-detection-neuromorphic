{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8c4f587",
   "metadata": {},
   "source": [
    "# üß† Demonstra√ß√£o: Detec√ß√£o de Fraude Neurom√≥rfica\n",
    "\n",
    "**Descri√ß√£o:** Notebook interativo demonstrando o pipeline completo de detec√ß√£o de fraude usando Spiking Neural Networks (SNNs), incluindo codifica√ß√£o de spikes, treinamento STDP, e an√°lise de performance.\n",
    "\n",
    "**Autor:** Mauro Risonho de Paula Assump√ß√£o\n",
    "**Data de Cria√ß√£o:** 5 de Dezembro de 2025\n",
    "**Licen√ßa:** MIT License\n",
    "**Desenvolvimento:** Desenvolvedor Humano + Desenvolvimento por AI Assitida:\n",
    "- Claude Sonnet 4.5\n",
    "- Gemini 3 Pro Preview\n",
    "\n",
    "---\n",
    "\n",
    "Este notebook demonstra o pipeline completo de detec√ß√£o de fraude usando Spiking Neural Networks (SNNs).\n",
    "\n",
    "## Conte√∫do\n",
    "1. Setup e Importa√ß√µes\n",
    "2. Gera√ß√£o de Dados Sint√©ticos\n",
    "3. Codifica√ß√£o de Spikes\n",
    "4. Arquitetura da SNN\n",
    "5. Treinamento com STDP\n",
    "6. Infer√™ncia e Avalia√ß√£o\n",
    "7. Visualiza√ß√µes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a287c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Adicionar src ao path\n",
    "# Notebook est√° em: Projeto-Neuromorfico-X/portfolio/01_fraud_neuromorphic/notebooks/\n",
    "# src est√° em: Projeto-Neuromorfico-X/portfolio/01_fraud_neuromorphic/src/\n",
    "notebook_dir = Path.cwd()\n",
    "\n",
    "# Verificar se estamos no diret√≥rio raiz do projeto ou no diret√≥rio notebooks\n",
    "if (notebook_dir / 'portfolio' / '01_fraud_neuromorphic' / 'src').exists():\n",
    "    # Estamos na raiz do projeto (Projeto-Neuromorfico-X)\n",
    "    src_path = notebook_dir / 'portfolio' / '01_fraud_neuromorphic' / 'src'\n",
    "elif (notebook_dir.parent / 'src').exists():\n",
    "    # Estamos em notebooks/\n",
    "    src_path = notebook_dir.parent / 'src'\n",
    "elif (notebook_dir / 'src').exists():\n",
    "    # Estamos em 01_fraud_neuromorphic/\n",
    "    src_path = notebook_dir / 'src'\n",
    "else:\n",
    "    src_path = None\n",
    "\n",
    "if src_path and src_path.exists():\n",
    "    if str(src_path) not in sys.path:\n",
    "        sys.path.insert(0, str(src_path))\n",
    "    print(f\"‚úÖ Diret√≥rio src adicionado: {src_path}\")\n",
    "else:\n",
    "    print(f\"‚ùå Diret√≥rio src n√£o encontrado!\")\n",
    "    print(f\"   Notebook dir: {notebook_dir}\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import time\n",
    "from tqdm.auto import tqdm\n",
    "import brian2\n",
    "\n",
    "# Configurar Brian2 para usar numpy (evita erros de compila√ß√£o C++ e problemas com SymPy/Cython)\n",
    "brian2.prefs.codegen.target = \"numpy\"\n",
    "\n",
    "# Nossos m√≥dulos\n",
    "try:\n",
    "    from main import FraudDetectionPipeline, generate_synthetic_transactions\n",
    "    from encoders import RateEncoder, TemporalEncoder, PopulationEncoder, TransactionEncoder\n",
    "    from models_snn import FraudSNN, demonstrate_lif_neuron\n",
    "    print(\"‚úÖ Importa√ß√µes dos m√≥dulos do projeto conclu√≠das!\")\n",
    "except ImportError as e:\n",
    "    print(f\"‚ùå Erro ao importar m√≥dulos: {e}\")\n",
    "    print(f\"   sys.path: {sys.path[:3]}\")\n",
    "\n",
    "# Configura√ß√£o de visualiza√ß√£o\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b3c422e",
   "metadata": {},
   "source": [
    "## 2. Gera√ß√£o de Dados Sint√©ticos\n",
    "\n",
    "Vamos criar um dataset sint√©tico de transa√ß√µes banc√°rias com padr√µes realistas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9542a0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gerar 1000 transa√ß√µes (5% fraudes)\n",
    "print(\"Gerando transa√ß√µes sint√©ticas...\")\n",
    "df = generate_synthetic_transactions(n=1000, fraud_ratio=0.05)\n",
    "\n",
    "print(f\"\\nüìä Dataset gerado:\")\n",
    "print(f\"Total de transa√ß√µes: {len(df)}\")\n",
    "print(f\"Transa√ß√µes leg√≠timas: {np.sum(df['is_fraud'] == 0)}\")\n",
    "print(f\"Transa√ß√µes fraudulentas: {np.sum(df['is_fraud'] == 1)}\")\n",
    "print(f\"Taxa de fraude: {df['is_fraud'].mean():.2%}\")\n",
    "\n",
    "# Mostrar primeiras linhas\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55178d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar distribui√ß√£o de valores\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Distribui√ß√£o de valores por classe\n",
    "df[df['is_fraud'] == 0]['amount'].hist(bins=50, alpha=0.7, label='Leg√≠timas', ax=axes[0], color='green')\n",
    "df[df['is_fraud'] == 1]['amount'].hist(bins=30, alpha=0.7, label='Fraudulentas', ax=axes[0], color='red')\n",
    "axes[0].set_xlabel('Valor da Transa√ß√£o ($)')\n",
    "axes[0].set_ylabel('Frequ√™ncia')\n",
    "axes[0].set_title('Distribui√ß√£o de Valores por Classe')\n",
    "axes[0].legend()\n",
    "\n",
    "# Frequ√™ncia di√°ria por classe\n",
    "df.boxplot(column='daily_frequency', by='is_fraud', ax=axes[1])\n",
    "axes[1].set_xlabel('Classe (0=Leg√≠tima, 1=Fraude)')\n",
    "axes[1].set_ylabel('Frequ√™ncia Di√°ria')\n",
    "axes[1].set_title('Frequ√™ncia de Transa√ß√µes por Classe')\n",
    "plt.suptitle('')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüìà Padr√µes observados:\")\n",
    "print(\"  - Fraudes tendem a ter valores mais altos\")\n",
    "print(\"  - Fraudes t√™m maior frequ√™ncia de transa√ß√µes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac22d44",
   "metadata": {},
   "source": [
    "## 3. Codifica√ß√£o de Spikes\n",
    "\n",
    "Demonstrar como features de transa√ß√µes s√£o convertidas em spikes temporais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b29cf11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemplo de Rate Encoding\n",
    "print(\"=== RATE ENCODING ===\")\n",
    "print(\"Codifica valores cont√≠nuos como frequ√™ncia de spikes\\n\")\n",
    "\n",
    "rate_encoder = RateEncoder(min_rate=1, max_rate=100, duration=0.1)\n",
    "\n",
    "# Testar com diferentes valores\n",
    "test_amounts = [100, 500, 1000, 5000, 10000]\n",
    "\n",
    "fig, axes = plt.subplots(len(test_amounts), 1, figsize=(12, 10))\n",
    "\n",
    "for idx, amount in enumerate(test_amounts):\n",
    "    spike_times = rate_encoder.encode(amount, min_val=0, max_val=10000)\n",
    "    \n",
    "    # Visualizar\n",
    "    if spike_times:\n",
    "        axes[idx].eventplot([spike_times], linewidths=2, colors='blue')\n",
    "    axes[idx].set_xlim(0, 0.1)\n",
    "    axes[idx].set_ylim(0.5, 1.5)\n",
    "    axes[idx].set_ylabel(f'${amount}')\n",
    "    axes[idx].set_title(f'Valor: ${amount} ‚Üí {len(spike_times)} spikes')\n",
    "    axes[idx].grid(True, alpha=0.3)\n",
    "    \n",
    "axes[-1].set_xlabel('Tempo (segundos)')\n",
    "plt.suptitle('Rate Encoding: Valor ‚Üí Frequ√™ncia de Spikes', fontsize=14, y=1.0)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüí° Observa√ß√£o: Valores maiores geram mais spikes (maior frequ√™ncia)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3bd4fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemplo de Population Encoding (Geolocaliza√ß√£o)\n",
    "print(\"=== POPULATION ENCODING ===\")\n",
    "print(\"Codifica valores usando m√∫ltiplos neur√¥nios com campos receptivos\\n\")\n",
    "\n",
    "pop_encoder = PopulationEncoder(n_neurons=20, min_val=-1, max_val=1, sigma=0.15)\n",
    "\n",
    "# Testar com diferentes localiza√ß√µes\n",
    "test_locations = [-0.8, -0.3, 0.0, 0.4, 0.9]\n",
    "\n",
    "fig, axes = plt.subplots(2, 1, figsize=(14, 8))\n",
    "\n",
    "# Plot 1: Ativa√ß√£o dos neur√¥nios\n",
    "for loc in test_locations:\n",
    "    activations = np.exp(-((pop_encoder.centers - loc) ** 2) / (2 * pop_encoder.sigma ** 2))\n",
    "    axes[0].plot(pop_encoder.centers, activations, marker='o', label=f'Localiza√ß√£o = {loc:.1f}', alpha=0.7)\n",
    "\n",
    "axes[0].set_xlabel('Centro do Neur√¥nio')\n",
    "axes[0].set_ylabel('Ativa√ß√£o')\n",
    "axes[0].set_title('Ativa√ß√£o da Popula√ß√£o de Neur√¥nios por Localiza√ß√£o')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Raster plot de spikes\n",
    "spike_data = []\n",
    "for idx, loc in enumerate(test_locations):\n",
    "    encoding = pop_encoder.encode(loc, duration=0.1)\n",
    "    if len(encoding.spike_times) > 0:\n",
    "        for t, n in zip(encoding.spike_times, encoding.neuron_indices):\n",
    "            spike_data.append([t, n + idx * 25])  # Offset for visualization\n",
    "\n",
    "if spike_data:\n",
    "    spike_array = np.array(spike_data)\n",
    "    axes[1].scatter(spike_array[:, 0], spike_array[:, 1], marker='|', s=100, alpha=0.6)\n",
    "\n",
    "axes[1].set_xlabel('Tempo (segundos)')\n",
    "axes[1].set_ylabel('Neur√¥nio + Offset')\n",
    "axes[1].set_title('Spikes Gerados por Popula√ß√£o de Neur√¥nios')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüí° Observa√ß√£o: Cada localiza√ß√£o ativa um grupo diferente de neur√¥nios\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cccf508d",
   "metadata": {},
   "source": [
    "## 4. Arquitetura da SNN\n",
    "\n",
    "Visualizar e entender a arquitetura da Spiking Neural Network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68cc26d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstra√ß√£o de neur√¥nio LIF individual\n",
    "print(\"=== LEAKY INTEGRATE-AND-FIRE NEURON ===\")\n",
    "print(\"Demonstra√ß√£o do comportamento de um neur√¥nio LIF\\n\")\n",
    "\n",
    "lif_data = demonstrate_lif_neuron()\n",
    "\n",
    "fig, axes = plt.subplots(2, 1, figsize=(14, 8), sharex=True)\n",
    "\n",
    "# Plot 1: Corrente de entrada\n",
    "axes[0].plot(lif_data['time'], lif_data['input'], color='blue', linewidth=2)\n",
    "axes[0].set_ylabel('Corrente de Entrada (I)')\n",
    "axes[0].set_title('Est√≠mulo de Entrada (Step Current)')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Potencial de membrana e spikes\n",
    "axes[1].plot(lif_data['time'], lif_data['voltage'], color='green', linewidth=2, label='Potencial de Membrana')\n",
    "axes[1].axhline(-50, color='red', linestyle='--', label='Threshold (-50mV)', alpha=0.7)\n",
    "axes[1].axhline(-70, color='gray', linestyle='--', label='Resting (-70mV)', alpha=0.5)\n",
    "\n",
    "# Marcar spikes\n",
    "for spike_time in lif_data['spikes']:\n",
    "    axes[1].axvline(spike_time, color='red', alpha=0.3, linewidth=1)\n",
    "\n",
    "axes[1].set_xlabel('Tempo (ms)')\n",
    "axes[1].set_ylabel('Voltagem (mV)')\n",
    "axes[1].set_title(f'Potencial de Membrana (Total de {len(lif_data[\"spikes\"])} spikes)')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nüìä An√°lise:\")\n",
    "print(f\"  - Spikes detectados: {len(lif_data['spikes'])}\")\n",
    "print(f\"  - Frequ√™ncia m√©dia: {len(lif_data['spikes']) / (lif_data['time'][-1] / 1000):.1f} Hz\")\n",
    "print(f\"  - ISI m√©dio: {np.mean(np.diff(lif_data['spikes'])):.2f} ms\" if len(lif_data['spikes']) > 1 else \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830456a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estat√≠sticas da arquitetura SNN\n",
    "print(\"=== ARQUITETURA DA SNN ===\")\n",
    "\n",
    "snn = FraudSNN(input_size=256, hidden_sizes=[128, 64], output_size=2)\n",
    "stats = snn.get_network_stats()\n",
    "\n",
    "print(f\"\\nüìê Estrutura da Rede:\")\n",
    "print(f\"  Input Layer:    {stats['layers']['input']} neur√¥nios\")\n",
    "print(f\"  Hidden Layer 1: {stats['layers']['hidden'][0]} neur√¥nios (LIF)\")\n",
    "print(f\"  Hidden Layer 2: {stats['layers']['hidden'][1]} neur√¥nios (LIF)\")\n",
    "print(f\"  Output Layer:   {stats['layers']['output']} neur√¥nios\")\n",
    "print(f\"\\n  Total de neur√¥nios: {stats['total_neurons']}\")\n",
    "print(f\"  Total de sinapses:  {stats['total_synapses']}\")\n",
    "\n",
    "print(f\"\\n‚öñÔ∏è Pesos Sin√°pticos:\")\n",
    "print(f\"  M√©dia: {stats['weights']['mean']:.4f}\")\n",
    "print(f\"  Desvio padr√£o: {stats['weights']['std']:.4f}\")\n",
    "print(f\"  Min: {stats['weights']['min']:.4f}\")\n",
    "print(f\"  Max: {stats['weights']['max']:.4f}\")\n",
    "\n",
    "# Visualizar arquitetura\n",
    "layer_sizes = [256, 128, 64, 2]\n",
    "layer_names = ['Input\\n(256)', 'Hidden 1\\n(128)', 'Hidden 2\\n(64)', 'Output\\n(2)']\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 6))\n",
    "\n",
    "# Desenhar camadas\n",
    "x_positions = np.linspace(0, 10, len(layer_sizes))\n",
    "max_size = max(layer_sizes)\n",
    "\n",
    "for i, (size, name, x) in enumerate(zip(layer_sizes, layer_names, x_positions)):\n",
    "    y_positions = np.linspace(0, max_size, size)\n",
    "    \n",
    "    # Limitar visualiza√ß√£o para camadas grandes\n",
    "    display_neurons = min(size, 20)\n",
    "    y_display = np.linspace(0, max_size, display_neurons)\n",
    "    \n",
    "    ax.scatter([x] * display_neurons, y_display, s=100, alpha=0.7, \n",
    "               color=f'C{i}', label=name, zorder=3)\n",
    "    \n",
    "    # Conectar com pr√≥xima camada\n",
    "    if i < len(layer_sizes) - 1:\n",
    "        next_x = x_positions[i + 1]\n",
    "        next_size = min(layer_sizes[i + 1], 20)\n",
    "        next_y = np.linspace(0, max_size, next_size)\n",
    "        \n",
    "        # Desenhar algumas conex√µes (amostra)\n",
    "        for y1 in y_display[::3]:\n",
    "            for y2 in next_y[::3]:\n",
    "                ax.plot([x, next_x], [y1, y2], 'k-', alpha=0.05, linewidth=0.5, zorder=1)\n",
    "\n",
    "ax.set_xlim(-1, 11)\n",
    "ax.set_ylim(-20, max_size + 20)\n",
    "ax.set_xticks(x_positions)\n",
    "ax.set_xticklabels(layer_names)\n",
    "ax.set_yticks([])\n",
    "ax.set_title('Arquitetura da Spiking Neural Network para Detec√ß√£o de Fraude', fontsize=14)\n",
    "ax.spines['left'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0cd59bc",
   "metadata": {},
   "source": [
    "## 5. Pipeline Completo\n",
    "\n",
    "Executar o pipeline de ponta a ponta: treinar e avaliar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d67fe06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializar pipeline\n",
    "print(\"Inicializando pipeline de detec√ß√£o de fraude...\")\n",
    "pipeline = FraudDetectionPipeline()\n",
    "\n",
    "# Split train/test - usar dados menores para demo r√°pida\n",
    "train_size = int(0.8 * len(df))\n",
    "train_data = df[:train_size].copy()\n",
    "test_data = df[train_size:].copy()\n",
    "\n",
    "# Para demo, usar apenas um subset pequeno do treino\n",
    "# Reduzido para 20 amostras para execu√ß√£o r√°pida em modo numpy (sem compila√ß√£o C++)\n",
    "train_subset_size = min(20, len(train_data))\n",
    "train_subset = train_data.sample(n=train_subset_size, random_state=42)\n",
    "\n",
    "print(f\"\\nüìä Divis√£o dos dados:\")\n",
    "print(f\"  Treino (subset para demo): {len(train_subset)} transa√ß√µes\")\n",
    "print(f\"  Teste:  {len(test_data)} transa√ß√µes\")\n",
    "print(f\"\\nüí° Nota: Usando subset reduzido para demonstra√ß√£o r√°pida\")\n",
    "\n",
    "print(\"\\n‚è≥ Iniciando treinamento com STDP...\")\n",
    "print(\"(Usando poucos epochs e dados reduzidos para demo r√°pida)\\n\")\n",
    "\n",
    "# Reduzir drasticamente para demo\n",
    "epochs = 2\n",
    "print(f\"üîÑ Treinamento: {epochs} epochs com {len(train_subset)} transa√ß√µes\")\n",
    "\n",
    "# Treinamento r√°pido\n",
    "start_time = time.time()\n",
    "print(\"Treinando...\")\n",
    "pipeline.train(train_subset, epochs=epochs)\n",
    "training_time = time.time() - start_time\n",
    "\n",
    "print(f\"\\n‚úÖ Treinamento conclu√≠do em {training_time:.1f}s\")\n",
    "print(f\"‚ö° Tempo m√©dio por epoch: {training_time/epochs:.2f}s\")\n",
    "print(f\"‚ö° Taxa: {len(train_subset) * epochs / training_time:.1f} transa√ß√µes/segundo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b7304d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avaliar no conjunto de teste\n",
    "print(\"üéØ Avaliando modelo no conjunto de teste...\")\n",
    "print(f\"Total de {len(test_data)} transa√ß√µes\\n\")\n",
    "\n",
    "# Avalia√ß√£o com tempo estimado\n",
    "start_eval = time.time()\n",
    "metrics = pipeline.evaluate(test_data)\n",
    "eval_time = time.time() - start_eval\n",
    "\n",
    "print(f\"\\n‚úÖ Avalia√ß√£o conclu√≠da em {eval_time:.2f}s\")\n",
    "print(f\"‚ö° Velocidade: {len(test_data)/eval_time:.1f} transa√ß√µes/segundo\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d27213",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar matriz de confus√£o\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "# Converter explicitamente para numpy arrays\n",
    "y_true = test_data['is_fraud'].to_numpy()\n",
    "y_pred = []\n",
    "\n",
    "print(\"üîÑ Gerando predi√ß√µes para matriz de confus√£o...\")\n",
    "for _, row in tqdm(test_data.iterrows(), total=len(test_data), desc=\"Predi√ß√µes\", unit=\"txn\"):\n",
    "    result = pipeline.predict(row.to_dict())\n",
    "    y_pred.append(int(result['is_fraud']))\n",
    "\n",
    "# Converter y_pred para numpy array\n",
    "y_pred = np.array(y_pred, dtype=int)\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['Leg√≠tima', 'Fraude'],\n",
    "            yticklabels=['Leg√≠tima', 'Fraude'],\n",
    "            cbar_kws={'label': 'Contagem'})\n",
    "ax.set_xlabel('Predi√ß√£o')\n",
    "ax.set_ylabel('Real')\n",
    "ax.set_title('Matriz de Confus√£o - Detec√ß√£o de Fraude Neurom√≥rfica')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n‚úÖ Acur√°cia: {metrics['accuracy']:.2%}\")\n",
    "print(f\"‚úÖ Precis√£o: {metrics['precision']:.2%}\")\n",
    "print(f\"‚úÖ Recall: {metrics['recall']:.2%}\")\n",
    "print(f\"‚úÖ F1-Score: {metrics['f1_score']:.2%}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42280973",
   "metadata": {},
   "source": [
    "## 6. Exemplos de Predi√ß√£o Individual\n",
    "\n",
    "Testar com transa√ß√µes espec√≠ficas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f933f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemplo 1: Transa√ß√£o leg√≠tima t√≠pica\n",
    "print(\"=\" * 60)\n",
    "print(\"EXEMPLO 1: Transa√ß√£o Leg√≠tima\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "legitimate_txn = {\n",
    "    'id': 'demo_001',\n",
    "    'amount': 85.50,\n",
    "    'timestamp': time.time(),\n",
    "    'merchant_category': 'groceries',\n",
    "    'location': (-23.5505, -46.6333),  # S√£o Paulo\n",
    "    'device_id': 'device_regular_001',\n",
    "    'daily_frequency': 3\n",
    "}\n",
    "\n",
    "result = pipeline.predict(legitimate_txn)\n",
    "\n",
    "print(f\"\\nTransa√ß√£o:\")\n",
    "print(f\"  Valor: ${legitimate_txn['amount']:.2f}\")\n",
    "print(f\"  Categoria: {legitimate_txn['merchant_category']}\")\n",
    "print(f\"  Localiza√ß√£o: S√£o Paulo\")\n",
    "\n",
    "print(f\"\\nüîç Resultado da An√°lise:\")\n",
    "print(f\"  Fraude detectada: {'‚ùå SIM' if result['is_fraud'] else '‚úÖ N√ÉO'}\")\n",
    "print(f\"  Confian√ßa: {result['confidence']:.2%}\")\n",
    "print(f\"  Score Leg√≠tima: {result['legitimate_score']:.2f} Hz\")\n",
    "print(f\"  Score Fraude: {result['fraud_score']:.2f} Hz\")\n",
    "print(f\"  Lat√™ncia: {result['latency_ms']:.2f}ms\")\n",
    "print(f\"  Spikes gerados: {result['n_spikes_generated']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e53466",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemplo 2: Transa√ß√£o suspeita (alta probabilidade de fraude)\n",
    "print(\"=\" * 60)\n",
    "print(\"EXEMPLO 2: Transa√ß√£o Suspeita\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "suspicious_txn = {\n",
    "    'id': 'demo_002',\n",
    "    'amount': 8500.00,  # Valor alto\n",
    "    'timestamp': time.time(),\n",
    "    'merchant_category': 'electronics',\n",
    "    'location': (51.5074, -0.1278),  # Londres (localiza√ß√£o incomum)\n",
    "    'device_id': 'device_new_unknown',  # Dispositivo novo\n",
    "    'daily_frequency': 25  # Frequ√™ncia anormal\n",
    "}\n",
    "\n",
    "result = pipeline.predict(suspicious_txn)\n",
    "\n",
    "print(f\"\\nTransa√ß√£o:\")\n",
    "print(f\"  Valor: ${suspicious_txn['amount']:.2f}\")\n",
    "print(f\"  Categoria: {suspicious_txn['merchant_category']}\")\n",
    "print(f\"  Localiza√ß√£o: Londres (incomum)\")\n",
    "print(f\"  Dispositivo: Novo/Desconhecido\")\n",
    "\n",
    "print(f\"\\nüîç Resultado da An√°lise:\")\n",
    "print(f\"  Fraude detectada: {'‚ùå SIM' if result['is_fraud'] else '‚úÖ N√ÉO'}\")\n",
    "print(f\"  Confian√ßa: {result['confidence']:.2%}\")\n",
    "print(f\"  Score Leg√≠tima: {result['legitimate_score']:.2f} Hz\")\n",
    "print(f\"  Score Fraude: {result['fraud_score']:.2f} Hz\")\n",
    "print(f\"  Lat√™ncia: {result['latency_ms']:.2f}ms\")\n",
    "print(f\"  Spikes gerados: {result['n_spikes_generated']}\")\n",
    "\n",
    "if result['is_fraud']:\n",
    "    print(f\"\\n‚ö†Ô∏è ALERTA: Transa√ß√£o bloqueada para an√°lise manual!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "692bb248",
   "metadata": {},
   "source": [
    "## 7. An√°lise de Performance\n",
    "\n",
    "Avaliar lat√™ncia e throughput do sistema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b29e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benchmark de lat√™ncia\n",
    "print(\"=== BENCHMARK DE LAT√äNCIA ===\")\n",
    "n_samples = min(100, len(test_data))\n",
    "print(f\"Testando {n_samples} transa√ß√µes...\\n\")\n",
    "\n",
    "latencies = []\n",
    "sample_txns = test_data.sample(n=n_samples)\n",
    "\n",
    "for _, row in tqdm(sample_txns.iterrows(), total=n_samples, desc=\"Benchmark\", unit=\"txn\"):\n",
    "    start = time.time()\n",
    "    result = pipeline.predict(row.to_dict())\n",
    "    latency = (time.time() - start) * 1000  # ms\n",
    "    latencies.append(latency)\n",
    "\n",
    "latencies = np.array(latencies)\n",
    "\n",
    "print(f\"\\nüìä Estat√≠sticas de Lat√™ncia:\")\n",
    "print(f\"  M√©dia:     {latencies.mean():.2f}ms\")\n",
    "print(f\"  Mediana:   {np.median(latencies):.2f}ms\")\n",
    "print(f\"  Min:       {latencies.min():.2f}ms\")\n",
    "print(f\"  Max:       {latencies.max():.2f}ms\")\n",
    "print(f\"  P95:       {np.percentile(latencies, 95):.2f}ms\")\n",
    "print(f\"  P99:       {np.percentile(latencies, 99):.2f}ms\")\n",
    "\n",
    "throughput = 1000 / latencies.mean()  # transa√ß√µes por segundo\n",
    "print(f\"\\n‚ö° Throughput estimado: {throughput:.0f} transa√ß√µes/segundo\")\n",
    "\n",
    "# Visualizar distribui√ß√£o\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "axes[0].hist(latencies, bins=30, color='skyblue', edgecolor='black', alpha=0.7)\n",
    "axes[0].axvline(latencies.mean(), color='red', linestyle='--', label=f'M√©dia: {latencies.mean():.2f}ms')\n",
    "axes[0].axvline(np.percentile(latencies, 95), color='orange', linestyle='--', label=f'P95: {np.percentile(latencies, 95):.2f}ms')\n",
    "axes[0].set_xlabel('Lat√™ncia (ms)')\n",
    "axes[0].set_ylabel('Frequ√™ncia')\n",
    "axes[0].set_title('Distribui√ß√£o de Lat√™ncia')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1].boxplot(latencies, vert=True)\n",
    "axes[1].set_ylabel('Lat√™ncia (ms)')\n",
    "axes[1].set_title('Boxplot de Lat√™ncia')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e126f205",
   "metadata": {},
   "source": [
    "## 8. Conclus√µes\n",
    "\n",
    "### ‚úÖ Vantagens da Abordagem Neurom√≥rfica\n",
    "\n",
    "1. **Ultra-baixa lat√™ncia**: Detec√ß√£o em ~10ms\n",
    "2. **Processamento temporal nativo**: Captura padr√µes de sequ√™ncia naturalmente\n",
    "3. **Efici√™ncia energ√©tica**: Ideal para deployment em edge devices\n",
    "4. **Aprendizado biol√≥gico**: STDP permite adapta√ß√£o cont√≠nua\n",
    "\n",
    "### üéØ Aplica√ß√µes em Bancos e Fintechs\n",
    "\n",
    "- Detec√ß√£o de fraude em tempo real no POS\n",
    "- Prote√ß√£o de transa√ß√µes Pix/TED/DOC\n",
    "- Monitoramento de carteiras digitais\n",
    "- An√°lise comportamental em mobile banking\n",
    "\n",
    "### üöÄ Pr√≥ximos Passos\n",
    "\n",
    "- Deploy em hardware neurom√≥rfico (Intel Loihi, IBM TrueNorth)\n",
    "- Integra√ß√£o com sistemas legados via API\n",
    "- Explicabilidade (SHAP para SNNs)\n",
    "- Federated learning entre institui√ß√µes\n",
    "\n",
    "---\n",
    "\n",
    "**Autor:** Mauro Risonho de Paula Assump√ß√£o  \n",
    "**Projeto:** Computa√ß√£o Neurom√≥rfica para Cybersecurity Banc√°ria"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
