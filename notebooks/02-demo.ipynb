{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8c4f587",
   "metadata": {},
   "source": [
    "# Demonstração: Detecção de Fraude Neuromórfica\n",
    "\n",
    "**Descrição:** Notebook interativo demonstrando o pipeline completo de detecção de fraude usando Spiking Neural Networks (SNNs), incluindo codificação de spikes, treinamento STDP, e análise de performance.\n",
    "\n",
    "**Autor:** Mauro Risonho de Paula Assumpção.\n",
    "**Data de Criação:** 5 de Dezembro de 2025.\n",
    "**Licença:** MIT License.\n",
    "**Desenvolvimento:** Humano + Desenvolvimento por AI Assistida (Claude Sonnet 4.5, Gemini 3 Pro Preview).\n",
    "\n",
    "---\n",
    "\n",
    "Este notebook demonstra o pipeline completo de detecção de fraude usando Spiking Neural Networks (SNNs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a287c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Adicionar src ao path\n",
    "# Notebook está em: Projeto-Neuromorfico-X/portfolio/01_fraud_neuromorphic/notebooks/\n",
    "# src está em: Projeto-Neuromorfico-X/portfolio/01_fraud_neuromorphic/src/\n",
    "notebook_dir = Path.cwd()\n",
    "\n",
    "# Verificar se estamos no diretório raiz do projeto ou no diretório notebooks\n",
    "if (notebook_dir / 'portfolio' / '01_fraud_neuromorphic' / 'src').exists():\n",
    "    # Estamos na raiz do projeto (Projeto-Neuromorfico-X)\n",
    "    src_path = notebook_dir / 'portfolio' / '01_fraud_neuromorphic' / 'src'\n",
    "elif (notebook_dir.parent / 'src').exists():\n",
    "    # Estamos em notebooks/\n",
    "    src_path = notebook_dir.parent / 'src'\n",
    "elif (notebook_dir / 'src').exists():\n",
    "    # Estamos em 01_fraud_neuromorphic/\n",
    "    src_path = notebook_dir / 'src'\n",
    "else:\n",
    "    src_path = None\n",
    "\n",
    "if src_path and src_path.exists():\n",
    "    if str(src_path) not in sys.path:\n",
    "        sys.path.insert(0, str(src_path))\n",
    "        print(f\"✓ Diretório src adicionado: {src_path}\")\n",
    "else:\n",
    "    print(f\"✗ Diretório src não encontrado!\")\n",
    "    print(f\"  Notebook dir: {notebook_dir}\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import time\n",
    "from tqdm.auto import tqdm\n",
    "import brian2\n",
    "\n",
    "# Configurar Brian2 para usar numpy (evita erros de compilação C++ e problemas com SymPy/Cython)\n",
    "brian2.prefs.codegen.target = \"numpy\"\n",
    "\n",
    "# Nossos módulos\n",
    "try:\n",
    "    from main import FraudDetectionPipeline, generate_synthetic_transactions\n",
    "    from encoders import RateEncoder, TemporalEncoder, PopulationEncoder, TransactionEncoder\n",
    "    from models_snn import FraudSNN, demonstrate_lif_neuron  # type: ignore[attr-defined]\n",
    "    print(\"✓ Importações dos módulos do projeto concluídas!\")\n",
    "except ImportError as e:\n",
    "    print(f\"✗ Erro ao importar módulos: {e}\")\n",
    "    print(f\"  sys.path: {sys.path[:3]}\")\n",
    "\n",
    "# Configuração de visualização\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b3c422e",
   "metadata": {},
   "source": [
    "## 2. Geração de Dados Sintéticos\n",
    "\n",
    "Vamos criar um dataset sintético de transações bancárias com padrões realistas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9542a0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gerar 1000 transações (5% fraudes)\n",
    "print(\"Gerando transações sintéticas...\")\n",
    "df = generate_synthetic_transactions(n=1000, fraud_ratio=0.05)\n",
    "\n",
    "print(f\"\\n Dataset gerado:\")\n",
    "print(f\"Total de transações: {len(df)}\")\n",
    "print(f\"Transações legítimas: {np.sum(df['is_fraud'] == 0)}\")\n",
    "print(f\"Transações fraudulentas: {np.sum(df['is_fraud'] == 1)}\")\n",
    "print(f\"Taxa de fraude: {df['is_fraud'].mean():.2%}\")\n",
    "\n",
    "# Mostrar primeiras linhas\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55178d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar distribuição de valores\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Distribuição de valores por classe\n",
    "df[df['is_fraud'] == 0]['amount'].hist(bins=50, alpha=0.7, label='Legítimas', ax=axes[0], color='green')\n",
    "df[df['is_fraud'] == 1]['amount'].hist(bins=30, alpha=0.7, label='Fraudulentas', ax=axes[0], color='red')\n",
    "axes[0].set_xlabel('Valor da Transação ($)')\n",
    "axes[0].set_ylabel('Frequência')\n",
    "axes[0].set_title('Distribuição de Valores por Classe')\n",
    "axes[0].legend()\n",
    "\n",
    "# Frequência diária por classe\n",
    "df.boxplot(column='daily_frequency', by='is_fraud', ax=axes[1])\n",
    "axes[1].set_xlabel('Classe (0=Legítima, 1=Fraude)')\n",
    "axes[1].set_ylabel('Frequência Diária')\n",
    "axes[1].set_title('Frequência de Transações por Classe')\n",
    "plt.suptitle('')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n Padrões observados:\")\n",
    "print(\" - Fraudes tendem a ter valores mais altos\")\n",
    "print(\" - Fraudes têm maior frequência de transações\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac22d44",
   "metadata": {},
   "source": [
    "## 3. Codificação de Spikes\n",
    "\n",
    "Demonstrar como features de transações são convertidas em spikes temporais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b29cf11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemplo de Rate Encoding\n",
    "print(\"=== RATE ENCODING ===\")\n",
    "print(\"Codifica valores contínuos como frequência de spikes\\n\")\n",
    "\n",
    "rate_encoder = RateEncoder(min_rate=1, max_rate=100, duration=0.1)\n",
    "\n",
    "# Testar com diferentes valores\n",
    "test_amounts = [100, 500, 1000, 5000, 10000]\n",
    "\n",
    "fig, axes = plt.subplots(len(test_amounts), 1, figsize=(12, 10))\n",
    "\n",
    "for idx, amount in enumerate(test_amounts):\n",
    "    spike_times = rate_encoder.encode(amount, min_val=0, max_val=10000)\n",
    "    \n",
    "    # Visualizar\n",
    "    if spike_times:\n",
    "        axes[idx].eventplot([spike_times], linewidths=2, colors='blue')\n",
    "        axes[idx].set_xlim(0, 0.1)\n",
    "        axes[idx].set_ylim(0.5, 1.5)\n",
    "        axes[idx].set_ylabel(f'${amount}')\n",
    "        axes[idx].set_title(f'Valor: ${amount} → {len(spike_times)} spikes')\n",
    "        axes[idx].grid(True, alpha=0.3)\n",
    "    \n",
    "axes[-1].set_xlabel('Tempo (segundos)')\n",
    "plt.suptitle('Rate Encoding: Valor → Frequência de Spikes', fontsize=14, y=1.0)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n✓ Observação: Valores maiores geram mais spikes (maior frequência)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3bd4fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemplo de Population Encoding (Geolocalização)\n",
    "print(\"=== POPULATION ENCODING ===\")\n",
    "print(\"Codifica valores usando múltiplos neurônios com campos receptivos\\n\")\n",
    "\n",
    "pop_encoder = PopulationEncoder(n_neurons=20, min_val=-1, max_val=1, sigma=0.15)\n",
    "\n",
    "# Testar com diferentes localizações\n",
    "test_locations = [-0.8, -0.3, 0.0, 0.4, 0.9]\n",
    "\n",
    "fig, axes = plt.subplots(2, 1, figsize=(14, 8))\n",
    "\n",
    "# Plot 1: Ativação dos neurônios\n",
    "for loc in test_locations:\n",
    "    activations = np.exp(-((pop_encoder.centers - loc) ** 2) / (2 * pop_encoder.sigma ** 2))\n",
    "    axes[0].plot(pop_encoder.centers, activations, marker='o', label=f'Localização = {loc:.1f}', alpha=0.7)\n",
    "\n",
    "axes[0].set_xlabel('Centro do Neurônio')\n",
    "axes[0].set_ylabel('Ativação')\n",
    "axes[0].set_title('Ativação da População de Neurônios por Localização')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Raster plot de spikes\n",
    "spike_data = []\n",
    "for idx, loc in enumerate(test_locations):\n",
    "    encoding = pop_encoder.encode(loc, duration=0.1)\n",
    "    if len(encoding.spike_times) > 0:\n",
    "        for t, n in zip(encoding.spike_times, encoding.neuron_indices):\n",
    "            spike_data.append([t, n + idx * 25]) # Offset for visualization\n",
    "\n",
    "if spike_data:\n",
    "    spike_array = np.array(spike_data)\n",
    "    axes[1].scatter(spike_array[:, 0], spike_array[:, 1], marker='|', s=100, alpha=0.6)\n",
    "\n",
    "axes[1].set_xlabel('Tempo (segundos)')\n",
    "axes[1].set_ylabel('Neurônio + Offset')\n",
    "axes[1].set_title('Spikes Gerados por População de Neurônios')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n✓ Observação: Cada localização ativa um grupo diferente de neurônios\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cccf508d",
   "metadata": {},
   "source": [
    "## 4. Arquitetura da SNN\n",
    "\n",
    "Visualizar e entender a arquitetura da Spiking Neural Network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68cc26d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstração de neurônio LIF individual\n",
    "print(\"=== LEAKY INTEGRATE-AND-FIRE NEURON ===\")\n",
    "print(\"Demonstração do comportamento de um neurônio LIF\\n\")\n",
    "\n",
    "lif_data = demonstrate_lif_neuron()  # type: ignore[name-defined]\n",
    "\n",
    "fig, axes = plt.subplots(2, 1, figsize=(14, 8), sharex=True)\n",
    "\n",
    "# Plot 1: Corrente de entrada\n",
    "axes[0].plot(lif_data['time'], lif_data['input'], color='blue', linewidth=2)\n",
    "axes[0].set_ylabel('Corrente de Entrada (I)')\n",
    "axes[0].set_title('Estímulo de Entrada (Step Current)')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Potencial de membrana e spikes\n",
    "axes[1].plot(lif_data['time'], lif_data['voltage'], color='green', linewidth=2, label='Potencial de Membrana')\n",
    "axes[1].axhline(-50, color='red', linestyle='--', label='Threshold (-50mV)', alpha=0.7)\n",
    "axes[1].axhline(-70, color='gray', linestyle='--', label='Resting (-70mV)', alpha=0.5)\n",
    "\n",
    "# Marcar spikes\n",
    "for spike_time in lif_data['spikes']:\n",
    "    axes[1].axvline(spike_time, color='red', alpha=0.3, linewidth=1)\n",
    "\n",
    "axes[1].set_xlabel('Tempo (ms)')\n",
    "axes[1].set_ylabel('Voltagem (mV)')\n",
    "axes[1].set_title(f'Potencial de Membrana (Total de {len(lif_data[\"spikes\"])} spikes)')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n✓ Análise:\")\n",
    "print(f\"  - Spikes detectados: {len(lif_data['spikes'])}\")\n",
    "print(f\"  - Frequência média: {len(lif_data['spikes']) / (lif_data['time'][-1] / 1000):.1f} Hz\")\n",
    "print(f\"  - ISI médio: {np.mean(np.diff(lif_data['spikes'])):.2f} ms\" if len(lif_data['spikes']) > 1 else \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830456a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estatísticas da arquitetura SNN\n",
    "print(\"=== ARQUITETURA DA SNN ===\")\n",
    "\n",
    "snn = FraudSNN(input_size=256, hidden_sizes=[128, 64], output_size=2)\n",
    "stats = snn.get_network_stats()  # type: ignore[attr-defined]\n",
    "\n",
    "print(f\"\\n✓ Estrutura da Rede:\")\n",
    "print(f\"  Input Layer: {stats['layers']['input']} neurônios\")\n",
    "print(f\"  Hidden Layer 1: {stats['layers']['hidden'][0]} neurônios (LIF)\")\n",
    "print(f\"  Hidden Layer 2: {stats['layers']['hidden'][1]} neurônios (LIF)\")\n",
    "print(f\"  Output Layer: {stats['layers']['output']} neurônios\")\n",
    "print(f\"\\n  Total de neurônios: {stats['total_neurons']}\")\n",
    "print(f\"  Total de sinapses: {stats['total_synapses']}\")\n",
    "\n",
    "print(f\"\\n✓ Pesos Sinápticos:\")\n",
    "print(f\"  Média: {stats['weights']['mean']:.4f}\")\n",
    "print(f\"  Desvio padrão: {stats['weights']['std']:.4f}\")\n",
    "print(f\"  Min: {stats['weights']['min']:.4f}\")\n",
    "print(f\"  Max: {stats['weights']['max']:.4f}\")\n",
    "\n",
    "# Visualizar arquitetura\n",
    "layer_sizes = [256, 128, 64, 2]\n",
    "layer_names = ['Input\\n(256)', 'Hidden 1\\n(128)', 'Hidden 2\\n(64)', 'Output\\n(2)']\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 6))\n",
    "\n",
    "# Desenhar camadas\n",
    "x_positions = np.linspace(0, 10, len(layer_sizes))\n",
    "max_size = max(layer_sizes)\n",
    "\n",
    "for i, (size, name, x) in enumerate(zip(layer_sizes, layer_names, x_positions)):\n",
    "    y_positions = np.linspace(0, max_size, size)\n",
    "    \n",
    "    # Limitar visualização para camadas grandes\n",
    "    display_neurons = min(size, 20)\n",
    "    y_display = np.linspace(0, max_size, display_neurons)\n",
    "    \n",
    "    ax.scatter([x] * display_neurons, y_display, s=100, alpha=0.7, \n",
    "               color=f'C{i}', label=name, zorder=3)\n",
    "    \n",
    "    # Conectar com próxima camada\n",
    "    if i < len(layer_sizes) - 1:\n",
    "        next_x = x_positions[i + 1]\n",
    "        next_size = min(layer_sizes[i + 1], 20)\n",
    "        next_y = np.linspace(0, max_size, next_size)\n",
    "        \n",
    "        # Desenhar algumas conexões (amostra)\n",
    "        for y1 in y_display[::3]:\n",
    "            for y2 in next_y[::3]:\n",
    "                ax.plot([x, next_x], [y1, y2], 'k-', alpha=0.05, linewidth=0.5, zorder=1)\n",
    "\n",
    "ax.set_xlim(-1, 11)\n",
    "ax.set_ylim(-20, max_size + 20)\n",
    "ax.set_xticks(x_positions)\n",
    "ax.set_xticklabels(layer_names)\n",
    "ax.set_yticks([])\n",
    "ax.set_title('Arquitetura da Spiking Neural Network para Detecção de Fraude', fontsize=14)\n",
    "ax.spines['left'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0cd59bc",
   "metadata": {},
   "source": [
    "## 5. Pipeline Completo\n",
    "\n",
    "Executar o pipeline de ponta a ponta: treinar e avaliar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d67fe06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializar pipeline\n",
    "print(\"Inicializando pipeline de detecção de fraude...\")\n",
    "pipeline = FraudDetectionPipeline()\n",
    "\n",
    "# Split train/test - usar dados menores para demo rápida\n",
    "train_size = int(0.8 * len(df))\n",
    "train_data = df[:train_size].copy()\n",
    "test_data = df[train_size:].copy()\n",
    "\n",
    "# Para demo, usar apenas um subset pequeno do treino\n",
    "# Reduzido para 20 amostras para execução rápida em modo numpy (sem compilação C++)\n",
    "train_subset_size = min(20, len(train_data))\n",
    "train_subset = train_data.sample(n=train_subset_size, random_state=42)\n",
    "\n",
    "print(f\"\\n Divisão dos dados:\")\n",
    "print(f\" Treino (subset para demo): {len(train_subset)} transações\")\n",
    "print(f\" Teste: {len(test_data)} transações\")\n",
    "print(f\"\\n Nota: Usando subset reduzido para demonstração rápida\")\n",
    "\n",
    "print(\"\\n⏳ Iniciando treinamento com STDP...\")\n",
    "print(\"(Usando poucos epochs e dados reduzidos para demo rápida)\\n\")\n",
    "\n",
    "# Reduzir drasticamente para demo\n",
    "epochs = 2\n",
    "print(f\" Treinamento: {epochs} epochs com {len(train_subset)} transações\")\n",
    "\n",
    "# Treinamento rápido\n",
    "start_time = time.time()\n",
    "print(\"Treinando...\")\n",
    "pipeline.train(train_subset, epochs=epochs)\n",
    "training_time = time.time() - start_time\n",
    "\n",
    "print(f\"\\n Treinamento concluído em {training_time:.1f}s\")\n",
    "print(f\" Tempo médio por epoch: {training_time/epochs:.2f}s\")\n",
    "print(f\" Taxa: {len(train_subset) * epochs / training_time:.1f} transações/segundo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b7304d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avaliar no conjunto de teste\n",
    "print(\" Avaliando modelo no conjunto de teste...\")\n",
    "print(f\"Total de {len(test_data)} transações\\n\")\n",
    "\n",
    "# Avaliação com tempo estimado\n",
    "start_eval = time.time()\n",
    "metrics = pipeline.evaluate(test_data)\n",
    "eval_time = time.time() - start_eval\n",
    "\n",
    "print(f\"\\n Avaliação concluída em {eval_time:.2f}s\")\n",
    "print(f\" Velocidade: {len(test_data)/eval_time:.1f} transações/segundo\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d27213",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar matriz de confusão\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "# Converter explicitamente para numpy arrays\n",
    "y_true = test_data['is_fraud'].to_numpy()\n",
    "y_pred = []\n",
    "\n",
    "print(\"✓ Gerando predições para matriz de confusão...\")\n",
    "for _, row in tqdm(test_data.iterrows(), total=len(test_data), desc=\"Predições\", unit=\"txn\"):\n",
    "    result = pipeline.predict(row.to_dict())\n",
    "    y_pred.append(int(result['is_fraud']))\n",
    "\n",
    "# Converter y_pred para numpy array\n",
    "y_pred = np.array(y_pred, dtype=int)\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['Legítima', 'Fraude'],\n",
    "            yticklabels=['Legítima', 'Fraude'],\n",
    "            cbar_kws={'label': 'Contagem'})\n",
    "ax.set_xlabel('Predição')\n",
    "ax.set_ylabel('Real')\n",
    "ax.set_title('Matriz de Confusão - Detecção de Fraude Neuromórfica')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n✓ Acurácia: {metrics['accuracy']:.2%}\")\n",
    "print(f\"  Precisão: {metrics['precision']:.2%}\")\n",
    "print(f\"  Recall: {metrics['recall']:.2%}\")\n",
    "print(f\"  F1-Score: {metrics['f1_score']:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42280973",
   "metadata": {},
   "source": [
    "## 6. Exemplos de Predição Individual\n",
    "\n",
    "Testar com transações específicas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f933f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemplo 1: Transação legítima típica\n",
    "print(\"=\" * 60)\n",
    "print(\"EXEMPLO 1: Transação Legítima\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "legitimate_txn = {\n",
    " 'id': 'demo_001',\n",
    " 'amount': 85.50,\n",
    " 'timestamp': time.time(),\n",
    " 'merchant_category': 'groceries',\n",
    " 'location': (-23.5505, -46.6333), # São Paulo\n",
    " 'device_id': 'device_regular_001',\n",
    " 'daily_frequency': 3\n",
    "}\n",
    "\n",
    "result = pipeline.predict(legitimate_txn)\n",
    "\n",
    "print(f\"\\nTransação:\")\n",
    "print(f\" Valor: ${legitimate_txn['amount']:.2f}\")\n",
    "print(f\" Categoria: {legitimate_txn['merchant_category']}\")\n",
    "print(f\" Localização: São Paulo\")\n",
    "\n",
    "print(f\"\\n Resultado da Análise:\")\n",
    "print(f\" Fraude detectada: {' SIM' if result['is_fraud'] else ' NÃO'}\")\n",
    "print(f\" Confiança: {result['confidence']:.2%}\")\n",
    "print(f\" Score Legítima: {result['legitimate_score']:.2f} Hz\")\n",
    "print(f\" Score Fraude: {result['fraud_score']:.2f} Hz\")\n",
    "print(f\" Latência: {result['latency_ms']:.2f}ms\")\n",
    "print(f\" Spikes gerados: {result['n_spikes_generated']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e53466",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemplo 2: Transação suspeita (alta probabilidade de fraude)\n",
    "print(\"=\" * 60)\n",
    "print(\"EXEMPLO 2: Transação Suspeita\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "suspicious_txn = {\n",
    " 'id': 'demo_002',\n",
    " 'amount': 8500.00, # Valor alto\n",
    " 'timestamp': time.time(),\n",
    " 'merchant_category': 'electronics',\n",
    " 'location': (51.5074, -0.1278), # Londres (localização incomum)\n",
    " 'device_id': 'device_new_unknown', # Dispositivo novo\n",
    " 'daily_frequency': 25 # Frequência anormal\n",
    "}\n",
    "\n",
    "result = pipeline.predict(suspicious_txn)\n",
    "\n",
    "print(f\"\\nTransação:\")\n",
    "print(f\" Valor: ${suspicious_txn['amount']:.2f}\")\n",
    "print(f\" Categoria: {suspicious_txn['merchant_category']}\")\n",
    "print(f\" Localização: Londres (incomum)\")\n",
    "print(f\" Dispositivo: Novo/Desconhecido\")\n",
    "\n",
    "print(f\"\\n Resultado da Análise:\")\n",
    "print(f\" Fraude detectada: {' SIM' if result['is_fraud'] else ' NÃO'}\")\n",
    "print(f\" Confiança: {result['confidence']:.2%}\")\n",
    "print(f\" Score Legítima: {result['legitimate_score']:.2f} Hz\")\n",
    "print(f\" Score Fraude: {result['fraud_score']:.2f} Hz\")\n",
    "print(f\" Latência: {result['latency_ms']:.2f}ms\")\n",
    "print(f\" Spikes gerados: {result['n_spikes_generated']}\")\n",
    "\n",
    "if result['is_fraud']:\n",
    " print(f\"\\n ALERTA: Transação bloqueada para análise manual!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "692bb248",
   "metadata": {},
   "source": [
    "## 7. Análise de Performance\n",
    "\n",
    "Avaliar latência e throughput do sistema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b29e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benchmark de latência\n",
    "print(\"=== BENCHMARK DE LATÊNCIA ===\")\n",
    "n_samples = min(100, len(test_data))\n",
    "print(f\"Testando {n_samples} transações...\\n\")\n",
    "\n",
    "latencies = []\n",
    "sample_txns = test_data.sample(n=n_samples)\n",
    "\n",
    "for _, row in tqdm(sample_txns.iterrows(), total=n_samples, desc=\"Benchmark\", unit=\"txn\"):\n",
    " start = time.time()\n",
    " result = pipeline.predict(row.to_dict())\n",
    " latency = (time.time() - start) * 1000 # ms\n",
    " latencies.append(latency)\n",
    "\n",
    "latencies = np.array(latencies)\n",
    "\n",
    "print(f\"\\n Estatísticas de Latência:\")\n",
    "print(f\" Média: {latencies.mean():.2f}ms\")\n",
    "print(f\" Mediana: {np.median(latencies):.2f}ms\")\n",
    "print(f\" Min: {latencies.min():.2f}ms\")\n",
    "print(f\" Max: {latencies.max():.2f}ms\")\n",
    "print(f\" P95: {np.percentile(latencies, 95):.2f}ms\")\n",
    "print(f\" P99: {np.percentile(latencies, 99):.2f}ms\")\n",
    "\n",
    "throughput = 1000 / latencies.mean() # transações por segundo\n",
    "print(f\"\\n Throughput estimado: {throughput:.0f} transações/segundo\")\n",
    "\n",
    "# Visualizar distribuição\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "axes[0].hist(latencies, bins=30, color='skyblue', edgecolor='black', alpha=0.7)\n",
    "axes[0].axvline(latencies.mean(), color='red', linestyle='--', label=f'Média: {latencies.mean():.2f}ms')\n",
    "axes[0].axvline(np.percentile(latencies, 95), color='orange', linestyle='--', label=f'P95: {np.percentile(latencies, 95):.2f}ms')\n",
    "axes[0].set_xlabel('Latência (ms)')\n",
    "axes[0].set_ylabel('Frequência')\n",
    "axes[0].set_title('Distribuição de Latência')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1].boxplot(latencies, vert=True)\n",
    "axes[1].set_ylabel('Latência (ms)')\n",
    "axes[1].set_title('Boxplot de Latência')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e126f205",
   "metadata": {},
   "source": [
    "## 8. Conclusões\n",
    "\n",
    "### Vantagens da Abordagem Neuromórfica\n",
    "\n",
    "1. **Ultra-baixa latência**: Detecção em ~10ms\n",
    "2. **Processamento temporal nativo**: Captura padrões de sequência naturalmente\n",
    "3. **Eficiência energética**: Ideal para deployment em edge devices\n",
    "4. **Aprendizado biológico**: STDP permite adaptação contínua\n",
    "\n",
    "### Aplicações em Bancos e Fintechs\n",
    "\n",
    "- Detecção de fraude em tempo real no POS\n",
    "- Proteção de transações Pix/TED/DOC\n",
    "- Monitoramento de carteiras digitais\n",
    "- Análise comportamental em mobile banking\n",
    "\n",
    "### Próximos Passos\n",
    "\n",
    "- Deploy em hardware neuromórfico (Intel Loihi, IBM TrueNorth)\n",
    "- Integração com sistemas legados via API\n",
    "- Explicabilidade (SHAP para SNNs)\n",
    "- Federated learning entre instituições\n",
    "\n",
    "---\n",
    "\n",
    "**Autor:** Mauro Risonho de Paula Assumpção \n",
    "**Projeto:** Computação Neuromórfica para Cybersecurity Bancária"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
