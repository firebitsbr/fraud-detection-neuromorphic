{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70d32b77",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.with/github/maurorisonho/fraud-detection-neuromorphic/blob/main/notebooks/01-stdp_example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.with/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc39bbca",
   "metadata": {
    "id": "dc39bbca"
   },
   "source": [
    "# STDP Example: Biological Learning\n",
    "\n",
    "**Description:** Interactive Tutorial about the biological learning mechanism STDP (Spike-Timing-Dependent Plasticity) used in neuromorphic neural networks. Demonstrates how neurons learn timeral correlations automatically.\n",
    "\n",
    "**Author:** Mauro Risonho de Paula AssumpÃ§Ã£o.\n",
    "**Creation Date:** December 5, 2025.\n",
    "**License:** MIT License.\n",
    "**Development:** Human + AI Assisted Development (Claude Sonnet 4.5, Gemini 3 Pro Preview).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec46581a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ec46581a",
    "outputId": "f535eb26-67b3-4567-f00f-8c95313f4ddf"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "# Install the Brian2 library if not yet installed\n",
    "try:\n",
    "    import brian2\n",
    "except ImportError:\n",
    "    !pip install brian2\n",
    "    import brian2\n",
    "\n",
    "# Specific imports from brian2 instead of wildcard\n",
    "from brian2 import (\n",
    "    ms, mV, Hz, second,\n",
    "    NeuronGroup, Synapses, SpikeMonitor, StateMonitor,\n",
    "    SpikeGeneratorGroup, Network,\n",
    "    defaultclock, run, device, start_scope,\n",
    "    clip, prefs\n",
    ")\n",
    "\n",
    "# Configure to use numpy (avoids C++ compilation errors if headers are missing)\n",
    "prefs.codegen.target = \"numpy\"\n",
    "\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"âœ“ Imports completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "803daf9a",
   "metadata": {
    "id": "803daf9a"
   },
   "source": [
    "# STDP: Spike-Timing-Dependent Plasticity\n",
    "\n",
    "**Description:** Interactive Tutorial about the biological learning mechanism STDP (Spike-Timing-Dependent Plasticity) used in neuromorphic neural networks. Demonstrates how neurons learn timeral correlations automatically.\n",
    "\n",
    "**Author:** Mauro Risonho de Paula AssumpÃ§Ã£o\n",
    "**Creation Date:** December 5, 2025\n",
    "**License:** MIT License\n",
    "**Development:** Human + AI-Assisted Development (Claude Sonnet 4.5, Gemini 3 Pro Preview).\n",
    "\n",
    "---\n",
    "\n",
    "This notebook explores the biological learning mechanism **STDP** used in neuromorphic neural networks.\n",
    "\n",
    "## What is STDP?\n",
    "\n",
    "STDP (Spike-Timing-Dependent Plasticity) is an **unsupervised** learning rule inspired by biological neurons:\n",
    "\n",
    "- **if the pre-synaptic neuron fires BEFORE the post-synaptic** â†’ **Potentiation** (weight â†‘)\n",
    "- **if the pre-synaptic neuron fires AFTER the post-synaptic** â†’ **Depression** (weight â†“)\n",
    "\n",
    "This allows the network to learn **timeral causal relationships** without explicit labels.\n",
    "\n",
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f140a7",
   "metadata": {
    "id": "e8f140a7"
   },
   "source": [
    "## 1. Classic STDP Curve\n",
    "\n",
    "Visualize how the change in weight depends on the timeral difference between spikes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39341177",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 694
    },
    "id": "39341177",
    "outputId": "21c88645-a928-4204-9654-4fa9a893b3c7"
   },
   "outputs": [],
   "source": [
    "# STDP Parameters\n",
    "tau_pre = 20.0 # ms - pre-synaptic time constant\n",
    "tau_post = 20.0 # ms - post-synaptic time constant\n",
    "A_pre = 0.01 # Potentiation Amplitude\n",
    "A_post = -0.012 # Depression Amplitude\n",
    "\n",
    "# Delta t (time difference)\n",
    "dt_range = np.linspace(-100, 100, 500) # ms\n",
    "\n",
    "# Calculate weight change\n",
    "def stdp_weight_change(dt, tau_pre, tau_post, A_pre, A_post):\n",
    "    \"\"\"\n",
    "    Calculates weight change via STDP.\n",
    "    dt = t_post - t_pre\n",
    "    \"\"\"\n",
    "    if dt > 0: # Post after Pre â†’ Potentiation\n",
    "        return A_pre * np.exp(-dt / tau_pre)\n",
    "    else: # Post before Pre â†’ Depression\n",
    "        return A_post * np.exp(dt / tau_post)\n",
    "\n",
    "weight_changes = np.array([stdp_weight_change(dt, tau_pre, tau_post, A_pre, A_post)\n",
    "                           for dt in dt_range])\n",
    "\n",
    "# Plot STDP curve\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "ax.plot(dt_range, weight_changes, linewidth=3, color='purple')\n",
    "ax.axhline(0, color='black', linestyle='--', linewidth=1, alpha=0.5)\n",
    "ax.axvline(0, color='black', linestyle='--', linewidth=1, alpha=0.5)\n",
    "\n",
    "# Annotate regions\n",
    "ax.fill_between(dt_range[dt_range > 0], 0, weight_changes[dt_range > 0],\n",
    "                alpha=0.2, color='green', label='Potentiation (LTP)')\n",
    "ax.fill_between(dt_range[dt_range < 0], 0, weight_changes[dt_range < 0],\n",
    "                alpha=0.2, color='red', label='Depression (LTD)')\n",
    "\n",
    "ax.set_xlabel('Î”t = t_post - t_pre (ms)', fontsize=12)\n",
    "ax.set_ylabel('Weight Change (Î”w)', fontsize=12)\n",
    "ax.set_title('STDP Curve: Spike-Timing-Dependent Plasticity', fontsize=14, fontweight='bold')\n",
    "ax.legend(fontsize=11)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Add annotations\n",
    "ax.annotate('Pre â†’ Post\\n(Causal)', xy=(20, 0.008), fontsize=10,\n",
    "            ha='center', color='green', fontweight='bold')\n",
    "ax.annotate('Post â†’ Pre\\n(Anti-causal)', xy=(-20, -0.009), fontsize=10,\n",
    "            ha='center', color='red', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nâœ“ Interpretation:\")\n",
    "print(\"  - Î”t > 0: pre-synaptic neuron fires BEFORE â†’ Potentiation (strengthens connection)\")\n",
    "print(\"  - Î”t < 0: pre-synaptic neuron fires AFTER â†’ Depression (weakens connection)\")\n",
    "print(\"  - Effect decays exponentially with |Î”t|\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b3ec008",
   "metadata": {
    "id": "9b3ec008"
   },
   "source": [
    "PT_## 2. Simulation STDP with Brian2\n",
    "\n",
    "Simulate two neurons connected with STDP and observe weight evolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596a82cd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "596a82cd",
    "outputId": "0de93294-7a96-4909-8e4f-df128e93956d"
   },
   "outputs": [],
   "source": [
    "start_scope()\n",
    "\n",
    "# Simulation parameters\n",
    "duration = 100*ms  # type: ignore[operator]\n",
    "defaultclock.dt = 0.1*ms  # type: ignore[operator]\n",
    "\n",
    "print(\"âš™ï¸ Configuring STDP simulation...\")\n",
    "print(f\"Duration: {duration}\")\n",
    "print(f\"Time step: {defaultclock.dt}\\n\")\n",
    "\n",
    "# LIF neurons\n",
    "tau_m = 10*ms  # type: ignore[operator]\n",
    "tau_syn = 5*ms  # type: ignore[operator] # Synaptic time constant\n",
    "v_rest = -70*mV\n",
    "v_thresh = -50*mV\n",
    "v_reset = -70*mV\n",
    "\n",
    "# Added synaptic decay (dI_syn/dt)\n",
    "eqs_post = '''\n",
    "dv/dt = (v_rest - v + I_syn) / tau_m : volt\n",
    "dI_syn/dt = -I_syn / tau_syn : volt\n",
    "'''\n",
    "\n",
    "# Create neurons\n",
    "neuron_pre = SpikeGeneratorGroup(1, [0], [10]*ms)  # type: ignore[operator]\n",
    "neuron_post = NeuronGroup(1, eqs_post, threshold='v > v_thresh',\n",
    "                          reset='v = v_reset', method='euler')\n",
    "neuron_post.v = v_rest\n",
    "neuron_post.I_syn = 0*mV\n",
    "\n",
    "# STDP Parameters\n",
    "tau_pre_stdp = 20*ms  # type: ignore[operator]\n",
    "tau_post_stdp = 20*ms  # type: ignore[operator]\n",
    "A_pre_stdp = 0.01\n",
    "A_post_stdp = -0.012\n",
    "w_max = 1.0\n",
    "w_min = 0.0\n",
    "\n",
    "synapse_model = '''\n",
    "w : 1\n",
    "dApre/dt = -Apre / tau_pre_stdp : 1 (event-driven)\n",
    "dApost/dt = -Apost / tau_post_stdp : 1 (event-driven)\n",
    "'''\n",
    "\n",
    "# Increased synaptic gain to ensure firing (w * 60*mV)\n",
    "on_pre_stdp = '''\n",
    "I_syn_post += w * 60 * mV\n",
    "Apre += A_pre_stdp\n",
    "w = clip(w + Apost, w_min, w_max)\n",
    "'''\n",
    "\n",
    "on_post_stdp = '''\n",
    "Apost += A_post_stdp\n",
    "w = clip(w + Apre, w_min, w_max)\n",
    "'''\n",
    "\n",
    "synapse = Synapses(neuron_pre, neuron_post,\n",
    "                   model=synapse_model,\n",
    "                   on_pre=on_pre_stdp,\n",
    "                   on_post=on_post_stdp,\n",
    "                   method='euler')\n",
    "synapse.connect(i=0, j=0)\n",
    "synapse.w = 0.5 # weight Initial\n",
    "\n",
    "# Monitores\n",
    "mon_pre = SpikeMonitor(neuron_pre)\n",
    "mon_post = SpikeMonitor(neuron_post)\n",
    "mon_weight = StateMonitor(synapse, 'w', record=True)\n",
    "mon_voltage = StateMonitor(neuron_post, 'v', record=True)\n",
    "\n",
    "# Execute simulation\n",
    "print(\"â³ Executing Brian2 simulation...\")\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "net = Network(neuron_pre, neuron_post, synapse, mon_pre, mon_post, mon_weight, mon_voltage)\n",
    "net.run(duration)\n",
    "\n",
    "sim_time = time.time() - start_time\n",
    "\n",
    "print(f\"âœ… Simulation completed in {sim_time:.3f}s!\")\n",
    "print(f\"\\n Results:\")\n",
    "print(f\" Pre-synaptic spikes: {len(mon_pre.t)}\")\n",
    "print(f\" Spikes post-synaptics: {len(mon_post.t)}\")\n",
    "print(f\" weight Initial: {0.5:.3f}\")\n",
    "print(f\" weight Final: {mon_weight.w[0][-1]:.3f}\")\n",
    "print(f\" Change: {(mon_weight.w[0][-1] - 0.5):.3f} ({(mon_weight.w[0][-1] - 0.5)/0.5*100:+.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09eb07f1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "09eb07f1",
    "outputId": "58973737-ad04-4767-eefa-d0033b3c5716"
   },
   "outputs": [],
   "source": [
    "# Visualize results\n",
    "fig, axes = plt.subplots(3, 1, figsize=(14, 10), sharex=True)\n",
    "\n",
    "# Plot 1: Spikes\n",
    "if len(mon_pre.t) > 0:\n",
    "    axes[0].eventplot([mon_pre.t/ms], lineoffsets=1, linelengths=0.8,\n",
    "                      linewidths=2, colors='blue', label='pre-synaptic')\n",
    "if len(mon_post.t) > 0:\n",
    "    axes[0].eventplot([mon_post.t/ms], lineoffsets=0, linelengths=0.8,\n",
    "                      linewidths=2, colors='red', label='post-synaptic')\n",
    "\n",
    "axes[0].set_ylabel('neuron')\n",
    "axes[0].set_yticks([0, 1])\n",
    "axes[0].set_yticklabels(['Post', 'Pre'])\n",
    "axes[0].set_title('Raster Plot: Pre and Post-Synaptic Spikes', fontsize=12, fontweight='bold')\n",
    "axes[0].legend(loc='upper right')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Evolution of the Synaptic weight\n",
    "axes[1].plot(mon_weight.t/ms, mon_weight.w[0], linewidth=2.5, color='purple')\n",
    "axes[1].axhline(0.5, color='gray', linestyle='--', alpha=0.5, label='weight Initial')\n",
    "axes[1].set_ylabel('weight Synaptic (w)')\n",
    "axes[1].set_title('Evolution of the Synaptic weight with STDP', fontsize=12, fontweight='bold')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 3: Voltage of the neuron post-synaptic\n",
    "axes[2].plot(mon_voltage.t/ms, mon_voltage.v[0]/mV, linewidth=1.5, color='green')\n",
    "axes[2].axhline(-50, color='red', linestyle='--', alpha=0.7, label='Threshold')\n",
    "axes[2].axhline(-70, color='gray', linestyle='--', alpha=0.5, label='Resting')\n",
    "axes[2].set_xlabel('time (ms)')\n",
    "axes[2].set_ylabel('Voltage (mV)')\n",
    "axes[2].set_title('Potencial of Membrana post-synaptic', fontsize=12, fontweight='bold')\n",
    "axes[2].legend()\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca5113d",
   "metadata": {
    "id": "eca5113d"
   },
   "source": [
    "## 3. STDP with Input Patterns\n",
    "\n",
    "Demonstrate how STDP learns temporal correlations in repeated patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a5e69b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "54a5e69b",
    "outputId": "9dff6a0b-ec3e-4147-e20d-e2f950a8c9ba"
   },
   "outputs": [],
   "source": [
    "start_scope()\n",
    "\n",
    "# Simulate multiple pre-synaptic neurons\n",
    "n_pre = 5\n",
    "n_post = 1\n",
    "duration = 500*ms  # type: ignore[operator]\n",
    "defaultclock.dt = 0.1*ms  # type: ignore[operator]\n",
    "\n",
    "print(\"âš™ï¸ Configuring simulation with multiple neurons...\")\n",
    "print(f\"Pre-synaptic neurons: {n_pre}\")\n",
    "print(f\"Duration: {duration}\\n\")\n",
    "\n",
    "# Generate temporal pattern (some neurons fire in sequence)\n",
    "spike_pattern = [\n",
    "    [10, 110, 210, 310, 410], # neuron 0: regular spikes\n",
    "    [15, 115, 215, 315, 415], # neuron 1: slightly delayed\n",
    "    [20, 120, 220, 320, 420], # neuron 2: more delayed\n",
    "    [100, 200, 300, 400], # neuron 3: sparse spikes\n",
    "    [50, 150, 250, 350, 450] # neuron 4: different phase\n",
    "]\n",
    "\n",
    "indices = []\n",
    "times = []\n",
    "print(\"ðŸ“Š Spike patterns:\")\n",
    "for neuron_idx, spike_times in enumerate(spike_pattern):\n",
    "    print(f\"  Neuron {neuron_idx}: {len(spike_times)} spikes\")\n",
    "    for t in spike_times:\n",
    "        indices.append(neuron_idx)\n",
    "        times.append(t)\n",
    "\n",
    "neuron_pre = SpikeGeneratorGroup(n_pre, indices, times*ms)  # type: ignore[operator]\n",
    "\n",
    "# neuron post-synaptic\n",
    "neuron_post = NeuronGroup(n_post, eqs_post, threshold='v > v_thresh',\n",
    "                          reset='v = v_reset', method='euler')\n",
    "neuron_post.v = v_rest\n",
    "\n",
    "# Synapses with STDP\n",
    "synapse = Synapses(neuron_pre, neuron_post,\n",
    "                   model=synapse_model,\n",
    "                   on_pre=on_pre_stdp,\n",
    "                   on_post=on_post_stdp,\n",
    "                   method='euler')\n",
    "synapse.connect() # Connect all\n",
    "synapse.w = 'rand() * 0.3 + 0.2' # Random initial weights [0.2, 0.5]\n",
    "\n",
    "# Monitores\n",
    "mon_pre = SpikeMonitor(neuron_pre)\n",
    "mon_post = SpikeMonitor(neuron_post)\n",
    "mon_weight = StateMonitor(synapse, 'w', record=True)\n",
    "\n",
    "# Save weights initial\n",
    "initial_weights = np.array(synapse.w).copy()\n",
    "\n",
    "# Execute\n",
    "print(\"\\nâ³ Executing simulation of temporal patterns...\")\n",
    "start_time = time.time()\n",
    "\n",
    "net = Network(neuron_pre, neuron_post, synapse, mon_pre, mon_post, mon_weight)\n",
    "net.run(duration)\n",
    "\n",
    "sim_time = time.time() - start_time\n",
    "final_weights = np.array(synapse.w).copy()\n",
    "\n",
    "print(f\"âœ… Simulation completed in {sim_time:.3f}s!\")\n",
    "print(f\"\\nðŸ“Š Synaptic Weights Analysis:\")\n",
    "for i in range(n_pre):\n",
    "    delta = final_weights[i] - initial_weights[i]\n",
    "    percentage = (delta / initial_weights[i]) * 100 if initial_weights[i] > 0 else 0\n",
    "    print(f\"  Neuron {i}: {initial_weights[i]:.3f} â†’ {final_weights[i]:.3f} (Î” = {delta:+.3f}, {percentage:+.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19bb0d87",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "19bb0d87",
    "outputId": "d2ea0cdd-f24f-4464-bb7e-e07058947ddb"
   },
   "outputs": [],
   "source": [
    "# Visualize evolution of the weights\n",
    "fig, axes = plt.subplots(2, 1, figsize=(14, 10))\n",
    "\n",
    "# Plot 1: Temporal evolution of weights\n",
    "for i in range(n_pre):\n",
    " axes[0].plot(mon_weight.t/ms, mon_weight.w[i], label=f'Synapse {i}', linewidth=2)\n",
    "\n",
    "axes[0].set_xlabel('Time (ms)')\n",
    "axes[0].set_ylabel('Synaptic Weight')\n",
    "axes[0].set_title('Temporal Evolution of Synaptic Weights with STDP', fontsize=12, fontweight='bold')\n",
    "axes[0].legend(loc='best')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Comparison before/after\n",
    "x_pos = np.arange(n_pre)\n",
    "width = 0.35\n",
    "\n",
    "axes[1].bar(x_pos - width/2, initial_weights, width, label='Initial', alpha=0.7, color='lightblue')\n",
    "axes[1].bar(x_pos + width/2, final_weights, width, label='Final', alpha=0.7, color='darkblue')\n",
    "\n",
    "axes[1].set_xlabel('Pre-synaptic Neuron')\n",
    "axes[1].set_ylabel('Synaptic Weight')\n",
    "axes[1].set_title('Comparison: Initial vs Final Weights', fontsize=12, fontweight='bold')\n",
    "axes[1].set_xticks(x_pos)\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nðŸ’¡ Interpretation:\")\n",
    "print(\"  - Neurons that fire consistently BEFORE the post-synaptic neuron are reinforced\")\n",
    "print(\"  - Neurons with inconsistent timing have reduced weights\")\n",
    "print(\"  - The network learns temporal correlations automatically!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e349a918",
   "metadata": {
    "id": "e349a918"
   },
   "source": [
    "## 4. Application to Fraud Detection\n",
    "\n",
    "How does STDP help in fraud detection?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a44a316",
   "metadata": {
    "id": "1a44a316"
   },
   "source": [
    "### Scenario 1: Normal Temporal Sequence\n",
    "\n",
    "**Legitimate Transaction:**\n",
    "1. Login to the app (t=0ms)\n",
    "2. Navigation to balance (t=500ms)\n",
    "3. Selection of known beneficiary (t=2000ms)\n",
    "4. Payment confirmation (t=3000ms)\n",
    "\n",
    "**STDP learns:**\n",
    "- Expected causal sequence\n",
    "- Normal temporal intervals\n",
    "- Reinforces connections that represent legitimate behavior\n",
    "\n",
    "### Scenario 2: Anomalous Sequence (Fraud)\n",
    "\n",
    "**Fraudulent Transaction:**\n",
    "1. Login to the app (t=0ms)\n",
    "2. Immediate transfer without navigation (t=50ms)\n",
    "3. High value to new beneficiary (t=100ms)\n",
    "4. Inconsistent geographic location (t=150ms)\n",
    "\n",
    "**STDP detects:**\n",
    "- Anomalous temporal pattern\n",
    "- Sequence not reinforced during training\n",
    "- High activation of \"fraud\" neurons\n",
    "\n",
    "### Advantages of STDP:\n",
    "\n",
    "1. **Unsupervised learning**: No need for explicit labels initially\n",
    "2. **Continuous adaptation**: Learns new fraud patterns automatically\n",
    "3. **Temporal sensitivity**: Detects anomalies in event sequences\n",
    "4. **Efficiency**: Local weight updates (without backpropagation)\n",
    "5. **Biologically plausible**: Inspired by the human brain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6dc0de9",
   "metadata": {
    "id": "f6dc0de9"
   },
   "source": [
    "## 5. Conclusions\n",
    "\n",
    "### STDP in Fraud Detection\n",
    "\n",
    "**Mechanism:**\n",
    "- Learns temporal correlations between transaction features\n",
    "- Reinforces frequent legitimate patterns\n",
    "- Detects deviations in temporal sequences\n",
    "\n",
    "**Practical Applications:**\n",
    "1. **Behavior analysis**: Sequence of actions in mobile banking\n",
    "2. **Velocity detection**: Impossible transactions (e.g., purchases in different cities within minutes)\n",
    "3. **Usage patterns**: Schedules, frequency, typical values\n",
    "4. **Suspicious navigation**: Atypical page sequences\n",
    "\n",
    "**Comparison with Traditional Methods:**\n",
    "\n",
    "| Feature | STDP/SNN | DNN/LSTM |\n",
    "|----------------|----------|----------|\n",
    "| Temporal processing | Native | Emulated |\n",
    "| Supervision | No | Yes |\n",
    "| Latency | Ultra-low (~ms) | High (~100ms) |\n",
    "| Energy consumption | Very low | High |\n",
    "| Online adaptation | Yes | Difficult |\n",
    "| Specialized hardware | Yes (Loihi, TrueNorth) | GPU |\n",
    "\n",
    "### Future Directions\n",
    "\n",
    "- Dedicated neuromorphic chips (Intel Loihi 2, IBM NorthPole)\n",
    "- STDP + Reward modulation (artificial dopamine)\n",
    "- Federated learning with STDP\n",
    "- Explainability: Visualize learned weights\n",
    "\n",
    "---\n",
    "\n",
    "**Author:** Mauro Risonho de Paula AssumpÃ§Ã£o\n",
    "**Project:** Neuromorphic Computing for Banking Cybersecurity"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "fraud-detection-neuromorphic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
