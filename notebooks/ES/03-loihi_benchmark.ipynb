{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "ed5a3e24",
      "metadata": {},
      "source": [
        "# Evaluaci√≥n de Hardware: Loihi vs CPU\n",
        "\n",
        "**Descripci√≥n:** Tutorial interactivo about the biological learning mechanism STDP (Spike-Timing-Dependent Plasticity) used in neurom√≥rfico neural networks. Demonstrates how neurons learn temporal correlations autom√°ticamente.\n",
        "\n",
        "**Autor:** Mauro Risonho de Paula Assump√ß√£o.\n",
        "**Fecha de creaci√≥n:** December 5, 2025.\n",
        "**Licencia:** MIT License.\n",
        "**Desarrollo:** Human + AI Assisted Development (Claude Sonnet 4.5, Gemini 3 Pro Preview).\n",
        "\n",
        "---\n",
        "\n",
        "## Objetivo\n",
        "\n",
        "Compare the performance of fraud detection implementation with SNN in:\n",
        "- **CPU Tradicional** (Brian2 yesulator)\n",
        "- **Intel Loihi 2** (yesulation of hardware neurom√≥rfico)\n",
        "\n",
        "## M√©tricas evaluadas\n",
        "\n",
        "1. **latencia** (ms per inference)\n",
        "2. **Rendimiento** (transactions by per)\n",
        "3. **energ√≠a** (millijoules)\n",
        "4. **potencia** (milliwatts)\n",
        "5. **eficiencia** (speedup e potencia eficiencia)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "491bb418",
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "# Determine the project root directory\n",
        "# The notebook is in: portfolio/01_fraud_neurom√≥rfico/notebooks/\n",
        "# We need to reach: portfolio/01_fraud_neurom√≥rfico/\n",
        "notebook_dir = Path.cwd()\n",
        "if 'notebooks' in str(notebook_dir):\n",
        "    # If we are in .../portfolio/01_fraud_neurom√≥rfico/notebooks\n",
        "    project_root = notebook_dir.parent if notebook_dir.name == 'notebooks' else notebook_dir\n",
        "elif '01_fraud_neurom√≥rfico' not in str(notebook_dir):\n",
        "    # If we are in repository root, navigate to the project\n",
        "    project_root = notebook_dir / 'portfolio' / '01_fraud_neurom√≥rfico'\n",
        "else:\n",
        "    # Already in the project root directory\n",
        "    project_root = notebook_dir\n",
        "\n",
        "src_path = project_root / 'src'\n",
        "hardware_path = project_root / 'hardware'\n",
        "\n",
        "# Remove previous paths if they exist to avoid duplicates\n",
        "for path in [str(src_path), str(hardware_path)]:\n",
        "    if path in sys.path:\n",
        "        sys.path.remove(path)\n",
        "\n",
        "# Add to the start of path\n",
        "sys.path.insert(0, str(src_path))\n",
        "sys.path.insert(0, str(hardware_path))\n",
        "\n",
        "# Verificar if the directories exist\n",
        "print(f\" Current directory: {notebook_dir}\")\n",
        "print(f\" Project root: {project_root}\")\n",
        "print(f\" Src path exists: {src_path.exists()}\")\n",
        "print(f\" Hardware path exists: {hardware_path.exists()}\")\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import time\n",
        "from tqdm.auto import tqdm\n",
        "import brian2\n",
        "\n",
        "# Configurar Brian2 to use numpy (avoids errors from compilation C++ and problems with SymPy/Cython)\n",
        "# Isso also suprime os logs of compilation of Cython que voc√™ estava vendo\n",
        "brian2.prefs.codegen.target = \"numpy\"\n",
        "\n",
        "# Importaciones of the project - directly since already in sys.path\n",
        "from main import FraudDetectionPipeline, generate_synthetic_transactions\n",
        "from loihi_simulator import LoihiSimulator, compare_with_cpu, LoihiSpecs # type: ignore\n",
        "\n",
        "# Configurar visualization\n",
        "plt.style.use('seaborn-v0_8-darkgrid')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b5c16e29",
      "metadata": {},
      "source": [
        "## 1. CPU Evaluaci√≥n\n",
        "\n",
        "First, let's measure the real performance of the implementation running on CPU."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dae7c4b7",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generar test dataset\n",
        "print(\" Generando test dataset...\")\n",
        "df_train = generate_synthetic_transactions(n=500, fraud_ratio=0.2)\n",
        "df_test = generate_synthetic_transactions(n=1000, fraud_ratio=0.2)\n",
        "\n",
        "# Separar features e labels\n",
        "feature_cols = ['amount', 'daily_frequency']\n",
        "X_train = df_train[feature_cols].values\n",
        "y_train = df_train['is_fraud'].values\n",
        "X_test = df_test[feature_cols].values\n",
        "y_test = df_test['is_fraud'].values\n",
        "\n",
        "print(f\"Train: X={X_train.shape}, y={y_train.shape}\")\n",
        "print(f\"Test: X={X_test.shape}, y={y_test.shape}\")\n",
        "\n",
        "# Converter for numpy array explicitamente for evitar errors of tipagem of Pylance\n",
        "y_train_np = np.array(y_train)\n",
        "y_test_np = np.array(y_test)\n",
        "\n",
        "print(f\"Fraudes no treino: {int(np.sum(y_train_np))}/{len(y_train_np)} ({float(np.mean(y_train_np))*100:.1f}%)\")\n",
        "print(f\"Fraudes no Test: {int(np.sum(y_test_np))}/{len(y_test_np)} ({float(np.mean(y_test_np))*100:.1f}%)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "83a4d2c5",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initializar model (usar without training for inference benchmark)\n",
        "print(\" Initializando pipeline SNN...\")\n",
        "pipeline = FraudDetectionPipeline()\n",
        "\n",
        "print(\" Pipeline initialized\")\n",
        "print(\" Nota: This benchmark focuses on INFERENCE latencia\")\n",
        "print(\" The model is using random weights - in production would be pre-trained\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d3d66499",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Important: Reload modules after corrections\n",
        "import importlib\n",
        "import sys\n",
        "\n",
        "# Reload project modules\n",
        "if 'models_snn' in sys.modules:\n",
        " importlib.reload(sys.modules['models_snn'])\n",
        "if 'encoders' in sys.modules:\n",
        " importlib.reload(sys.modules['encoders'])\n",
        "if 'main' in sys.modules:\n",
        " importlib.reload(sys.modules['main'])\n",
        "\n",
        "# Reimport after reload\n",
        "from main import FraudDetectionPipeline, generate_synthetic_transactions\n",
        "\n",
        "print(\"‚úÖ Modules reloaded with dt=0.1ms corrections\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1b879705",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Reinitialize pipeline with corrected modules\n",
        "print(\"‚öôÔ∏è Reinitializing SNN pipeline with dt=0.1ms...\")\n",
        "pipeline = FraudDetectionPipeline()\n",
        "\n",
        "print(\"‚úÖ Pipeline reinitialized\")\n",
        "print(\"üí° Note: Now using Brian2 dt=0.1ms (100 microseconds)\")\n",
        "print(\"‚úÖ This eliminates duplicate spike conflicts\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ae613912",
      "metadata": {},
      "outputs": [],
      "source": [
        "# CPU inference benchmark\n",
        "print(\"‚è± CPU Inference Evaluaci√≥n\\n\")\n",
        "\n",
        "# Garantir que num_samples esteja definido (c√©lula can ser executada isoladamente)\n",
        "if 'num_samples' not in globals():\n",
        "    num_samples = 100  # Reduzido of 1000 for speed\n",
        "latencies_cpu = []\n",
        "\n",
        "print(f\"Processando {num_samples} amostras...\")\n",
        "\n",
        "for i in tqdm(range(num_samples), desc=\"CPU Inferences\"):\n",
        "    transaction = df_test.iloc[i].to_dict()\n",
        "\n",
        "    try:\n",
        "        start = time.perf_counter()\n",
        "        prediction = pipeline.predict(transaction)\n",
        "        end = time.perf_counter()\n",
        "\n",
        "        latency_ms = (end - start) * 1000\n",
        "        latencies_cpu.append(latency_ms)\n",
        "    except ValueError as e:\n",
        "        if \"spike more than once\" in str(e):\n",
        "            print(f\"\\n error of colis√£o of spikes na amostra {i}!\")\n",
        "            print(f\"Detalhes: {e}\")\n",
        "            print(\"Tentando continuar with a next amostra...\")\n",
        "            continue\n",
        "        else:\n",
        "            print(f\"\\n error inesperado na amostra {i}: {e}\")\n",
        "            raise e\n",
        "    except Exception as e:\n",
        "        print(f\"\\n error gen√©rico na amostra {i}: {e}\")\n",
        "        raise e\n",
        "\n",
        "# Estat√≠sticas CPU\n",
        "if latencies_cpu:\n",
        "    cpu_metrics = {\n",
        "        'mean_latencia_ms': np.mean(latencies_cpu),\n",
        "        'median_latencia_ms': np.median(latencies_cpu),\n",
        "        'p95_latencia_ms': np.percentile(latencies_cpu, 95),\n",
        "        'p99_latencia_ms': np.percentile(latencies_cpu, 99),\n",
        "        'rendimiento_fps': 1000 / np.mean(latencies_cpu),\n",
        "        'total_time_s': sum(latencies_cpu) / 1000,\n",
        "    }\n",
        "\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"CPU Evaluaci√≥n RESULTS\")\n",
        "    print(\"=\"*50)\n",
        "    print(f\"Amostras processadas: {len(latencies_cpu)}/{num_samples}\")\n",
        "    print(f\"latencia average: {cpu_metrics['mean_latencia_ms']:.2f} ms\")\n",
        "    print(f\"latencia median: {cpu_metrics['median_latencia_ms']:.2f} ms\")\n",
        "    print(f\"latencia P95: {cpu_metrics['p95_latencia_ms']:.2f} ms\")\n",
        "    print(f\"latencia P99: {cpu_metrics['p99_latencia_ms']:.2f} ms\")\n",
        "    print(f\"Rendimiento: {cpu_metrics['rendimiento_fps']:.1f} transactions/s\")\n",
        "    print(f\"time total: {cpu_metrics['total_time_s']:.2f} s\")\n",
        "    print(\"=\"*50)\n",
        "else:\n",
        "    print(\"\\n Nenhuma amostra processada with sucesso.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "af24f4b9",
      "metadata": {},
      "source": [
        "## 2. Intel Loihi 2 Simulation\n",
        "\n",
        "Now let's simulate what the performance would be on the Loihi 2 neurom√≥rfico chip."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6ad70467",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Inicializar Loihi simulator\n",
        "loihi = LoihiSimulator()\n",
        "\n",
        "# Network specifications\n",
        "network_neurons = 256 + 128 + 64 + 2 # 450 neurons\n",
        "network_synapses = (256 * 128) + (128 * 64) + (64 * 2) # 41,088 synapses\n",
        "\n",
        "print(f\"üß† Neural Network:\")\n",
        "print(f\"  - Neurons: {network_neurons:,}\")\n",
        "print(f\"  - Synapses: {network_synapses:,}\")\n",
        "print(f\"\\n Loihi 2 Specs:\")\n",
        "print(f\" - Cores: {loihi.specs.num_cores}\")\n",
        "print(f\" - neurons: {loihi.specs.total_neurons:,}\")\n",
        "print(f\" - potencia/core: {loihi.specs.potencia_per_core_active*1000:.1f} mW\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "33b015af",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Execute Loihi Evaluaci√≥n\n",
        "print(\"\\n‚è≥ Executing Loihi 2 Evaluaci√≥n...\\n\")\n",
        "\n",
        "# Ensure num_samples is available even if the CPU cell was not executed\n",
        "if 'num_samples' not in locals():\n",
        "    num_samples = 100\n",
        "    print(\"‚ö†Ô∏è Advertencia: 'num_samples' not defined previously; using default of 100 inferences.\")\n",
        "\n",
        "loihi_metrics = loihi.benchmark_inference(\n",
        "    network_neurons=network_neurons,\n",
        "    network_synapses=network_synapses,\n",
        "    num_inferences=num_samples,\n",
        "    simulation_time_ms=100.0\n",
        ")\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"LOIHI 2 Evaluaci√≥n RESULTS\")\n",
        "print(\"=\"*50)\n",
        "print(f\"latencia: {loihi_metrics.latencia_ms:.2f} ms\")\n",
        "print(f\"Rendimiento: {loihi_metrics.rendimiento_fps:.1f} transactions/s\")\n",
        "print(f\"energ√≠a total: {loihi_metrics.energ√≠a_mj:.2f} mJ\")\n",
        "print(f\"potencia average: {loihi_metrics.potencia_mw:.2f} mW\")\n",
        "print(f\"Cores Usados: {loihi_metrics.cores_used}/{loihi.specs.num_cores}\")\n",
        "print(f\"total of Spikes: {loihi_metrics.total_spikes:,}\")\n",
        "print(f\"Ops Sin√°pticas: {loihi_metrics.synaptic_operations:,}\")\n",
        "print(\"=\"*50)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4977f6cc",
      "metadata": {},
      "source": [
        "## 3. Comparison e An√°lisis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6eaead8e",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Comparar with CPU\n",
        "cpu_power_w = 65.0 # TDP t√≠pico of CPU Intel Core i5/i7\n",
        "\n",
        "comparison = compare_with_cpu(\n",
        " loihi_metrics=loihi_metrics,\n",
        " cpu_latencia_ms=cpu_metrics['mean_latencia_ms'],\n",
        " cpu_power_w=cpu_power_w\n",
        ")\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"LOIHI vs CPU COMPARISON\")\n",
        "print(\"=\"*50)\n",
        "print(f\" Speedup: {comparison['speedup']:.2f}x\")\n",
        "print(f\" potencia eficiencia: {comparison['potencia_eficiencia']:.2f}x\")\n",
        "print(f\" energ√≠a eficiencia: {comparison['energ√≠a_eficiencia']:.2f}x\")\n",
        "print(f\"\\n Reductions:\")\n",
        "print(f\" - latencia: {comparison['latencia_reduction_percent']:.1f}%\")\n",
        "print(f\" - potencia: {comparison['potencia_reduction_percent']:.1f}%\")\n",
        "print(f\" - energ√≠a: {comparison['energ√≠a_reduction_percent']:.1f}%\")\n",
        "print(\"=\"*50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6d25e024",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Crear DataFrame comparativo\n",
        "comparison_df = pd.DataFrame({\n",
        " 'metric': ['latencia (ms)', 'Rendimiento (TPS)', 'potencia (mW)', 'energ√≠a (mJ)'],\n",
        " 'CPU': [\n",
        " cpu_metrics['mean_latencia_ms'],\n",
        " cpu_metrics['rendimiento_fps'],\n",
        " cpu_power_w * 1000, # 65W in mW\n",
        " (cpu_potencia_w * 1000 * cpu_metrics['mean_latencia_ms']) / 1000 # mJ\n",
        " ],\n",
        " 'Loihi 2': [\n",
        " loihi_metrics.latency_ms,\n",
        " loihi_metrics.throughput_fps,\n",
        " loihi_metrics.power_mw,\n",
        " loihi_metrics.energy_mj\n",
        " ]\n",
        "})\n",
        "\n",
        "comparison_df['Improvement'] = comparison_df['CPU'] / comparison_df['Loihi 2']\n",
        "comparison_df"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "35c0c983",
      "metadata": {},
      "source": [
        "## 4. Visualizaci√≥ns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eff257c9",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot 1: Comparison of latencia\n",
        "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
        "\n",
        "# latencia\n",
        "ax1 = axes[0, 0]\n",
        "latencies = [cpu_metrics['mean_latencia_ms'], loihi_metrics.latencia_ms]\n",
        "labels = ['CPU', 'Loihi 2']\n",
        "colors = ['#FF6B6B', '#4ECDC4']\n",
        "ax1.bar(labels, latencies, color=colors, alpha=0.8, edgecolor='black')\n",
        "ax1.set_ylabel('latencia (ms)', fontsize=12)\n",
        "ax1.set_title('latencia per Inference', fontsize=14, fontweight='bold')\n",
        "ax1.grid(axis='y', alpha=0.3)\n",
        "for i, v in enumerate(latencies):\n",
        " ax1.text(i, v + 0.5, f'{v:.2f}ms', ha='center', fontweight='bold')\n",
        "\n",
        "# Rendimiento\n",
        "ax2 = axes[0, 1]\n",
        "rendimientos = [cpu_metrics['rendimiento_fps'], loihi_metrics.rendimiento_fps]\n",
        "ax2.bar(labels, rendimientos, color=colors, alpha=0.8, edgecolor='black')\n",
        "ax2.set_ylabel('Rendimiento (TPS)', fontsize=12)\n",
        "ax2.set_title('Rendimiento (Transactions/second)', fontsize=14, fontweight='bold')\n",
        "ax2.grid(axis='y', alpha=0.3)\n",
        "for i, v in enumerate(throughputs):\n",
        " ax2.text(i, v + 5, f'{v:.1f}', ha='center', fontweight='bold')\n",
        "\n",
        "# potencia\n",
        "ax3 = axes[1, 0]\n",
        "powers = [cpu_power_w * 1000, loihi_metrics.power_mw]\n",
        "ax3.bar(labels, potencias, color=colors, alpha=0.8, edgecolor='black')\n",
        "ax3.set_ylabel('potencia (mW)', fontsize=12)\n",
        "ax3.set_title('consumption of potencia', fontsize=14, fontweight='bold')\n",
        "ax3.set_yscale('log')\n",
        "ax3.grid(axis='y', alpha=0.3)\n",
        "for i, v in enumerate(powers):\n",
        " ax3.text(i, v * 1.2, f'{v:.0f}mW', ha='center', fontweight='bold')\n",
        "\n",
        "# energ√≠a by inference\n",
        "ax4 = axes[1, 1]\n",
        "cpu_energ√≠a = (cpu_potencia_w * 1000 * cpu_metrics['mean_latencia_ms']) / 1000\n",
        "energies = [cpu_energy, loihi_metrics.energy_mj / num_samples]\n",
        "ax4.bar(labels, energies, color=colors, alpha=0.8, edgecolor='black')\n",
        "ax4.set_ylabel('energ√≠a (mJ)', fontsize=12)\n",
        "ax4.set_title('energ√≠a per Inference', fontsize=14, fontweight='bold')\n",
        "ax4.set_yscale('log')\n",
        "ax4.grid(axis='y', alpha=0.3)\n",
        "for i, v in enumerate(energies):\n",
        " ax4.text(i, v * 1.5, f'{v:.2f}mJ', ha='center', fontweight='bold')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('hardware_comparison.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n Gr√°ficos salvos in 'hardware_comparison.png'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bb7b4b48",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot 2: eficiencia Gains\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "\n",
        "metrics_names = ['Speedup', 'potencia\\nEfficiency', 'energ√≠a\\nEfficiency']\n",
        "improvements = [\n",
        " comparison['speedup'],\n",
        " comparison['potencia_eficiencia'],\n",
        " comparison['energ√≠a_eficiencia']\n",
        "]\n",
        "\n",
        "bars = ax.barh(metrics_names, improvements, color='#4ECDC4', alpha=0.8, edgecolor='black')\n",
        "ax.set_xlabel('Fator of bestia (X vezes better)', fontsize=12)\n",
        "ax.set_title('Loihi 2 eficiencia Gains vs CPU', fontsize=14, fontweight='bold')\n",
        "ax.axvline(x=1, color='red', linestyle='--', linewidth=2, label='Baseline CPU')\n",
        "ax.grid(axis='x', alpha=0.3)\n",
        "ax.legend(fontsize=10)\n",
        "\n",
        "for i, (bar, val) in enumerate(zip(bars, improvements)):\n",
        " ax.text(val + 50, i, f'{val:.1f}x', va='center', fontweight='bold', fontsize=12)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('eficiencia_gains.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(\" Gr√°ficos salvos in 'eficiencia_gains.png'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4566fba2",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot 3: latencia distribution CPU\n",
        "fig, ax = plt.subplots(figsize=(12, 6))\n",
        "\n",
        "ax.hist(latencies_cpu, bins=50, color='#FF6B6B', alpha=0.7, edgecolor='black')\n",
        "ax.axvline(cpu_metrics['mean_latencia_ms'], color='red', linestyle='--', \n",
        " linewidth=2, label=f\"average: {cpu_metrics['mean_latencia_ms']:.2f}ms\")\n",
        "ax.axvline(cpu_metrics['median_latencia_ms'], color='orange', linestyle='--', \n",
        " linewidth=2, label=f\"median: {cpu_metrics['median_latencia_ms']:.2f}ms\")\n",
        "ax.axvline(loihi_metrics.latencia_ms, color='green', linestyle='-', \n",
        " linewidth=3, label=f\"Loihi: {loihi_metrics.latencia_ms:.2f}ms\")\n",
        "\n",
        "ax.set_xlabel('latencia (ms)', fontsize=12)\n",
        "ax.set_ylabel('Frequency', fontsize=12)\n",
        "ax.set_title('latencia distribution - CPU vs Loihi 2', fontsize=14, fontweight='bold')\n",
        "ax.legend(fontsize=11)\n",
        "ax.grid(alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('latencia_distribution.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(\" Gr√°ficos salvos in 'latencia_distribution.png'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ba195358",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot 4: ROC Curve\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "\n",
        "# Obter predictions probabil√≠sticas of model\n",
        "print(\"Generando predictions for ROC Curve...\")\n",
        "y_scores = []\n",
        "for i in tqdm(range(len(X_test)), desc=\"Predictions\"):\n",
        "    transaction = df_test.iloc[i].to_dict()\n",
        "    try:\n",
        "        prediction = pipeline.predict(transaction)\n",
        "        # Extrair o value num√©rico of prediction\n",
        "        # pipeline.predict() can retornar dict, float ou int\n",
        "        if isinstance(prediction, dict):\n",
        "            # Se for dict, tentar extrair probability of fraude\n",
        "            score = prediction.get('fraud_probability', prediction.get('prediction', 0.5))\n",
        "        elif isinstance(prediction, (int, float)):\n",
        "            score = float(prediction)\n",
        "        else:\n",
        "            score = 0.5\n",
        "        y_scores.append(score)\n",
        "    except Exception as e:\n",
        "        print(f\"\\nErro na amostra {i}: {e}\")\n",
        "        y_scores.append(0.5)  # value pattern in case of error\n",
        "\n",
        "# Converter for array numpy\n",
        "y_scores = np.array(y_scores, dtype=float)\n",
        "\n",
        "# Calcular ROC\n",
        "fpr, tpr, thresholds = roc_curve(y_test_np, y_scores)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "# Plot\n",
        "fig, ax = plt.subplots(figsize=(10, 8))\n",
        "ax.plot(fpr, tpr, color='#4ECDC4', linewidth=3, label=f'ROC Curve (AUC = {roc_auc:.3f})')\n",
        "ax.plot([0, 1], [0, 1], 'r--', linewidth=2, label='Random Classifier')\n",
        "ax.fill_between(fpr, tpr, alpha=0.3, color='#4ECDC4')\n",
        "\n",
        "ax.set_xlabel('False Positive Rate', fontsize=12)\n",
        "ax.set_ylabel('True Positive Rate', fontsize=12)\n",
        "ax.set_title('ROC Curve - Fraud Detection Performance', fontsize=14, fontweight='bold')\n",
        "ax.legend(loc='lower right', fontsize=11)\n",
        "ax.grid(alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('roc_curve.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(f\"‚úì ROC Curve salva in 'roc_curve.png' (AUC = {roc_auc:.3f})\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ab752b28",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot 5: Confusion Matrix\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "# Converter predictions to binary (threshold = 0.5)\n",
        "# y_scores is already an array numpy of floats of c√©lula anterior\n",
        "y_pred = (y_scores > 0.5).astype(int)\n",
        "\n",
        "# Calcular confusion matrix\n",
        "cm = confusion_matrix(y_test_np, y_pred)\n",
        "\n",
        "# Plot\n",
        "fig, ax = plt.subplots(figsize=(10, 8))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=True, \n",
        "            square=True, linewidths=2, linecolor='black',\n",
        "            xticklabels=['Leg√≠tima', 'Fraude'],\n",
        "            yticklabels=['Leg√≠tima', 'Fraude'],\n",
        "            annot_kws={'size': 16, 'weight': 'bold'},\n",
        "            ax=ax)\n",
        "\n",
        "ax.set_xlabel('Prediction', fontsize=12, fontweight='bold')\n",
        "ax.set_ylabel('value Real', fontsize=12, fontweight='bold')\n",
        "ax.set_title('Confusion Matrix - Fraud Detection', fontsize=14, fontweight='bold')\n",
        "\n",
        "# Add metrics no plot\n",
        "tn, fp, fn, tp = cm.ravel()\n",
        "accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
        "precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
        "recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "\n",
        "metrics_text = f'Accuracy: {accuracy:.3f}\\nPrecision: {precision:.3f}\\nRecall: {recall:.3f}\\nF1-Score: {f1:.3f}'\n",
        "ax.text(1.15, 0.5, metrics_text, transform=ax.transAxes, \n",
        "        fontsize=11, verticalalignment='center',\n",
        "        bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('confusion_matrix.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(f\"‚úì Confusion Matrix salva in 'confusion_matrix.png'\")\n",
        "print(f\"\\nüìä Classification Metrics:\")\n",
        "print(f\"  Accuracy:  {accuracy:.3f}\")\n",
        "print(f\"  Precision: {precision:.3f}\")\n",
        "print(f\"  Recall:    {recall:.3f}\")\n",
        "print(f\"  F1-Score:  {f1:.3f}\")\n",
        "\n",
        "# Relat√≥rio detalhado\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"CLASSIFICATION REPORT\")\n",
        "print(\"=\"*50)\n",
        "print(classification_report(y_test_np, y_pred, target_names=['Leg√≠tima', 'Fraude']))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6f057f26",
      "metadata": {},
      "source": [
        "## 5. An√°lisis of Escalabilidade"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "02daaadd",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Simulate different transaction volumes\n",
        "print(\"üìà Analyzing scalability...\\n\")\n",
        "\n",
        "volumes = [100, 500, 1000, 5000, 10000, 50000]\n",
        "scalability_results = []\n",
        "\n",
        "for vol in tqdm(volumes, desc=\"Volumes\"):\n",
        " # CPU: latencia grows linearly\n",
        " cpu_total_time_s = (cpu_metrics['mean_latencia_ms'] * vol) / 1000\n",
        " cpu_total_energy_mj = (cpu_power_w * 1000 * cpu_total_time_s)\n",
        " \n",
        " # Loihi: much better scalability\n",
        " loihi_sim = loihi.benchmark_inference(\n",
        " network_neurons=network_neurons,\n",
        " network_synapses=network_synapses,\n",
        " num_inferences=vol,\n",
        " simulation_time_ms=100.0\n",
        " )\n",
        " loihi_total_time_s = (loihi_sim.latency_ms * vol) / 1000\n",
        " \n",
        " scalability_results.append({\n",
        " 'volume': vol,\n",
        " 'cpu_time_s': cpu_total_time_s,\n",
        " 'loihi_time_s': loihi_total_time_s,\n",
        " 'cpu_energ√≠a_mj': cpu_total_energ√≠a_mj,\n",
        " 'loihi_energ√≠a_mj': loihi_sim.energ√≠a_mj,\n",
        " 'speedup': cpu_total_time_s / loihi_total_time_s\n",
        " })\n",
        "\n",
        "scalability_df = pd.DataFrame(scalability_results)\n",
        "scalability_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e3b71f1f",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot of escalabilidade\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# time of execution\n",
        "ax1 = axes[0]\n",
        "ax1.plot(scalability_df['volume'], scalability_df['cpu_time_s'], \n",
        " marker='o', linewidth=2, markersize=8, label='CPU', color='#FF6B6B')\n",
        "ax1.plot(scalability_df['volume'], scalability_df['loihi_time_s'], \n",
        " marker='s', linewidth=2, markersize=8, label='Loihi 2', color='#4ECDC4')\n",
        "ax1.set_xlabel('Volume of Transactions', fontsize=12)\n",
        "ax1.set_ylabel('time total (s)', fontsize=12)\n",
        "ax1.set_title('Escalabilidade: time of Execution', fontsize=14, fontweight='bold')\n",
        "ax1.set_xscale('log')\n",
        "ax1.set_yscale('log')\n",
        "ax1.legend(fontsize=11)\n",
        "ax1.grid(alpha=0.3)\n",
        "\n",
        "# energ√≠a consumida\n",
        "ax2 = axes[1]\n",
        "ax2.plot(scalability_df['volume'], scalability_df['cpu_energ√≠a_mj'], \n",
        " marker='o', linewidth=2, markersize=8, label='CPU', color='#FF6B6B')\n",
        "ax2.plot(scalability_df['volume'], scalability_df['loihi_energ√≠a_mj'], \n",
        " marker='s', linewidth=2, markersize=8, label='Loihi 2', color='#4ECDC4')\n",
        "ax2.set_xlabel('Volume of Transactions', fontsize=12)\n",
        "ax2.set_ylabel('energ√≠a total (mJ)', fontsize=12)\n",
        "ax2.set_title('Escalabilidade: energ√≠a consumption', fontsize=14, fontweight='bold')\n",
        "ax2.set_xscale('log')\n",
        "ax2.set_yscale('log')\n",
        "ax2.legend(fontsize=11)\n",
        "ax2.grid(alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('scalability_analysis.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(\" Gr√°ficos salvos in 'scalability_analysis.png'\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c85d905e",
      "metadata": {},
      "source": [
        "## 6. Conclusiones e Recommendations\n",
        "\n",
        "### main Resultados\n",
        "\n",
        "with base nos benchmarks realizados:\n",
        "\n",
        "**Performance:**\n",
        "- Loihi 2 oferece **speedup significativo** in latencia\n",
        "- Rendimiento very superior for Processing paralelo\n",
        "- consistent and predictable latencia (event-driven)\n",
        "\n",
        "**eficiencia Energ√©tica:**\n",
        "- **Drastic reduction** no energ√≠a consumption (1000x+)\n",
        "- Ideal for edge computing e dispositivos m√≥veis\n",
        "- Viable continuous operation with battery\n",
        "\n",
        "**Escalabilidade:**\n",
        "- Vantagem of Loihi aumenta with volume of transactions\n",
        "- Processing paralelo Native\n",
        "- Multi-chip for applications very large\n",
        "\n",
        "### Recommendations of Deployment\n",
        "\n",
        "#### Use **CPU/GPU** when:\n",
        "- Volume low of transactions (< 1000/s)\n",
        "- Prototipagem e Development\n",
        "- Code flexibility √© priority\n",
        "- Infraestrutura existente available\n",
        "\n",
        "#### Use **Loihi 2** when:\n",
        "- high volume of transactions (> 10000/s)\n",
        "- eficiencia energ√©tica √© cr√≠tica\n",
        "- Edge computing / dispositivos m√≥veis\n",
        "- latencia ultra-low √© requisito\n",
        "- 24/7 Operation with restrictions of energ√≠a\n",
        "\n",
        "### Pr√≥ximos pasos\n",
        "\n",
        "1. **Implementation real in Loihi**: Migrar of Brian2 for Lava\n",
        "2. **Optimization of arquitetura**: Ajustar for maximizar eficiencia of Loihi\n",
        "3. **Tests in Production**: Validar with tr√°fego real\n",
        "4. **Custo-benef√≠cio**: An√°lisis of TCO (total Cost of Ownership)\n",
        "5. **Comparison with outros chips**: TrueNorth, SpiNNaker, BrainScaleS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b709f22b",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Guardar results in CSV\n",
        "comparison_df.to_csv('hardware_benchmark_results.csv', index=False)\n",
        "scalability_df.to_csv('scalability_results.csv', index=False)\n",
        "\n",
        "print(\"\\n Resultados salvos:\")\n",
        "print(\" - hardware_benchmark_results.csv\")\n",
        "print(\" - scalability_results.csv\")\n",
        "print(\" - hardware_comparison.png\")\n",
        "print(\" - eficiencia_gains.png\")\n",
        "print(\" - latencia_distribution.png\")\n",
        "print(\" - scalability_analysis.png\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "fraud-detection-neuromorphic",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
