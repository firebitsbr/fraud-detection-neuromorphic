{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf868a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# A√±adir src al path\n",
    "# El notebook est√° en: /portfolio/01_fraud_neuromorphic/notebooks/\n",
    "# src est√° en: /portfolio/01_fraud_neuromorphic/src/\n",
    "notebook_dir = Path.cwd()\n",
    "\n",
    "# Comprobar si estamos en el directorio ra√≠z del proyecto o en notebooks\n",
    "if (notebook_dir / 'portfolio' / '01_fraud_neuromorphic' / 'src').exists():\n",
    "    # Estamos en la ra√≠z del proyecto (Project-Neuromorfico-X)\n",
    "    src_path = notebook_dir / 'portfolio' / '01_fraud_neuromorphic' / 'src'\n",
    "elif (notebook_dir.parent / 'src').exists():\n",
    "    # Estamos en notebooks/\n",
    "    src_path = notebook_dir.parent / 'src'\n",
    "elif (notebook_dir / 'src').exists():\n",
    "    # Estamos en 01_fraud_neuromorphic/\n",
    "    src_path = notebook_dir / 'src'\n",
    "else:\n",
    "    src_path = None\n",
    "\n",
    "if src_path and src_path.exists():\n",
    "    if str(src_path) not in sys.path:\n",
    "        sys.path.insert(0, str(src_path))\n",
    "        print(f\"‚úÖ Directorio src a√±adido: {src_path}\")\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è ¬°Directorio src no encontrado!\")\n",
    "    print(f\"  Directorio del notebook: {notebook_dir}\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import time\n",
    "from tqdm.auto import tqdm\n",
    "import brian2\n",
    "\n",
    "# Configurar Brian2 para usar numpy (evita errores de compilaci√≥n en C++ y problemas con SymPy/Cython)\n",
    "brian2.prefs.codegen.target = \"numpy\"\n",
    "\n",
    "# Nuestros m√≥dulos\n",
    "try:\n",
    "    from main import FraudDetectionPipeline, generate_synthetic_transactions\n",
    "    from encoders import RateEncoder, timeralEncoder, PopulationEncoder, TransactionEncoder\n",
    "    from models_snn import FraudSNN, demonstrate_lif_neuron  # type: ignore[attr-defined]\n",
    "    print(\"‚úÖ Importaci√≥n de m√≥dulos del proyecto completada!\")\n",
    "except ImportError as e:\n",
    "    print(f\"‚ö†Ô∏è Error al importar m√≥dulos: {e}\")\n",
    "    print(f\"  sys.path: {sys.path[:3]}\")\n",
    "\n",
    "# Configuraci√≥n de visualizaci√≥n\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5de470",
   "metadata": {},
   "source": [
    "## 2. Generaci√≥n de Datos Sint√©ticos\n",
    "\n",
    "Vamos a crear un conjunto de datos sint√©tico de transacciones bancarias con patrones realistas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c9d975",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generar 1000 transacciones (5% fraudes)\n",
    "print(\"Generando transacciones sint√©ticas...\")\n",
    "df = generate_synthetic_transactions(n=1000, fraud_ratio=0.05)\n",
    "\n",
    "print(f\"\\nüìä Conjunto de datos generado:\")\n",
    "print(f\"  Total de transacciones: {len(df)}\")\n",
    "print(f\"  Transacciones leg√≠timas: {np.sum(df['is_fraud'] == 0)}\")\n",
    "print(f\"  Transacciones fraudulentas: {np.sum(df['is_fraud'] == 1)}\")\n",
    "print(f\"  Tasa de fraude: {df['is_fraud'].mean():.2%}\")\n",
    "\n",
    "# Mostrar primeras filas\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c419d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar distribuci√≥n de valores\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Distribuci√≥n de valores por clase\n",
    "df[df['is_fraud'] == 0]['amount'].hist(bins=50, alpha=0.7, label='Leg√≠tima', ax=axes[0], color='green')\n",
    "df[df['is_fraud'] == 1]['amount'].hist(bins=30, alpha=0.7, label='Fraude', ax=axes[0], color='red')\n",
    "axes[0].set_xlabel('Valor de transacci√≥n ($)')\n",
    "axes[0].set_ylabel('Frecuencia')\n",
    "axes[0].set_title('Distribuci√≥n de valores por clase')\n",
    "axes[0].legend()\n",
    "\n",
    "# Frecuencia diaria por clase\n",
    "df.boxplot(column='daily_frequency', by='is_fraud', ax=axes[1])\n",
    "axes[1].set_xlabel('Clase (0=Leg√≠tima, 1=Fraude)')\n",
    "axes[1].set_ylabel('Frecuencia diaria')\n",
    "axes[1].set_title('Frecuencia de transacciones por clase')\n",
    "plt.suptitle('')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüìä Patrones observados:\")\n",
    "print(\"  - Las fraudes tienden a tener valores m√°s altos\")\n",
    "print(\"  - Las fraudes tienen mayor frecuencia de transacciones\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6987dcc",
   "metadata": {},
   "source": [
    "## 3. Codificaci√≥n de Picos\n",
    "\n",
    "Demostrar c√≥mo las caracter√≠sticas de la transacci√≥n se convierten en picos temporales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e7d9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplo de codificaci√≥n por tasa\n",
    "print(\"=== CODIFICACI√ìN POR TASA ===\")\n",
    "print(\"Codifica valores continuos como frecuencia de picos\\n\")\n",
    "\n",
    "rate_encoder = RateEncoder(min_rate=1, max_rate=100, duration=0.1)\n",
    "\n",
    "# Prueba con diferentes valores\n",
    "test_amounts = [100, 500, 1000, 5000, 10000]\n",
    "\n",
    "fig, axes = plt.subplots(len(test_amounts), 1, figsize=(12, 10))\n",
    "\n",
    "for idx, amount in enumerate(test_amounts):\n",
    "    spike_times = rate_encoder.encode(amount, min_val=0, max_val=10000)\n",
    "    \n",
    "    # Visualizaci√≥n\n",
    "    if spike_times:\n",
    "        axes[idx].eventplot([spike_times], linewidths=2, colors='blue')\n",
    "        axes[idx].set_xlim(0, 0.1)\n",
    "        axes[idx].set_ylim(0.5, 1.5)\n",
    "        axes[idx].set_ylabel(f'$ {amount}')\n",
    "        axes[idx].set_title(f'valor: $ {amount} ‚Üí {len(spike_times)} picos')\n",
    "        axes[idx].grid(True, alpha=0.3)\n",
    "    \n",
    "axes[-1].set_xlabel('Tiempo (segundos)')\n",
    "plt.suptitle('Codificaci√≥n por tasa: Valor ‚Üí Frecuencia de picos', fontsize=14, y=1.0)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüí° Nota: Valores m√°s altos generan m√°s picos (mayor frecuencia)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e0d927",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplo de codificaci√≥n por poblaci√≥n (Geolocalizaci√≥n)\n",
    "print(\"=== CODIFICACI√ìN POR POBLACI√ìN ===\")\n",
    "print(\"Codifica valores usando m√∫ltiples neuronas con campos receptivos\\n\")\n",
    "\n",
    "pop_encoder = PopulationEncoder(n_neurons=20, min_val=-1, max_val=1, sigma=0.15)\n",
    "\n",
    "# Prueba con diferentes ubicaciones\n",
    "test_locations = [-0.8, -0.3, 0.0, 0.4, 0.9]\n",
    "\n",
    "fig, axes = plt.subplots(2, 1, figsize=(14, 8))\n",
    "\n",
    "# Gr√°fico 1: Activaci√≥n de neuronas\n",
    "for loc in test_locations:\n",
    "    activations = np.exp(-((pop_encoder.centers - loc) ** 2) / (2 * pop_encoder.sigma ** 2))\n",
    "    axes[0].plot(pop_encoder.centers, activations, marker='o', label=f'Ubicaci√≥n = {loc:.1f}', alpha=0.7)\n",
    "\n",
    "axes[0].set_xlabel('Centro de neurona')\n",
    "axes[0].set_ylabel('Activaci√≥n')\n",
    "axes[0].set_title('Activaci√≥n de la poblaci√≥n neuronal por ubicaci√≥n')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Gr√°fico 2: Raster plot de picos\n",
    "spike_data = []\n",
    "for idx, loc in enumerate(test_locations):\n",
    "    encoding = pop_encoder.encode(loc, duration=0.1)\n",
    "    if len(encoding.spike_times) > 0:\n",
    "        for t, n in zip(encoding.spike_times, encoding.neuron_indices):\n",
    "            spike_data.append([t, n + idx * 25]) # Desplazamiento para visualizaci√≥n\n",
    "\n",
    "if spike_data:\n",
    "    spike_array = np.array(spike_data)\n",
    "    axes[1].scatter(spike_array[:, 0], spike_array[:, 1], marker='|', s=100, alpha=0.6)\n",
    "\n",
    "axes[1].set_xlabel('Tiempo (segundos)')\n",
    "axes[1].set_ylabel('Neurona + desplazamiento')\n",
    "axes[1].set_title('Picos generados por la poblaci√≥n neuronal')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüí° Nota: Cada ubicaci√≥n activa un grupo diferente de neuronas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0677c07f",
   "metadata": {},
   "source": [
    "## 4. Arquitectura SNN\n",
    "\n",
    "Visualizar y comprender la arquitectura de la Red Neuronal de Picos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d23f9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demostraci√≥n de neurona LIF individual\n",
    "print(\"=== NEURONA LIF (FUGA INTEGRAR-DISPARAR) ===\")\n",
    "print(\"Demostraci√≥n del comportamiento de la neurona LIF\\n\")\n",
    "\n",
    "lif_data = demonstrate_lif_neuron()  # type: ignore[name-defined]\n",
    "\n",
    "fig, axes = plt.subplots(2, 1, figsize=(14, 8), sharex=True)\n",
    "\n",
    "# Gr√°fico 1: Corriente de entrada\n",
    "axes[0].plot(lif_data['time'], lif_data['input'], color='blue', linewidth=2)\n",
    "axes[0].set_ylabel('Corriente de entrada (I)')\n",
    "axes[0].set_title('Est√≠mulo de entrada (corriente escal√≥n)')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Gr√°fico 2: Potencial de membrana y picos\n",
    "axes[1].plot(lif_data['time'], lif_data['voltage'], color='green', linewidth=2, label='Potencial de membrana')\n",
    "axes[1].axhline(-50, color='red', linestyle='--', label='Umbral (-50mV)', alpha=0.7)\n",
    "axes[1].axhline(-70, color='gray', linestyle='--', label='Reposo (-70mV)', alpha=0.5)\n",
    "\n",
    "# Marcar picos\n",
    "for spike_time in lif_data['spikes']:\n",
    "    axes[1].axvline(spike_time, color='red', alpha=0.3, linewidth=1)\n",
    "\n",
    "axes[1].set_xlabel('Tiempo (ms)')\n",
    "axes[1].set_ylabel('Voltaje (mV)')\n",
    "axes[1].set_title(f'Potencial de membrana (total de {len(lif_data[\"spikes\"])} picos)')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nüìä An√°lisis:\")\n",
    "print(f\"  - Picos detectados: {len(lif_data['spikes'])}\")\n",
    "print(f\"  - Frecuencia media: {len(lif_data['spikes']) / (lif_data['time'][-1] / 1000):.1f} Hz\")\n",
    "print(f\"  - ISI medio: {np.mean(np.diff(lif_data['spikes'])):.2f} ms\" if len(lif_data['spikes']) > 1 else \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713d17c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estad√≠sticas de arquitectura SNN\n",
    "print(\"=== ARQUITECTURA SNN ===\")\n",
    "\n",
    "snn = FraudSNN(input_size=256, hidden_sizes=[128, 64], output_size=2)\n",
    "stats = snn.get_network_stats()  # type: ignore[attr-defined]\n",
    "\n",
    "print(f\"\\nüìä Estructura de la red:\")\n",
    "print(f\"  Capa de entrada: {stats['layers']['input']} neuronas\")\n",
    "print(f\"  Capa oculta 1: {stats['layers']['hidden'][0]} neuronas (LIF)\")\n",
    "print(f\"  Capa oculta 2: {stats['layers']['hidden'][1]} neuronas (LIF)\")\n",
    "print(f\"  Capa de salida: {stats['layers']['output']} neuronas\")\n",
    "print(f\"\\n  Total de neuronas: {stats['total_neurons']}\")\n",
    "print(f\"  Total de sinapsis: {stats['total_synapses']}\")\n",
    "\n",
    "print(f\"\\n‚öñÔ∏è Pesos sin√°pticos:\")\n",
    "print(f\"  Media: {stats['weights']['mean']:.4f}\")\n",
    "print(f\"  Desviaci√≥n est√°ndar: {stats['weights']['std']:.4f}\")\n",
    "print(f\"  M√≠n: {stats['weights']['min']:.4f}\")\n",
    "print(f\"  M√°x: {stats['weights']['max']:.4f}\")\n",
    "\n",
    "# Visualizar arquitectura\n",
    "layer_sizes = [256, 128, 64, 2]\n",
    "layer_names = ['Entrada\\n(256)', 'Oculta 1\\n(128)', 'Oculta 2\\n(64)', 'Salida\\n(2)']\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 6))\n",
    "\n",
    "# Dibujar capas\n",
    "x_positions = np.linspace(0, 10, len(layer_sizes))\n",
    "max_size = max(layer_sizes)\n",
    "\n",
    "for i, (size, name, x) in enumerate(zip(layer_sizes, layer_names, x_positions)):\n",
    "    y_positions = np.linspace(0, max_size, size)\n",
    "    \n",
    "    # Limitar visualizaci√≥n para capas grandes\n",
    "    display_neurons = min(size, 20)\n",
    "    y_display = np.linspace(0, max_size, display_neurons)\n",
    "    \n",
    "    ax.scatter([x] * display_neurons, y_display, s=100, alpha=0.7, \n",
    "               color=f'C{i}', label=name, zorder=3)\n",
    "    \n",
    "    # Conectar con la siguiente capa\n",
    "    if i < len(layer_sizes) - 1:\n",
    "        next_x = x_positions[i + 1]\n",
    "        next_size = min(layer_sizes[i + 1], 20)\n",
    "        next_y = np.linspace(0, max_size, next_size)\n",
    "        \n",
    "        # Dibujar algunas conexiones (muestra)\n",
    "        for y1 in y_display[::3]:\n",
    "            for y2 in next_y[::3]:\n",
    "                ax.plot([x, next_x], [y1, y2], 'k-', alpha=0.05, linewidth=0.5, zorder=1)\n",
    "\n",
    "ax.set_xlim(-1, 11)\n",
    "ax.set_ylim(-20, max_size + 20)\n",
    "ax.set_xticks(x_positions)\n",
    "ax.set_xticklabels(layer_names)\n",
    "ax.set_yticks([])\n",
    "ax.set_title('Arquitectura de red neuronal de picos para detecci√≥n de fraude', fontsize=14)\n",
    "ax.spines['left'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c162d2",
   "metadata": {},
   "source": [
    "## 5. Pipeline Completo\n",
    "\n",
    "Ejecutar el pipeline de extremo a extremo: entrenar y evaluar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412d5512",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializar pipeline\n",
    "print(\"Inicializando pipeline de detecci√≥n de fraude...\")\n",
    "pipeline = FraudDetectionPipeline()\n",
    "\n",
    "# Dividir entrenamiento/prueba - usar datos m√°s peque√±os para una demostraci√≥n r√°pida\n",
    "train_size = int(0.8 * len(df))\n",
    "train_data = df[:train_size].copy()\n",
    "test_data = df[train_size:].copy()\n",
    "\n",
    "# Para la demo, usar solo un subconjunto peque√±o de entrenamiento\n",
    "# Reducido a 20 muestras para ejecuci√≥n r√°pida en modo numpy (sin compilaci√≥n C++)\n",
    "train_subset_size = min(20, len(train_data))\n",
    "train_subset = train_data.sample(n=train_subset_size, random_state=42)\n",
    "\n",
    "print(f\"\\n Divisi√≥n de los datos:\")\n",
    "print(f\" Entrenamiento (subconjunto para demo): {len(train_subset)} transacciones\")\n",
    "print(f\" Prueba: {len(test_data)} transacciones\")\n",
    "print(f\"\\n Nota: Usando subconjunto reducido para demostraci√≥n r√°pida\")\n",
    "\n",
    "print(\"\\n‚è≥ Iniciando entrenamiento con STDP...\")\n",
    "print(\"(Usando pocas √©pocas y datos reducidos para una demostraci√≥n r√°pida)\\n\")\n",
    "\n",
    "# Reducir dr√°sticamente para la demo\n",
    "epochs = 2\n",
    "print(f\" Entrenamiento: {epochs} √©pocas con {len(train_subset)} transacciones\")\n",
    "\n",
    "# Entrenamiento r√°pido\n",
    "start_time = time.time()\n",
    "print(\"Entrenando...\")\n",
    "pipeline.train(train_subset, epochs=epochs)\n",
    "training_time = time.time() - start_time\n",
    "\n",
    "print(f\"\\n Entrenamiento finalizado en {training_time:.1f}s\")\n",
    "print(f\" tiempo medio por √©poca: {training_time/epochs:.2f}s\")\n",
    "print(f\" tasa: {len(train_subset) * epochs / training_time:.1f} transacciones/s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42749f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluar en el conjunto de prueba\n",
    "print(\" Evaluando el modelo en el conjunto de prueba...\")\n",
    "print(f\"total de {len(test_data)} transacciones\\n\")\n",
    "\n",
    "# Evaluaci√≥n con tiempo estimado\n",
    "start_eval = time.time()\n",
    "metrics = pipeline.evaluate(test_data)\n",
    "eval_time = time.time() - start_eval\n",
    "\n",
    "print(f\"\\n Evaluaci√≥n finalizada en {eval_time:.2f}s\")\n",
    "print(f\" velocidad: {len(test_data)/eval_time:.1f} transacciones/s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b999ef00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar matriz de confusi√≥n\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "# Convertir expl√≠citamente a arrays de numpy\n",
    "y_true = test_data['is_fraud'].to_numpy()\n",
    "y_pred = []\n",
    "\n",
    "print(\" Generando predicciones para la matriz de confusi√≥n...\")\n",
    "for _, row in tqdm(test_data.iterrows(), total=len(test_data), desc=\"Predicciones\", unit=\"txn\"):\n",
    "    result = pipeline.predict(row.to_dict())\n",
    "    y_pred.append(int(result['is_fraud']))\n",
    "\n",
    "# Convertir y_pred a array de numpy\n",
    "y_pred = np.array(y_pred, dtype=int)\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['Leg√≠tima', 'Fraude'],\n",
    "            yticklabels=['Leg√≠tima', 'Fraude'],\n",
    "            cbar_kws={'label': 'Conteo'})\n",
    "ax.set_xlabel('Predicci√≥n')\n",
    "ax.set_ylabel('Real')\n",
    "ax.set_title('Matriz de confusi√≥n - Detecci√≥n de fraude neurom√≥rfica')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n Exactitud: {metrics['accuracy']:.2%}\")\n",
    "print(f\"  Precisi√≥n: {metrics['precision']:.2%}\")\n",
    "print(f\"  Sensibilidad (recall): {metrics['recall']:.2%}\")\n",
    "print(f\"  F1-Score: {metrics['f1_score']:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4324d3a3",
   "metadata": {},
   "source": [
    "## 6. Ejemplos de Predicci√≥n Individual\n",
    "\n",
    "Probar con transacciones espec√≠ficas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c33875",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplo 1: Transacci√≥n leg√≠tima t√≠pica\n",
    "print(\"=\" * 60)\n",
    "print(\"Ejemplo 1: Transacci√≥n Leg√≠tima\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "legitimate_txn = {\n",
    " 'id': 'demo_001',\n",
    " 'amount': 85.50,\n",
    " 'timestamp': time.time(),\n",
    " 'merchant_category': 'groceries',\n",
    " 'location': (-23.5505, -46.6333), # S√£o Paulo\n",
    " 'device_id': 'device_regular_001',\n",
    " 'daily_frequency': 3\n",
    "}\n",
    "\n",
    "result = pipeline.predict(legitimate_txn)\n",
    "\n",
    "print(f\"\\nTransacci√≥n:\")\n",
    "print(f\" valor: $ {legitimate_txn['amount']:.2f}\")\n",
    "print(f\" Categor√≠a: {legitimate_txn['merchant_category']}\")\n",
    "print(f\" Ubicaci√≥n: S√£o Paulo\")\n",
    "\n",
    "print(f\"\\n Resultado del an√°lisis:\")\n",
    "print(f\" Fraude detectada: {' S√ç' if result['is_fraud'] else ' NO'}\")\n",
    "print(f\" Confianza: {result['confidence']:.2%}\")\n",
    "print(f\" Puntuaci√≥n Leg√≠tima: {result['legitimate_score']:.2f} Hz\")\n",
    "print(f\" Puntuaci√≥n Fraude: {result['fraud_score']:.2f} Hz\")\n",
    "print(f\" Latencia: {result['latency_ms']:.2f}ms\")\n",
    "print(f\" Picos generados: {result['n_spikes_generated']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9eb998",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplo 2: Transacci√≥n sospechosa (alta probabilidad de fraude)\n",
    "print(\"=\" * 60)\n",
    "print(\"Ejemplo 2: Transacci√≥n Sospechosa\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "suspicious_txn = {\n",
    " 'id': 'demo_002',\n",
    " 'amount': 8500.00, # valor alto\n",
    " 'timestamp': time.time(),\n",
    " 'merchant_category': 'electronics',\n",
    " 'location': (51.5074, -0.1278), # Londres (ubicaci√≥n poco com√∫n)\n",
    " 'device_id': 'device_new_unknown', # Dispositivo nuevo\n",
    " 'daily_frequency': 25 # frecuencia anormal\n",
    "}\n",
    "\n",
    "result = pipeline.predict(suspicious_txn)\n",
    "\n",
    "print(f\"\\nTransacci√≥n:\")\n",
    "print(f\" valor: $ {suspicious_txn['amount']:.2f}\")\n",
    "print(f\" Categor√≠a: {suspicious_txn['merchant_category']}\")\n",
    "print(f\" Ubicaci√≥n: Londres (poco com√∫n)\")\n",
    "print(f\" Dispositivo: nuevo/desconocido\")\n",
    "\n",
    "print(f\"\\n Resultado del an√°lisis:\")\n",
    "print(f\" Fraude detectada: {' S√ç' if result['is_fraud'] else ' NO'}\")\n",
    "print(f\" Confianza: {result['confidence']:.2%}\")\n",
    "print(f\" Puntuaci√≥n Leg√≠tima: {result['legitimate_score']:.2f} Hz\")\n",
    "print(f\" Puntuaci√≥n Fraude: {result['fraud_score']:.2f} Hz\")\n",
    "print(f\" Latencia: {result['latency_ms']:.2f}ms\")\n",
    "print(f\" Picos generados: {result['n_spikes_generated']}\")\n",
    "\n",
    "if result['is_fraud']:\n",
    " print(f\"\\n ALERTA: ¬°Transacci√≥n bloqueada para an√°lisis manual!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b04cfa8",
   "metadata": {},
   "source": [
    "## 7. An√°lisis de Rendimiento\n",
    "\n",
    "Evaluar latencia y rendimiento del sistema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10168f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benchmark de latencia\n",
    "print(\"=== Benchmark de latencia ===\")\n",
    "n_samples = min(100, len(test_data))\n",
    "print(f\"Probando {n_samples} transacciones...\\n\")\n",
    "\n",
    "latencies = []\n",
    "sample_txns = test_data.sample(n=n_samples)\n",
    "\n",
    "for _, row in tqdm(sample_txns.iterrows(), total=n_samples, desc=\"Benchmark\", unit=\"txn\"):\n",
    " start = time.time()\n",
    " result = pipeline.predict(row.to_dict())\n",
    " latency = (time.time() - start) * 1000 # ms\n",
    " latencies.append(latency)\n",
    "\n",
    "latencies = np.array(latencies)\n",
    "\n",
    "print(f\"\\n Estad√≠sticas de latencia:\")\n",
    "print(f\" media: {latencies.mean():.2f}ms\")\n",
    "print(f\" mediana: {np.median(latencies):.2f}ms\")\n",
    "print(f\" M√≠n: {latencies.min():.2f}ms\")\n",
    "print(f\" M√°x: {latencies.max():.2f}ms\")\n",
    "print(f\" P95: {np.percentile(latencies, 95):.2f}ms\")\n",
    "print(f\" P99: {np.percentile(latencies, 99):.2f}ms\")\n",
    "\n",
    "throughput = 1000 / latencies.mean() # transacciones por segundo\n",
    "print(f\"\\n Rendimiento estimado: {throughput:.0f} transacciones/s\")\n",
    "\n",
    "# Visualizar distribuci√≥n\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "axes[0].hist(latencies, bins=30, color='skyblue', edgecolor='black', alpha=0.7)\n",
    "axes[0].axvline(latencies.mean(), color='red', linestyle='--', label=f'media: {latencies.mean():.2f}ms')\n",
    "axes[0].axvline(np.percentile(latencies, 95), color='orange', linestyle='--', label=f'P95: {np.percentile(latencies, 95):.2f}ms')\n",
    "axes[0].set_xlabel('latencia (ms)')\n",
    "axes[0].set_ylabel('Frecuencia')\n",
    "axes[0].set_title('Distribuci√≥n de latencia')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1].boxplot(latencies, vert=True)\n",
    "axes[1].set_ylabel('latencia (ms)')\n",
    "axes[1].set_title('Diagrama de caja de la latencia')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d43aaf2",
   "metadata": {},
   "source": [
    "## 8. Conclusiones\n",
    "\n",
    "### Ventajas de la aproximaci√≥n neurom√≥rfica\n",
    "\n",
    "1. **Ultrabaja latencia**: Detecci√≥n en ~10ms\n",
    "2. **Procesamiento temporal nativo**: Captura patrones de secuencia de forma natural\n",
    "3. **Eficiencia energ√©tica**: Ideal para despliegue en dispositivos de borde\n",
    "4. **Aprendizaje biol√≥gico**: STDP permite adaptaci√≥n continua\n",
    "\n",
    "### Aplicaciones en bancos y fintechs\n",
    "\n",
    "- Detecci√≥n de fraude en tiempo real en POS\n",
    "- Protecci√≥n de transacciones Pix/TED/DOC\n",
    "- Monitoreo de carteras digitales\n",
    "- An√°lisis comportamental en banca m√≥vil\n",
    "\n",
    "### Pr√≥ximos pasos\n",
    "\n",
    "- Despliegue en hardware neurom√≥rfico (Intel Loihi, IBM TrueNorth)\n",
    "- Integraci√≥n con sistemas heredados v√≠a API\n",
    "- Explicabilidad (SHAP para SNNs)\n",
    "- Aprendizaje federado entre instituciones\n",
    "\n",
    "---\n",
    "\n",
    "**Autor:** Mauro Risonho de Paula Assump√ß√£o \n",
    "**Proyecto:** Computaci√≥n neurom√≥rfica para ciberseguridad bancaria"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
