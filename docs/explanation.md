# ExplicaÃ§Ã£o TÃ©cnica: Como Funciona a DetecÃ§Ã£o de Fraude NeuromÃ³rfica

**DescriÃ§Ã£o:** ExplicaÃ§Ã£o detalhada e didÃ¡tica do funcionamento do sistema de detecÃ§Ã£o de fraude neuromÃ³rfica, desde os conceitos fundamentais atÃ© a implementaÃ§Ã£o prÃ¡tica.

**Autor:** Mauro Risonho de Paula AssumpÃ§Ã£o  
**Data de CriaÃ§Ã£o:** 5 de Dezembro de 2025  
**LicenÃ§a:** MIT License

---

## ğŸ¯ Contexto: O Problema da Fraude BancÃ¡ria

### Desafios Atuais

Bancos e fintechs enfrentam um cenÃ¡rio crescente de fraudes sofisticadas:

- **Velocidade**: Fraudadores agem em segundos
- **Volume**: MilhÃµes de transaÃ§Ãµes por dia
- **EvoluÃ§Ã£o**: PadrÃµes de fraude mudam constantemente
- **LatÃªncia**: DetecÃ§Ã£o deve ser < 100ms para nÃ£o impactar UX
- **Custo computacional**: GPUs e servidores custam caro

### Por Que MÃ©todos Tradicionais TÃªm LimitaÃ§Ãµes?

#### 1. Regras EstÃ¡ticas (Rule-based)
```python
if amount > 10000 and new_merchant:
    flag_as_fraud()
```
âŒ **Problema**: Fraudadores aprendem as regras e as contornam

#### 2. Machine Learning ClÃ¡ssico (Random Forest, XGBoost)
```python
features = [amount, location, time_of_day, ...]
prediction = model.predict(features)
```
âœ… **Vantagem**: Aprende padrÃµes complexos  
âŒ **Problema**: NÃ£o captura relaÃ§Ãµes temporais naturalmente

#### 3. Deep Learning (LSTM, Transformer)
```python
sequence = [txn1, txn2, txn3, ...]
prediction = lstm_model.predict(sequence)
```
âœ… **Vantagem**: Processa sequÃªncias temporais  
âŒ **Problemas**:
- Alta latÃªncia (~100-500ms)
- Alto consumo energÃ©tico (GPUs)
- DifÃ­cil adaptar online

---

## ğŸ§  A SoluÃ§Ã£o NeuromÃ³rfica

### O Que SÃ£o Redes Neurais Spiking (SNNs)?

**InspiraÃ§Ã£o biolÃ³gica**: NeurÃ´nios no cÃ©rebro humano nÃ£o processam valores contÃ­nuos, mas **eventos discretos chamados spikes**.

```
NeurÃ´nio tradicional (ANN):      NeurÃ´nio spiking (SNN):
Input: [0.5, 0.8, 0.3]           Input: Spikes em t=[5ms, 12ms, 18ms]
Output: 0.67                     Output: Spike em t=25ms
```

### Por Que Isso Ã‰ RevolucionÃ¡rio?

1. **Processamento Event-driven**
   - SÃ³ computa quando hÃ¡ eventos (spikes)
   - Economia massiva de energia

2. **Temporal por Natureza**
   - Timing de spikes carrega informaÃ§Ã£o
   - Detecta sequÃªncias e padrÃµes temporais naturalmente

3. **Aprendizado BiolÃ³gico (STDP)**
   - NÃ£o precisa de backpropagation
   - Aprende correlaÃ§Ãµes causais automaticamente

---

## ğŸ”¬ Como Funciona: Passo a Passo

### Passo 1: Receber TransaÃ§Ã£o

```json
{
  "amount": 5000.00,
  "timestamp": "2025-12-05T14:30:00Z",
  "merchant": "Electronics Store",
  "location": {"lat": -23.5505, "lon": -46.6333},
  "device_id": "abc123xyz",
  "user_id": "user_8472"
}
```

**Contexto Adicional (Consultado):**
- HistÃ³rico do usuÃ¡rio: MÃ©dia de $150 por transaÃ§Ã£o
- LocalizaÃ§Ã£o usual: SÃ£o Paulo
- HorÃ¡rio tÃ­pico: 10h-18h
- Device conhecido: Sim
- Ãšltima transaÃ§Ã£o: 2 horas atrÃ¡s

### Passo 2: Extrair Features

```python
features = {
    'amount_log': log(5000) = 8.52,          # Log-scale
    'hour': 14,                               # Hora do dia
    'weekday': 3,                             # Quarta-feira
    'is_weekend': False,
    'amount_deviation': (5000 - 150) / 150 = 32.3,  # Desvio da mÃ©dia
    'location_distance': 0 km,                # DistÃ¢ncia da Ãºltima
    'time_since_last': 7200 s,                # 2 horas
    'device_known': True,
    'merchant_category': 3                    # Electronics
}
```

### Passo 3: Codificar em Spikes

#### 3.1 Rate Encoding (Valor)
```
Amount = $5000 (alto) â†’ 50 spikes em 100ms
DistribuiÃ§Ã£o: Poisson com taxa Î»=500 Hz

Spikes gerados:
[2.3ms, 5.1ms, 8.7ms, 12.4ms, ..., 97.8ms]  (50 spikes total)
```

#### 3.2 Temporal Encoding (HorÃ¡rio)
```
14h30 = 14.5 horas
Normalizado: 14.5 / 24 = 0.604
Spike em: 0.604 * 100ms = 60.4ms
```

#### 3.3 Population Encoding (LocalizaÃ§Ã£o)
```
SÃ£o Paulo: (lat=-23.55, lon=-46.63)
Ativa neurÃ´nios [120-135] com intensidades variadas

NeurÃ´nio 127: 0.98 â†’ 98 spikes/s
NeurÃ´nio 128: 1.00 â†’ 100 spikes/s (centro)
NeurÃ´nio 129: 0.95 â†’ 95 spikes/s
```

**Resultado Final:**
```
Input spike train: 256 neurÃ´nios de entrada
Total de spikes: ~180 spikes distribuÃ­dos ao longo de 100ms
```

### Passo 4: Processar na SNN

#### 4.1 Input Layer â†’ Hidden Layer 1
```
256 neurÃ´nios de entrada â†’ 128 neurÃ´nios LIF

NeurÃ´nio LIF recebe spikes:
1. Spike chega â†’ corrente sinÃ¡ptica aumenta (I_syn += w)
2. Corrente integra ao potencial de membrana: V(t)
3. Se V > threshold â†’ neurÃ´nio dispara
4. Reset e perÃ­odo refratÃ¡rio
```

**Exemplo de NeurÃ´nio Individual:**
```
t=0ms:   V = -70mV (repouso)
t=5ms:   Spike chega, I_syn = +0.5mV â†’ V = -69.5mV
t=10ms:  Outro spike, I_syn = +0.5mV â†’ V = -68.8mV
t=15ms:  V continua subindo...
t=23ms:  V = -49mV > threshold (-50mV) â†’ SPIKE!
t=24ms:  V reset para -70mV, perÃ­odo refratÃ¡rio
```

#### 4.2 Hidden Layer 1 â†’ Hidden Layer 2
- Hidden 1 gera padrÃ£o de spikes
- Hidden 2 (64 neurÃ´nios) processa em nÃ­vel mais abstrato
- Detecta features de ordem superior

#### 4.3 Hidden Layer 2 â†’ Output
- Output tem 2 neurÃ´nios:
  - **NeurÃ´nio 0**: "LegÃ­tima"
  - **NeurÃ´nio 1**: "Fraudulenta"

**Resultado da SimulaÃ§Ã£o (100ms):**
```
NeurÃ´nio 0 (LegÃ­tima):  5 spikes  â†’ 50 Hz
NeurÃ´nio 1 (Fraude):    23 spikes â†’ 230 Hz
```

### Passo 5: DecisÃ£o

```python
fraud_rate = 230 Hz
legit_rate = 50 Hz

if fraud_rate > legit_rate:
    decision = "FRAUD"
    confidence = 230 / (230 + 50) = 0.82 = 82%
else:
    decision = "LEGITIMATE"
```

**AÃ§Ã£o:**
```
BLOCK TRANSACTION
Alert: Fraud detected (82% confidence)
Reason: High amount deviation + unusual spike pattern
```

---

## ğŸ§¬ STDP: O Aprendizado BiolÃ³gico

### O Que Ã‰ STDP?

**Spike-Timing-Dependent Plasticity** = Plasticidade dependente do timing de spikes

**PrincÃ­pio:**
- Se neurÃ´nio A dispara **ANTES** de neurÃ´nio B â†’ **ReforÃ§a conexÃ£o** (A causou B)
- Se neurÃ´nio A dispara **DEPOIS** de neurÃ´nio B â†’ **Enfraquece conexÃ£o** (A nÃ£o causou B)

### Como Funciona?

```
NeurÃ´nio PrÃ© (A)  â”€â”€â”€â”€â”€â”
                       â”‚ Sinapse (peso w)
NeurÃ´nio PÃ³s (B)  â”€â”€â”€â”€â”€â”˜

CenÃ¡rio 1: A dispara em t=10ms, B dispara em t=15ms
    Î”t = 15 - 10 = +5ms (positivo)
    â†’ PotenciaÃ§Ã£o: w aumenta (+0.01)
    â†’ InterpretaÃ§Ã£o: A contribuiu para B disparar

CenÃ¡rio 2: A dispara em t=20ms, B dispara em t=15ms
    Î”t = 15 - 20 = -5ms (negativo)
    â†’ DepressÃ£o: w diminui (-0.012)
    â†’ InterpretaÃ§Ã£o: A nÃ£o contribuiu para B
```

### AplicaÃ§Ã£o em Fraude

**Treinamento com transaÃ§Ãµes legÃ­timas:**
```
SequÃªncia tÃ­pica:
1. Login (t=0ms) â†’ spike no input
2. NavegaÃ§Ã£o (t=500ms) â†’ spike no input
3. SeleÃ§Ã£o beneficiÃ¡rio (t=2000ms) â†’ spike no input
4. Pagamento (t=3000ms) â†’ spike no input
5. Output "LegÃ­tima" dispara (t=3100ms)

STDP reforÃ§a:
- ConexÃµes que seguem essa sequÃªncia
- Pesos de features que precedem output "legÃ­tima"
```

**DetecÃ§Ã£o de fraude:**
```
SequÃªncia anÃ´mala:
1. Login (t=0ms)
2. Pagamento IMEDIATO (t=50ms) âš ï¸
3. Valor alto (50 spikes rÃ¡pidos) âš ï¸
4. LocalizaÃ§Ã£o estranha âš ï¸

STDP reconhece:
- SequÃªncia nÃ£o reforÃ§ada durante treinamento
- Timing incompatÃ­vel com padrÃ£o legÃ­timo
- Output "Fraude" dispara
```

---

## ğŸ“Š Por Que Isso Funciona?

### 1. Captura de PadrÃµes Temporais

**Exemplo Real:**

**TransaÃ§Ã£o LegÃ­tima:**
```
t=0s:    Abre app
t=30s:   Navega pelo extrato
t=120s:  Seleciona "Transferir"
t=180s:  Digita valor
t=240s:  Confirma com biometria
```
â†’ **SequÃªncia temporal natural**

**TransaÃ§Ã£o Fraudulenta (Malware):**
```
t=0s:    Abre app
t=2s:    TransferÃªncia executada automaticamente âš ï¸
```
â†’ **Velocidade impossÃ­vel para humano**

SNN detecta porque:
- Intervalo entre eventos Ã© codificado em spikes
- STDP aprendeu timing normal
- PadrÃ£o anÃ´malo nÃ£o ativa neurÃ´nios "legÃ­timos"

### 2. EficiÃªncia Computacional

**ComparaÃ§Ã£o:**

**DNN (Deep Neural Network):**
```
Forward pass: Multiplica TODAS as camadas
256 â†’ 128 â†’ 64 â†’ 2
Total: 256*128 + 128*64 + 64*2 = 41,088 multiplicaÃ§Ãµes
```

**SNN:**
```
Event-driven: SÃ³ computa quando hÃ¡ spike
Se 180 spikes em 100ms:
Total: ~5,000 operaÃ§Ãµes (apenas nos spikes)
```

**Economia: 88%**

### 3. Baixa LatÃªncia

**Pipeline:**
```
Feature extraction:  2ms
Spike encoding:      3ms
SNN simulation:      5ms  â† Event-driven, nÃ£o bloqueia
Decision:            <1ms
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
TOTAL:               ~10ms
```

Vs. DNN tradicional:
```
Feature extraction:  2ms
Neural network:      50ms  â† Batch processing
Post-processing:     10ms
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
TOTAL:               ~62ms
```

---

## ğŸ“ Conceitos AvanÃ§ados

### 1. Homeostatic Plasticity

**Problema**: NeurÃ´nios podem saturar (disparar sempre) ou silenciar (nunca disparar)

**SoluÃ§Ã£o**: Ajuste automÃ¡tico de sensibilidade
```python
if firing_rate > target_high:
    threshold += 0.1  # Fica mais difÃ­cil disparar
elif firing_rate < target_low:
    threshold -= 0.1  # Fica mais fÃ¡cil disparar
```

### 2. Lateral Inhibition

**Problema**: MÃºltiplos neurÃ´nios similares disparam juntos (redundÃ¢ncia)

**SoluÃ§Ã£o**: Winner-takes-all
```
NeurÃ´nios na mesma camada competem:
- NeurÃ´nio mais ativo inibe vizinhos
- ForÃ§a especializaÃ§Ã£o
- Aumenta esparsidade de representaÃ§Ã£o
```

### 3. Reward Modulation

**InspiraÃ§Ã£o**: Dopamina no cÃ©rebro

**AplicaÃ§Ã£o**:
```python
if transaction_confirmed_fraud:
    reward = +1
    # ReforÃ§a pesos que levaram Ã  detecÃ§Ã£o correta
else:
    reward = -1
    # Enfraquece pesos (falso positivo)

STDP modulado: Î”w = reward * STDP_change
```

---

## ğŸš€ Deployment em ProduÃ§Ã£o

### CenÃ¡rio 1: Cloud API

```python
from flask import Flask, request
from fraud_snn import FraudDetectionPipeline

app = Flask(__name__)
pipeline = FraudDetectionPipeline()

@app.route('/detect', methods=['POST'])
def detect_fraud():
    transaction = request.json
    result = pipeline.predict(transaction)
    
    if result['is_fraud']:
        # Bloquear transaÃ§Ã£o
        # Enviar alerta
        # Log no SIEM
        return {"action": "BLOCK", "confidence": result['confidence']}
    else:
        return {"action": "ALLOW"}
```

### CenÃ¡rio 2: Kafka Stream

```python
from kafka import KafkaConsumer, KafkaProducer

consumer = KafkaConsumer('transactions')
producer = KafkaProducer('fraud_alerts')

for message in consumer:
    transaction = json.loads(message.value)
    result = pipeline.predict(transaction)
    
    if result['is_fraud']:
        alert = {
            'transaction_id': transaction['id'],
            'confidence': result['confidence'],
            'timestamp': datetime.now()
        }
        producer.send('fraud_alerts', alert)
```

### CenÃ¡rio 3: Hardware NeuromÃ³rfico (Loihi)

```python
# Port para Intel Loihi
from nxsdk.graph.nxgraph import NxGraph

graph = NxGraph()
# Mapear SNN para cores Loihi
# LatÃªncia: <1ms
# Consumo: ~50mW
```

---

## ğŸ“ˆ Resultados Esperados

### MÃ©tricas de Performance

**AcurÃ¡cia:** 97-98%  
**PrecisÃ£o:** 94-96% (poucos falsos positivos)  
**Recall:** 93-95% (detecta maioria das fraudes)  
**F1-Score:** 94-95%  

**LatÃªncia:** <10ms  
**Throughput:** >100,000 transaÃ§Ãµes/segundo (paralelo)  
**Consumo energÃ©tico:** ~50mW (hardware neuromÃ³rfico)  

### Casos de Uso Detectados

âœ… **Fraudes detectadas:**
- Valores anormalmente altos
- Velocidade impossÃ­vel (impossibility attack)
- LocalizaÃ§Ã£o geogrÃ¡fica inconsistente
- Dispositivo novo + comportamento suspeito
- HorÃ¡rios atÃ­picos + valor alto
- SequÃªncia de aÃ§Ãµes anÃ´mala

âŒ **Falsos positivos minimizados:**
- UsuÃ¡rio genuÃ­no em viagem (location change)
- Compras maiores em datas especiais (Black Friday)
- Dispositivo novo mas sequÃªncia normal

---

## ğŸ¯ ConclusÃ£o

### Vantagens da Abordagem NeuromÃ³rfica

1. âœ… **Ultra-baixa latÃªncia** (<10ms)
2. âœ… **EficiÃªncia energÃ©tica** (100x menos que GPU)
3. âœ… **Processamento temporal nativo**
4. âœ… **Aprendizado contÃ­nuo** (STDP)
5. âœ… **EscalÃ¡vel** (hardware dedicado)

### Quando Usar?

**Ideal para:**
- DetecÃ§Ã£o de fraude em tempo real
- AplicaÃ§Ãµes edge (mobile, IoT)
- Alto volume de transaÃ§Ãµes
- Requisitos de baixa latÃªncia
- RestriÃ§Ãµes de energia

**NÃ£o ideal para:**
- Pequeno volume de dados
- LatÃªncia nÃ£o crÃ­tica
- Infraestrutura legada sem GPU/neuromorphic

---

**Autor:** Mauro Risonho de Paula AssumpÃ§Ã£o  
**Projeto:** ComputaÃ§Ã£o NeuromÃ³rfica para Cybersecurity BancÃ¡ria  
**Contato:** [GitHub](https://github.com/maurorisonho)
